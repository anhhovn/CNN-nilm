{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "334f78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fbd87ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_selected_channels_h1 = ['kitchen_outlets_7','kitchen_outlets_8','kitchen_outlets_15','kitchen_outlets_16'\n",
    "                            ,'lighting_9','lighting_17','lighting_18','electric_oven_3','electric_oven_4','microwave',\n",
    "                            'washer_dryer_10','washer_dryer_20', 'refrigerator', 'bathroom_gfi']\n",
    "selected_channels_h1     = ['kitchen_outlets_7', 'lighting_18', 'washer_dryer_20', 'electric_oven_3', 'microwave', \n",
    "                            'refrigerator', 'bathroom_gfi']\n",
    "all_selected_channels_h3 = ['kitchen_outlets_22','furnace','washer_dryer_13', 'microwave', 'bathroom_gfi']\n",
    "\n",
    "selected_channels_h3     = ['kitchen_outlets_22','furnace','washer_dryer_13', 'microwave', 'bathroom_gfi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "859389d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('house3-nosampling/h3_5min.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6141dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['main'].copy()\n",
    "y = df[selected_channels_h3].copy()\n",
    "target_name = selected_channels_h3\n",
    "window = 100\n",
    "dimension = 6\n",
    "delay_in_second = 32\n",
    "sample = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe6baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8523ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowing(narray, window):\n",
    "    rem = len(narray) % window\n",
    "    if rem > 0:\n",
    "        narray = narray[:-rem]\n",
    "    n_dims = len(narray.shape)\n",
    "    if n_dims == 1:\n",
    "        seq_in_batches = np.reshape(narray, (int(len(narray) / window), window))\n",
    "    elif n_dims == 2:\n",
    "        seq_in_batches = np.reshape(narray, (int(len(narray) / window), window, narray.shape[1]))\n",
    "    print(seq_in_batches)\n",
    "    return seq_in_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dcf4b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensions(data_in_batches: np.ndarray, window: int, sample_period: int,\n",
    "                      dimension: int, delay_in_seconds: int, should_fit: bool = True):\n",
    "    \"\"\"\n",
    "    It uses the method approximate of the TimeSeriesTransformer in order to achieve dimensionality reduction.\n",
    "    Args:\n",
    "        data_in_batches (ndarray): The data of the time series separated in batches.\n",
    "        window (int): The size of the sub-segments of the given time series.\n",
    "            This is not supported by all algorithms.\n",
    "        target (ndarray): The labels that correspond to the given data in batches.\n",
    "        should_fit (bool): True if it is supported by the algorithm of the specified time series representation.\n",
    "    Returns:\n",
    "        The shortened time series as an array (ndarray).\n",
    "    \"\"\"\n",
    "    squeezed_seq = approximate(delay_in_seconds, dimension, sample_period = sample_period, \n",
    "                               series_in_segments = data_in_batches, window = window, should_fit = True)\n",
    "\n",
    "    print('Shape of squeezed seq: {}'.format(squeezed_seq.shape))\n",
    "    if len(squeezed_seq.shape) == 3:\n",
    "        squeezed_seq = np.reshape(squeezed_seq, (squeezed_seq.shape[0], squeezed_seq.shape[1] * squeezed_seq.shape[2]))\n",
    "    return squeezed_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9522b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate(delay_in_seconds: int, dimension: int, sample_period: int, series_in_segments: np.ndarray, window: int = 1, should_fit: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    The time series is given as segments. For each segment we extract the delay embeddings.\n",
    "    \"\"\"\n",
    "    delay_items = int(delay_in_seconds / sample_period)\n",
    "    window_size = delay_items * dimension\n",
    "\n",
    "    if window_size > len(series_in_segments[0]):\n",
    "        raise Exception(\n",
    "            f'Not enough data for the given delay ({delay_in_seconds} seconds) and dimension ({dimension}).'\n",
    "            f'\\ndelay_items * dimension > len(data): {window_size} > {len(series_in_segments[0])}')\n",
    "\n",
    "    if window_size == len(series_in_segments[0]):\n",
    "        print(f\"TimeDelayEmbeddingAdapter is applied with delay embeddings equavalent to the length of each segment\"\n",
    "                f\" {window_size} == {len(series_in_segments[0])}\")\n",
    "\n",
    "    if window_size < len(series_in_segments[0]):\n",
    "        print(f\"TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each \"\n",
    "                f\"segment. {window_size} < {len(series_in_segments[0])}\")\n",
    "\n",
    "    delay_embeddings = []\n",
    "    for segment in series_in_segments:\n",
    "        embedding = takens_embedding(segment, delay_items, dimension)\n",
    "        delay_embeddings.append(embedding)\n",
    "    return np.asarray(delay_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b3ef2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def takens_embedding(series: np.ndarray, delay, dimension) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function returns the Takens embedding of data with delay into dimension,\n",
    "    delay*dimension must be < len(data)\n",
    "    \"\"\"\n",
    "    if delay * dimension > len(series):\n",
    "        print(f'Not enough data for the given delay ({delay}) and dimension ({dimension}).'\n",
    "             f'\\ndelay * dimension > len(data): {delay * dimension} > {len(series)}')\n",
    "        return series\n",
    "    delay_embedding = np.array([series[0:len(series) - delay * dimension]])\n",
    "    for i in range(1, dimension):\n",
    "        delay_embedding = np.append(delay_embedding,\n",
    "                                    [series[i * delay:len(series) - delay * (dimension - i)]], axis=0)\n",
    "    return delay_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4cb09b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0f89e39f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[181.34 180.74 182.   ... 187.97 182.53 181.96]\n",
      " [181.   180.86 180.35 ... 181.82 182.41 181.91]\n",
      " [194.41 199.73 193.31 ... 181.89 180.91 180.9 ]\n",
      " ...\n",
      " [ 15.45  15.44  15.48 ...  15.56  15.49  15.55]\n",
      " [ 15.43  15.49  15.46 ...  15.6   15.59  15.55]\n",
      " [ 15.48  15.48  15.49 ...  15.54  15.55  15.48]]\n",
      "[[[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "X = windowing(X, window)\n",
    "y = windowing(y, window)\n",
    "#y = y.reshape(y.shape[0]*y.shape[1],y.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3245ce68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 60 < 100\n",
      "Shape of squeezed seq: (37601, 6, 40)\n"
     ]
    }
   ],
   "source": [
    "X = reduce_dimensions(X, window, sample, dimension, delay_in_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a2082a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(shape=(y.shape[0],y.shape[2] ))\n",
    "# Process y, if the appliance was on once or more than once in the window then the label of the whole window is 1, else 0 \n",
    "for i in range(len(y)):\n",
    "    a[i] = y[i].sum(axis = 0)\n",
    "\n",
    "Y = np.zeros(shape=(y.shape[0],y.shape[2] ))\n",
    "\n",
    "for i in range(len(a)):\n",
    "    Y[i] += [1 if a[i][j] != 0 else 0 for j in range(len(a[i]))]\n",
    "Y = Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6d9ed51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d797edb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = MLkNN(k=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "predict_proba = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "022cd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_csr = sparse.csr_matrix(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "41c85f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 macro 0.4485846435323131\n",
      "F1 micro 0.6478646253021756\n",
      "{'kitchen_outlets_22': {'precision': 0.14482758620689656, 'recall': 0.16216216216216217, 'f1-score': 0.15300546448087432, 'support': 259}, 'furnace': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'washer_dryer_13': {'precision': 0.989010989010989, 'recall': 0.9540636042402827, 'f1-score': 0.9712230215827339, 'support': 566}, 'microwave': {'precision': 0.4744186046511628, 'recall': 0.4657534246575342, 'f1-score': 0.4700460829493088, 'support': 219}, 'bathroom_gfi': {'precision': 0.5194805194805194, 'recall': 0.8633093525179856, 'f1-score': 0.6486486486486486, 'support': 139}, 'micro avg': {'precision': 0.6189376443418014, 'recall': 0.6796280642434489, 'f1-score': 0.6478646253021756, 'support': 1183}, 'macro avg': {'precision': 0.42554753986991367, 'recall': 0.4890577087155929, 'f1-score': 0.4485846435323131, 'support': 1183}, 'weighted avg': {'precision': 0.6537582681607801, 'recall': 0.6796280642434489, 'f1-score': 0.6614056634357013, 'support': 1183}, 'samples avg': {'precision': 0.05796867864721841, 'recall': 0.05790152308808123, 'f1-score': 0.05663899857630214, 'support': 1183}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "micro = f1_score(y_test, predictions, average='micro')\n",
    "macro = f1_score(y_test, predictions, average='macro')\n",
    "#info('MlkNN report')\n",
    "print('F1 macro {}'.format(macro))\n",
    "print('F1 micro {}'.format(micro))\n",
    "report = classification_report(y_test, predictions, target_names=target_name, output_dict=True)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c58ccd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Ratio: 0.9455234104279152\n",
      "Hamming loss: 0.014086550084616005\n",
      "Recall: 0.05796867864721841\n",
      "Precision: 0.05790152308808123\n",
      "F1 Measure: 0.05663899857630214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "print('Exact Match Ratio: {0}'.format(metrics.accuracy_score(y_test, predictions, normalize=True, sample_weight=None)))\n",
    "print('Hamming loss: {0}'.format(metrics.hamming_loss(y_test, predictions))) \n",
    "print('Recall: {0}'.format(metrics.precision_score(y_true=y_test, y_pred=predictions, average='samples'))) \n",
    "print('Precision: {0}'.format(metrics.recall_score(y_true=y_test, y_pred=predictions, average='samples')))\n",
    "print('F1 Measure: {0}'.format(metrics.f1_score(y_true=y_test, y_pred=predictions, average='samples'))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3c28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
