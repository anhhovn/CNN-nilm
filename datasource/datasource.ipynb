{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec9529b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilmtk as nilmtk\n",
    "from nilmtk import DataSet, MeterGroup, Appliance\n",
    "from nilmtk.metergroup import MeterGroupID\n",
    "from nilmtk.elecmeter import ElecMeter, ElecMeterID \n",
    "from typing import List, Tuple, Dict\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "#REDD = os.path.join(dirname, r\"datasource\\dataset\\REDD\\redd.h5\")\n",
    "redd = DataSet('redd.h5')\n",
    "SITE_METER = 'Site meter'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4243a2",
   "metadata": {},
   "source": [
    "### House 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "938b4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2011'\n",
    "train_month_end = '5'\n",
    "train_month_start = '4'\n",
    "train_end_date = \"{}-17-{}\".format(train_month_end, year)\n",
    "train_start_date = \"{}-18-{}\".format(train_month_start, year)\n",
    "test_month_end = '5'\n",
    "test_month_start = '5'\n",
    "test_end_date = \"{}-25-{}\".format(test_month_end, year)\n",
    "test_start_date = \"{}-18-{}\".format(test_month_start, year)\n",
    "#appliances for [1]\n",
    "appliances_redd1_taba = ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
    "##appliances for [2]\n",
    "appliances_redd1_nalm = ['electric oven', 'fridge', 'light', 'microwave', 'unknown', 'sockets']\n",
    "\n",
    "building = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c95ea785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(t: str):\n",
    "    print('TIMING: ' + t)\n",
    "    print()\n",
    "\n",
    "    \n",
    "def info(i: str):\n",
    "    print('INFO: ' + i)\n",
    "    \n",
    "def debug(d):\n",
    "    print('DEBUG: ' + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d99a2",
   "metadata": {},
   "source": [
    "## Read data using nilmtk\n",
    "* Read selected data\n",
    "* Label data\n",
    "* Bucketize data (delay embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94ae4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_metergroup(dataset: DataSet, building: int, appliances: List,  start: str, end: str, \n",
    "                               sample_period = 3, include_mains=True):\n",
    "    \"\"\"\n",
    "    Get the MeterGroup of selected appliances\n",
    "    Return the MeterGroup\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_selected_metergroup() starts')\n",
    "    dataset.set_window(start=start, end=end)\n",
    "    elec = dataset.buildings[building].elec\n",
    "    appliances_with_one_meter = []\n",
    "    appliances_with_more_meters = []\n",
    "    for appliance in appliances:\n",
    "        metergroup = elec.select_using_appliances(type=appliances)\n",
    "        if len(metergroup.meters) > 1:\n",
    "            appliances_with_more_meters.append(appliance)\n",
    "        else:\n",
    "            appliances_with_one_meter.append(appliance)\n",
    "\n",
    "    special_metergroup = None\n",
    "    for appliance in appliances_with_more_meters:\n",
    "        inst = 1\n",
    "        if appliance == 'sockets' and building == 3:\n",
    "            inst = 4\n",
    "        if special_metergroup is None:\n",
    "            special_metergroup = elec.select_using_appliances(type=appliance, instance=inst)\n",
    "        else:\n",
    "            special_metergroup = special_metergroup.union(elec.select_using_appliances(type=appliance, instance=1))\n",
    "\n",
    "    selected_metergroup = elec.select_using_appliances(type=appliances_with_one_meter)\n",
    "    selected_metergroup = selected_metergroup.union(special_metergroup)\n",
    "    if include_mains:\n",
    "        mains_meter = dataset.buildings[building].elec.mains()\n",
    "        if isinstance(mains_meter, MeterGroup):\n",
    "            if len(mains_meter.meters) > 1:\n",
    "                mains_meter = mains_meter.meters[0]\n",
    "                mains_metergroup = MeterGroup(meters=[mains_meter])\n",
    "            else:\n",
    "                mains_metergroup = mains_meter\n",
    "        else:\n",
    "            mains_metergroup = MeterGroup(meters=[mains_meter])\n",
    "        selected_metergroup = selected_metergroup.union(mains_metergroup)\n",
    "    info('get_selected_metergroup() finished')\n",
    "    print(selected_metergroup)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "    return selected_metergroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3af49e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_selected_appliances(dataset: DataSet, building: int, appliances : List, start: str, end: str, include_mains,\n",
    "                               sample_period = 3):\n",
    "    \"\"\"\n",
    "    Read and fill in missing values of selected appliances in a given bulding\n",
    "    Return the DataFrame of selected appliances in which columns are ElecMeter IDs,\n",
    "    and values are the PC of the meter in given sample period\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('read_selected_appliances() starts')\n",
    "    selected_metergroup = get_selected_metergroup(dataset, building, appliances, start, end,sample_period,include_mains)\n",
    "    df = selected_metergroup.dataframe_of_meters(sample_period=sample_period)\n",
    "    df.fillna(0, inplace=True)\n",
    "    info('read_selected_appliances() finished')\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "    return df, selected_metergroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36a08373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_meters(dataset: DataSet, building: int, start_date: str, end_date:str, sample_period = 3):\n",
    "    \"\"\"\n",
    "    Read all the meters in given building\n",
    "    \"\"\"\n",
    "    elec = dataset.buildings[building].elec\n",
    "    print(elec)\n",
    "    #redd_datasource = Datasource(redd, \"REDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86957733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_df(df: DataFrame, selected_metergroup: MeterGroup) -> [List, Dict]:\n",
    "    \"\"\"\n",
    "    Returns two lists, one is a list of labels which describes DataFrame columns\n",
    "    Other is a list of power threshold of each appliances\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_labels_df() starts')\n",
    "    lst = []\n",
    "    threshold = {}\n",
    "    for m in df.columns:\n",
    "        label = \"\"\n",
    "        if isinstance(m,MeterGroupID):\n",
    "            tup_elecmeterID = m[0]\n",
    "            lst_elecmeterID = list(tup_elecmeterID)\n",
    "            #get meter group using list of ElecMeterIDs\n",
    "            mg = selected_metergroup[lst_elecmeterID]\n",
    "            #get labels of meter group\n",
    "            labels = mg.get_labels(lst_elecmeterID)\n",
    "            label = labels[0]\n",
    "            threshold[label] =mg.on_power_threshold()\n",
    "        else:\n",
    "            #get ElecMeter using ElecMeterID\n",
    "            elec_meter = selected_metergroup[m]\n",
    "            #get labels of ElecMeter\n",
    "            label = elec_meter.label()\n",
    "            threshold[label] = elec_meter.on_power_threshold()\n",
    "        lst += [label]\n",
    "    info('get_labels_df() finished')\n",
    "    print(lst)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "        \n",
    "    return lst, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77703d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dic_real_power(df: DataFrame, labels: List) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns a Dictionary in which key is name of the appliance, and value is the power consumption the appliance\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_dic_real_power() starts')\n",
    "    Dict = {}\n",
    "    lst = []\n",
    "    for k, v in df.items():\n",
    "        lst += [v]\n",
    "        \n",
    "    for i in range(len(labels)):\n",
    "        Dict[labels[i]] = lst[i]\n",
    "    info('get_dic_real_power() finished')\n",
    "    print(Dict)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))    \n",
    "    return Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10510e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dic_labeled_power(RealPower: Dict, threshold: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns a Dictionary in which key is name of the appliance, and value is \n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_dic_labeled_power() starts')\n",
    "    LabeledPower = {}\n",
    "    for appliance, real_power in RealPower.items():\n",
    "        if appliance != 'Site meter':\n",
    "            arr = create_labels(real_power, threshold[appliance])\n",
    "            LabeledPower[appliance] = arr\n",
    "    info('get_dic_labeled_power() finished')\n",
    "    print(LabeledPower)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "    return LabeledPower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b4b38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(array, threshold):\n",
    "    res = np.empty(array.shape)\n",
    "    for i in range(len(array)):\n",
    "        if array[i] >= threshold:\n",
    "            res[i] = 1\n",
    "        else:\n",
    "            res[i] = 0\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "217df2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def normalize_columns(df: DataFrame, meter_group: MeterGroup, appliance_names: List[str]) -> Tuple[DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    It normalizes the names of the columns for compatibility.\n",
    "    Args:\n",
    "        df (DataFrame):\n",
    "        meter_group (MeterGroup):\n",
    "        appliance_names (List[str]):\n",
    "    Returns:\n",
    "        A tuple with a DataFrame and a dictionary mapping labels to ids.\n",
    "    \"\"\"\n",
    "    labels = meter_group.get_labels(df.columns)\n",
    "    normalized_labels = []\n",
    "    info(f\"Df columns before normalization {df.columns}\")\n",
    "    info(f\"Labels before normalization {labels}\")\n",
    "\n",
    "    for label in labels:\n",
    "        if label == SITE_METER and SITE_METER not in appliance_names:\n",
    "            normalized_labels.append(SITE_METER)\n",
    "            continue\n",
    "        for name in appliance_names:\n",
    "            ratio = fuzz.ratio(label.lower().replace('electric', \"\").lstrip().rstrip().split()[0],\n",
    "                                   name.lower().replace('electric', \"\").lstrip().rstrip().split()[0])\n",
    "            if ratio > 90:\n",
    "                info(f\"{name} ~ {label} ({ratio}%)\")\n",
    "                normalized_labels.append(name)\n",
    "    if len(normalized_labels) != len(labels):\n",
    "        debug(f\"len(normalized_labels) {len(normalized_labels)} != len(labels) {len(labels)}\")\n",
    "        raise LabelNormalizationError()\n",
    "    label2id = {l: i for l, i in zip(normalized_labels, df.columns)}\n",
    "    df.columns = normalized_labels\n",
    "    info(f\"Normalized labels {normalized_labels}\")\n",
    "    return df, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e55534e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_site_meter_data(df: DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the data of the site meter from the given DataFrame.\n",
    "    Args:\n",
    "        df (DataFrame): A DataFrame containing energy data with columns corresponding to different meters.\n",
    "    Returns:\n",
    "        The site meter data as an array (ndarray).\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if SITE_METER in col:\n",
    "            return df[col].values\n",
    "    raise NoSiteMeterException(\"Couldn' t find site meter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "785ec9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multilabels(labels_df: DataFrame, appliances: List = None) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Get the labels of the specified appliances.\n",
    "    Args:\n",
    "        labels_df (DataFrame):\n",
    "        appliances (List):\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    debug(f\"get_multilabels  labels_df.columns {labels_df.columns}\")\n",
    "    debug(f\"get_multilabels  appliances {appliances}\")\n",
    "    if appliances is None:\n",
    "        return labels_df\n",
    "    else:\n",
    "        return labels_df[appliances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d32476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_one_building(dataset: DataSet, appliances, building, start, end, sample_period) -> (pd.DataFrame, MeterGroup, Dict, Dict):\n",
    "    all_df, metergroup = read_selected_appliances(dataset = dataset, building = building, \n",
    "                                                 appliances = appliances, start = start, end = end, include_mains = True, sample_period = sample_period )\n",
    "    debug(f\"Length of data of all loaded meters {len(all_df)}\")\n",
    "    all_df, label2id = normalize_columns(all_df, metergroup, appliances)\n",
    "    debug(f\"Length of data of all loaded meters {len(all_df)}\")\n",
    "    info('Meters that have been loaded (all_df.columns):\\n' + str(all_df.columns))\n",
    "    \n",
    "    \n",
    "    return all_df, metergroup, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ceb40d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multilabels_from_meters(meters: DataFrame, meter_group: MeterGroup, labels2id: dict) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Creates multi labels from the given meter group using a dictionary as a lookup table.\n",
    "    Args:\n",
    "        meters (DataFrame):\n",
    "        meter_group (MeterGroup):\n",
    "        labels2id (dict):\n",
    "    Returns:\n",
    "        A DataFrame with the multi labels.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    labels = dict()\n",
    "    for col in meters.columns:\n",
    "        info(f\"Creating multilabels from meter {col}, \"\n",
    "             f\"\\nlabels2id[col] {labels2id[col]}\"\n",
    "             f\"\\nmetergroup[labels2id[col]] {meter_group[labels2id[col]]}\")\n",
    "        meter = meter_group[labels2id[col]]\n",
    "        threshold = meter.on_power_threshold()\n",
    "        vals = meters[col].values.astype(float)\n",
    "        if vals is None or col == SITE_METER:\n",
    "            debug(f\"Skipping {col} - {vals}\")\n",
    "            continue\n",
    "        debug(f\"meters[col].values.astype(float) {col} - {vals}\")\n",
    "        labels[col] = create_labels(vals, threshold)\n",
    "    timing('Create multilabels from meters {}'.format(round(time.time() - start_time, 2)))\n",
    "    return DataFrame(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15921bb4",
   "metadata": {},
   "source": [
    "#### Set up train and test data (house 1) for [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5daa2f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: read_selected_appliances() starts\n",
      "INFO: get_selected_metergroup() starts\n",
      "INFO: get_selected_metergroup() finished\n",
      "MeterGroup(meters=\n",
      "  ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "    ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "  ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "  ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "    ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "  ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      ")\n",
      "TIMING: 0.03\n",
      "\n",
      "Loading data for meter ElecMeterID(instance=20, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Loading data for meter ElecMeterID(instance=4, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "INFO: read_selected_appliances() finished\n",
      "TIMING: 5.42\n",
      "\n",
      "DEBUG: Length of data of all loaded meters 411979\n",
      "INFO: Df columns before normalization Index([                       (7, 1, 'REDD'),\n",
      "       (((10, 1, 'REDD'), (20, 1, 'REDD')),),\n",
      "                              (5, 1, 'REDD'),\n",
      "                              (1, 1, 'REDD'),\n",
      "                             (12, 1, 'REDD'),\n",
      "         (((3, 1, 'REDD'), (4, 1, 'REDD')),),\n",
      "                              (9, 1, 'REDD'),\n",
      "                             (11, 1, 'REDD')],\n",
      "      dtype='object')\n",
      "INFO: Labels before normalization ['Sockets', 'Washer dryer', 'Fridge', 'Site meter', 'Unknown', 'Electric oven', 'Light', 'Microwave']\n",
      "INFO: sockets ~ Sockets (100%)\n",
      "INFO: washer dryer ~ Washer dryer (100%)\n",
      "INFO: fridge ~ Fridge (100%)\n",
      "INFO: unknown ~ Unknown (100%)\n",
      "INFO: electric oven ~ Electric oven (100%)\n",
      "INFO: light ~ Light (100%)\n",
      "INFO: microwave ~ Microwave (100%)\n",
      "INFO: Normalized labels ['sockets', 'washer dryer', 'fridge', 'Site meter', 'unknown', 'electric oven', 'light', 'microwave']\n",
      "DEBUG: Length of data of all loaded meters 411979\n",
      "INFO: Meters that have been loaded (all_df.columns):\n",
      "Index(['sockets', 'washer dryer', 'fridge', 'Site meter', 'unknown',\n",
      "       'electric oven', 'light', 'microwave'],\n",
      "      dtype='object')\n",
      "INFO: Creating multilabels from meter sockets, \n",
      "labels2id[col] ElecMeterID(instance=7, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) sockets - [ 0.  34.  34.5 ... 21.  21.5 21. ]\n",
      "INFO: Creating multilabels from meter washer dryer, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=10, building=1, dataset='REDD'), ElecMeterID(instance=20, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) washer dryer - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter fridge, \n",
      "labels2id[col] ElecMeterID(instance=5, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) fridge - [  0.    6.    6.  ... 199.  197.5 197.5]\n",
      "INFO: Creating multilabels from meter Site meter, \n",
      "labels2id[col] ElecMeterID(instance=1, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "DEBUG: Skipping Site meter - [225.28334045 222.60166931 222.67666626 ...   0.           0.\n",
      "   0.        ]\n",
      "INFO: Creating multilabels from meter unknown, \n",
      "labels2id[col] ElecMeterID(instance=12, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) unknown - [0. 1. 1. ... 1. 1. 1.]\n",
      "INFO: Creating multilabels from meter electric oven, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=3, building=1, dataset='REDD'), ElecMeterID(instance=4, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) electric oven - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter light, \n",
      "labels2id[col] ElecMeterID(instance=9, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) light - [ 0. 81. 81. ... 43. 43. 43.]\n",
      "INFO: Creating multilabels from meter microwave, \n",
      "labels2id[col] ElecMeterID(instance=11, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) microwave - [0. 5. 5. ... 4. 4. 4.]\n",
      "TIMING: Create multilabels from meters 1.16\n",
      "\n",
      "INFO: read_selected_appliances() starts\n",
      "INFO: get_selected_metergroup() starts\n",
      "INFO: get_selected_metergroup() finished\n",
      "MeterGroup(meters=\n",
      "  ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "    ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "  ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "  ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "    ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "  ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      ")\n",
      "TIMING: 0.03\n",
      "\n",
      "Loading data for meter ElecMeterID(instance=20, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Loading data for meter ElecMeterID(instance=4, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "INFO: read_selected_appliances() finished\n",
      "TIMING: 1.84\n",
      "\n",
      "DEBUG: Length of data of all loaded meters 95971\n",
      "INFO: Df columns before normalization Index([                       (7, 1, 'REDD'),\n",
      "       (((10, 1, 'REDD'), (20, 1, 'REDD')),),\n",
      "                              (5, 1, 'REDD'),\n",
      "                              (1, 1, 'REDD'),\n",
      "                             (12, 1, 'REDD'),\n",
      "         (((3, 1, 'REDD'), (4, 1, 'REDD')),),\n",
      "                              (9, 1, 'REDD'),\n",
      "                             (11, 1, 'REDD')],\n",
      "      dtype='object')\n",
      "INFO: Labels before normalization ['Sockets', 'Washer dryer', 'Fridge', 'Site meter', 'Unknown', 'Electric oven', 'Light', 'Microwave']\n",
      "INFO: sockets ~ Sockets (100%)\n",
      "INFO: washer dryer ~ Washer dryer (100%)\n",
      "INFO: fridge ~ Fridge (100%)\n",
      "INFO: unknown ~ Unknown (100%)\n",
      "INFO: electric oven ~ Electric oven (100%)\n",
      "INFO: light ~ Light (100%)\n",
      "INFO: microwave ~ Microwave (100%)\n",
      "INFO: Normalized labels ['sockets', 'washer dryer', 'fridge', 'Site meter', 'unknown', 'electric oven', 'light', 'microwave']\n",
      "DEBUG: Length of data of all loaded meters 95971\n",
      "INFO: Meters that have been loaded (all_df.columns):\n",
      "Index(['sockets', 'washer dryer', 'fridge', 'Site meter', 'unknown',\n",
      "       'electric oven', 'light', 'microwave'],\n",
      "      dtype='object')\n",
      "INFO: Creating multilabels from meter sockets, \n",
      "labels2id[col] ElecMeterID(instance=7, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) sockets - [22. 22. 22. ...  0.  0.  0.]\n",
      "INFO: Creating multilabels from meter washer dryer, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=10, building=1, dataset='REDD'), ElecMeterID(instance=20, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) washer dryer - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter fridge, \n",
      "labels2id[col] ElecMeterID(instance=5, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) fridge - [7. 7. 7. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter Site meter, \n",
      "labels2id[col] ElecMeterID(instance=1, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "DEBUG: Skipping Site meter - [  0.           0.           0.         ... 235.17333984 235.08500671\n",
      " 235.25      ]\n",
      "INFO: Creating multilabels from meter unknown, \n",
      "labels2id[col] ElecMeterID(instance=12, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) unknown - [1. 1. 1. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter electric oven, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=3, building=1, dataset='REDD'), ElecMeterID(instance=4, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) electric oven - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter light, \n",
      "labels2id[col] ElecMeterID(instance=9, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) light - [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Creating multilabels from meter microwave, \n",
      "labels2id[col] ElecMeterID(instance=11, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) microwave - [5. 5. 5. ... 0. 0. 0.]\n",
      "TIMING: Create multilabels from meters 0.27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df_taba1, train_metergroup_taba1, train_label2id_taba1 = setup_one_building(redd, appliances_redd1_taba, building, \n",
    "                                                                train_start_date, train_end_date, sample_period = 6)\n",
    "train_labels_df_taba1 = create_multilabels_from_meters(train_df_taba1, train_metergroup_taba1, train_label2id_taba1)\n",
    "\n",
    "test_df_taba1, test_metergroup_taba1, test_label2id_taba1 = setup_one_building(redd, appliances_redd1_taba, building, \n",
    "                                                                test_start_date, test_end_date, sample_period = 6)\n",
    "test_labels_df_taba1 = create_multilabels_from_meters(test_df_taba1, test_metergroup_taba1, test_label2id_taba1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3f708",
   "metadata": {},
   "source": [
    "#### Set up train and test data (house 1) for [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7d0cd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: read_selected_appliances() starts\n",
      "INFO: get_selected_metergroup() starts\n",
      "INFO: get_selected_metergroup() finished\n",
      "MeterGroup(meters=\n",
      "  ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "  ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "  ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "  ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "    ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "  ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      ")\n",
      "TIMING: 0.02\n",
      "\n",
      "Loading data for meter ElecMeterID(instance=4, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "INFO: read_selected_appliances() finished\n",
      "TIMING: 4.24\n",
      "\n",
      "DEBUG: Length of data of all loaded meters 411979\n",
      "INFO: Df columns before normalization Index([                     (7, 1, 'REDD'),\n",
      "                            (5, 1, 'REDD'),\n",
      "                            (1, 1, 'REDD'),\n",
      "                           (12, 1, 'REDD'),\n",
      "       (((3, 1, 'REDD'), (4, 1, 'REDD')),),\n",
      "                            (9, 1, 'REDD'),\n",
      "                           (11, 1, 'REDD')],\n",
      "      dtype='object')\n",
      "INFO: Labels before normalization ['Sockets', 'Fridge', 'Site meter', 'Unknown', 'Electric oven', 'Light', 'Microwave']\n",
      "INFO: sockets ~ Sockets (100%)\n",
      "INFO: fridge ~ Fridge (100%)\n",
      "INFO: unknown ~ Unknown (100%)\n",
      "INFO: electric oven ~ Electric oven (100%)\n",
      "INFO: light ~ Light (100%)\n",
      "INFO: microwave ~ Microwave (100%)\n",
      "INFO: Normalized labels ['sockets', 'fridge', 'Site meter', 'unknown', 'electric oven', 'light', 'microwave']\n",
      "DEBUG: Length of data of all loaded meters 411979\n",
      "INFO: Meters that have been loaded (all_df.columns):\n",
      "Index(['sockets', 'fridge', 'Site meter', 'unknown', 'electric oven', 'light',\n",
      "       'microwave'],\n",
      "      dtype='object')\n",
      "INFO: Creating multilabels from meter sockets, \n",
      "labels2id[col] ElecMeterID(instance=7, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) sockets - [ 0.  34.  34.5 ... 21.  21.5 21. ]\n",
      "INFO: Creating multilabels from meter fridge, \n",
      "labels2id[col] ElecMeterID(instance=5, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) fridge - [  0.    6.    6.  ... 199.  197.5 197.5]\n",
      "INFO: Creating multilabels from meter Site meter, \n",
      "labels2id[col] ElecMeterID(instance=1, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "DEBUG: Skipping Site meter - [225.28334045 222.60166931 222.67666626 ...   0.           0.\n",
      "   0.        ]\n",
      "INFO: Creating multilabels from meter unknown, \n",
      "labels2id[col] ElecMeterID(instance=12, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) unknown - [0. 1. 1. ... 1. 1. 1.]\n",
      "INFO: Creating multilabels from meter electric oven, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=3, building=1, dataset='REDD'), ElecMeterID(instance=4, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) electric oven - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter light, \n",
      "labels2id[col] ElecMeterID(instance=9, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) light - [ 0. 81. 81. ... 43. 43. 43.]\n",
      "INFO: Creating multilabels from meter microwave, \n",
      "labels2id[col] ElecMeterID(instance=11, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) microwave - [0. 5. 5. ... 4. 4. 4.]\n",
      "TIMING: Create multilabels from meters 1.03\n",
      "\n",
      "INFO: read_selected_appliances() starts\n",
      "INFO: get_selected_metergroup() starts\n",
      "INFO: get_selected_metergroup() finished\n",
      "MeterGroup(meters=\n",
      "  ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "  ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "  ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "  ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "    ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "  ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      ")\n",
      "TIMING: 0.03\n",
      "\n",
      "Loading data for meter ElecMeterID(instance=4, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "INFO: read_selected_appliances() finished\n",
      "TIMING: 1.29\n",
      "\n",
      "DEBUG: Length of data of all loaded meters 95971\n",
      "INFO: Df columns before normalization Index([                     (7, 1, 'REDD'),\n",
      "                            (5, 1, 'REDD'),\n",
      "                            (1, 1, 'REDD'),\n",
      "                           (12, 1, 'REDD'),\n",
      "       (((3, 1, 'REDD'), (4, 1, 'REDD')),),\n",
      "                            (9, 1, 'REDD'),\n",
      "                           (11, 1, 'REDD')],\n",
      "      dtype='object')\n",
      "INFO: Labels before normalization ['Sockets', 'Fridge', 'Site meter', 'Unknown', 'Electric oven', 'Light', 'Microwave']\n",
      "INFO: sockets ~ Sockets (100%)\n",
      "INFO: fridge ~ Fridge (100%)\n",
      "INFO: unknown ~ Unknown (100%)\n",
      "INFO: electric oven ~ Electric oven (100%)\n",
      "INFO: light ~ Light (100%)\n",
      "INFO: microwave ~ Microwave (100%)\n",
      "INFO: Normalized labels ['sockets', 'fridge', 'Site meter', 'unknown', 'electric oven', 'light', 'microwave']\n",
      "DEBUG: Length of data of all loaded meters 95971\n",
      "INFO: Meters that have been loaded (all_df.columns):\n",
      "Index(['sockets', 'fridge', 'Site meter', 'unknown', 'electric oven', 'light',\n",
      "       'microwave'],\n",
      "      dtype='object')\n",
      "INFO: Creating multilabels from meter sockets, \n",
      "labels2id[col] ElecMeterID(instance=7, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) sockets - [22. 22. 22. ...  0.  0.  0.]\n",
      "INFO: Creating multilabels from meter fridge, \n",
      "labels2id[col] ElecMeterID(instance=5, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) fridge - [7. 7. 7. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter Site meter, \n",
      "labels2id[col] ElecMeterID(instance=1, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "DEBUG: Skipping Site meter - [  0.           0.           0.         ... 235.17333984 235.08500671\n",
      " 235.25      ]\n",
      "INFO: Creating multilabels from meter unknown, \n",
      "labels2id[col] ElecMeterID(instance=12, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) unknown - [1. 1. 1. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter electric oven, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=3, building=1, dataset='REDD'), ElecMeterID(instance=4, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) electric oven - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter light, \n",
      "labels2id[col] ElecMeterID(instance=9, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) light - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter microwave, \n",
      "labels2id[col] ElecMeterID(instance=11, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) microwave - [5. 5. 5. ... 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMING: Create multilabels from meters 0.23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df_nalm1, train_metergroup_nalm1, train_label2id_nalm1 = setup_one_building(redd, appliances_redd1_nalm, building, \n",
    "                                                                train_start_date, train_end_date, sample_period = 6)\n",
    "train_labels_df_nalm1 = create_multilabels_from_meters(train_df_nalm1, train_metergroup_nalm1, train_label2id_nalm1)\n",
    "\n",
    "test_df_nalm1, test_metergroup_nalm1, test_label2id_nalm1 = setup_one_building(redd, appliances_redd1_nalm, building, \n",
    "                                                                test_start_date, test_end_date, sample_period = 6)\n",
    "test_labels_df_nalm1 = create_multilabels_from_meters(test_df_nalm1, test_metergroup_nalm1, test_label2id_nalm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f269b7",
   "metadata": {},
   "source": [
    "### Time series length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "63f58b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class TimeSeriesLength(Enum):\n",
    "    \"\"\"\n",
    "    The length of each segment of the time series, which will be used for inference.\n",
    "    \"\"\"\n",
    "    WINDOW_SAMPLE_PERIOD = 'same'\n",
    "    WINDOW_1_MIN = '1m'\n",
    "    WINDOW_5_MINS = '5m'\n",
    "    WINDOW_10_MINS = '10m'\n",
    "    WINDOW_30_MINS = '30m'\n",
    "    WINDOW_1_HOUR = '1h'\n",
    "    WINDOW_2_HOURS = '2h'\n",
    "    WINDOW_3_HOURS = '3h'\n",
    "    WINDOW_4_HOURS = '4h'\n",
    "    WINDOW_8_HOURS = '8h'\n",
    "    WINDOW_1_DAY = '1d'\n",
    "    WINDOW_1_WEEK = '1w'\n",
    "    \n",
    "def get_window(dt: TimeSeriesLength, sample_period) -> int:\n",
    "    choices = {TimeSeriesLength.WINDOW_SAMPLE_PERIOD: 1,\n",
    "               TimeSeriesLength.WINDOW_1_MIN        : get_no_of_samples_per_min(sample_period),\n",
    "               TimeSeriesLength.WINDOW_5_MINS       : get_no_of_samples_per_min(sample_period) * 5,\n",
    "               TimeSeriesLength.WINDOW_10_MINS      : get_no_of_samples_per_min(sample_period) * 10,\n",
    "               TimeSeriesLength.WINDOW_30_MINS      : get_no_of_samples_per_min(sample_period) * 30,\n",
    "               TimeSeriesLength.WINDOW_1_HOUR       : get_no_of_samples_per_hour(sample_period),\n",
    "               TimeSeriesLength.WINDOW_2_HOURS      : get_no_of_samples_per_hour(sample_period) * 2,\n",
    "               TimeSeriesLength.WINDOW_3_HOURS      : get_no_of_samples_per_hour(sample_period) * 3,\n",
    "               TimeSeriesLength.WINDOW_4_HOURS      : get_no_of_samples_per_hour(sample_period) * 4,\n",
    "               TimeSeriesLength.WINDOW_8_HOURS      : get_no_of_samples_per_hour(sample_period) * 8,\n",
    "               TimeSeriesLength.WINDOW_1_DAY        : get_no_of_samples_per_day(sample_period),\n",
    "               TimeSeriesLength.WINDOW_1_WEEK       : get_no_of_samples_per_day(sample_period) * 7\n",
    "              }\n",
    "    return int(choices.get(dt, 1))\n",
    "    \n",
    "def get_no_of_samples_per_min(sample_period):\n",
    "    \"\"\"\n",
    "    It returns the number of samples per minute. This depends also on the predefined sample period.\n",
    "    Returns:\n",
    "        An int representing the number of samples.\n",
    "    \"\"\"\n",
    "    return 60 / sample_period\n",
    "\n",
    "\n",
    "def get_no_of_samples_per_hour(sample_period):\n",
    "    \"\"\"\n",
    "    It returns the number of samples per hour. This depends also on the predefined sample period.\n",
    "    Returns:\n",
    "        An int representing the number of samples.\n",
    "    \"\"\"\n",
    "    return get_no_of_samples_per_min(sample_period) * 60\n",
    "\n",
    "\n",
    "def get_no_of_samples_per_day(sample_period):\n",
    "    \"\"\"\n",
    "    It returns the number of samples per day. This depends also on the predefined sample period.\n",
    "    Returns:\n",
    "        An int representing the number of samples.\n",
    "    \"\"\"\n",
    "    return get_no_of_samples_per_hour(sample_period) * 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c7e04",
   "metadata": {},
   "source": [
    "### Bucketize data / delay embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ffc8dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_data(data: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    It segments the time series grouping it into batches. Its segment is of size equal to the window.\n",
    "    Args:\n",
    "        data (ndarray): The given time series.\n",
    "        window (int): The size of the segments.\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    debug('bucketize_data: Initial shape {}'.format(data.shape))\n",
    "    n_dims = len(data.shape)\n",
    "\n",
    "    if n_dims == 1:\n",
    "        seq_in_batches = np.reshape(data, (int(len(data) / window), window))\n",
    "    elif n_dims == 2:\n",
    "        seq_in_batches = np.reshape(data, (int(len(data) / window), window, data.shape[1]))\n",
    "    else:\n",
    "        raise Exception('Invalid number of dimensions {}.'.format(n_dims))\n",
    "    debug('bucketize_data: Shape in batches: {}'.format(seq_in_batches.shape))\n",
    "    return seq_in_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c447f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_target(target: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Creates target data according to the lenght of the window of the segmented data.\n",
    "    Args:\n",
    "        target (ndarray): Target data with the original size.\n",
    "        window (int): The length of window that will be used to create the corresponding labels.\n",
    "    Returns:\n",
    "        The target data for the new bucketized time series.\n",
    "    \"\"\"\n",
    "    target_in_batches = bucketize_data(target, window)\n",
    "    any_multilabel = np.any(target_in_batches, axis=1)\n",
    "    debug('bucketize_target: Shape of array in windows: {}'.format(target_in_batches.shape))\n",
    "    debug('bucketize_target: Shape of array after merging windows: {}'.format(any_multilabel.shape))\n",
    "    return any_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0939b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def takens_embedding(series: np.ndarray, delay, dimension) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function returns the Takens embedding of data with delay into dimension,\n",
    "    delay*dimension must be < len(data)\n",
    "    \"\"\"\n",
    "    if delay * dimension > len(series):\n",
    "        info(f'Not enough data for the given delay ({delay}) and dimension ({dimension}).'\n",
    "             f'\\ndelay * dimension > len(data): {delay * dimension} > {len(series)}')\n",
    "        return series\n",
    "    delay_embedding = np.array([series[0:len(series) - delay * dimension]])\n",
    "    for i in range(1, dimension):\n",
    "        delay_embedding = np.append(delay_embedding,\n",
    "                                    [series[i * delay:len(series) - delay * (dimension - i)]], axis=0)\n",
    "    return delay_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51a21250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate(delay_in_seconds: int, dimension: int, sample_period: int, series_in_segments: np.ndarray, window: int = 1, should_fit: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    The time series is given as segments. For each segment we extract the delay embeddings.\n",
    "    \"\"\"\n",
    "    delay_items = int(delay_in_seconds / sample_period)\n",
    "    window_size = delay_items * dimension\n",
    "\n",
    "    if window_size > len(series_in_segments[0]):\n",
    "        raise Exception(\n",
    "            f'Not enough data for the given delay ({delay_in_seconds} seconds) and dimension ({dimension}).'\n",
    "            f'\\ndelay_items * dimension > len(data): {window_size} > {len(series_in_segments[0])}')\n",
    "\n",
    "    if window_size == len(series_in_segments[0]):\n",
    "        info(f\"TimeDelayEmbeddingAdapter is applied with delay embeddings equavalent to the length of each segment\"\n",
    "                f\" {window_size} == {len(series_in_segments[0])}\")\n",
    "\n",
    "    if window_size < len(series_in_segments[0]):\n",
    "        info(f\"TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each \"\n",
    "                f\"segment. {window_size} < {len(series_in_segments[0])}\")\n",
    "\n",
    "    delay_embeddings = []\n",
    "    for segment in series_in_segments:\n",
    "        embedding = takens_embedding(segment, delay_items, dimension)\n",
    "        delay_embeddings.append(embedding)\n",
    "    return np.asarray(delay_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aaf910f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensions(data_in_batches: np.ndarray, window: int, sample_period: int,\n",
    "                      dimension: int, delay_in_seconds: int, should_fit: bool = True):\n",
    "    \"\"\"\n",
    "    It uses the method approximate of the TimeSeriesTransformer in order to achieve dimensionality reduction.\n",
    "    Args:\n",
    "        data_in_batches (ndarray): The data of the time series separated in batches.\n",
    "        window (int): The size of the sub-segments of the given time series.\n",
    "            This is not supported by all algorithms.\n",
    "        target (ndarray): The labels that correspond to the given data in batches.\n",
    "        should_fit (bool): True if it is supported by the algorithm of the specified time series representation.\n",
    "    Returns:\n",
    "        The shortened time series as an array (ndarray).\n",
    "    \"\"\"\n",
    "    squeezed_seq = approximate(delay_in_seconds, dimension, sample_period = sample_period, \n",
    "                               series_in_segments = data_in_batches, window = window, should_fit = True)\n",
    "\n",
    "    debug('Shape of squeezed seq: {}'.format(squeezed_seq.shape))\n",
    "    return squeezed_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56cbfb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def _preprocess(data_df, labels_df, appliances, window_len, sample_period, \n",
    "                 dimension, delay_in_seconds, should_fit: bool = True):\n",
    "    start_time = time.time()\n",
    "    data = get_site_meter_data(data_df)\n",
    "    get_features_time = time.time() - start_time\n",
    "    timing(f\"get features time {get_features_time}\")\n",
    "\n",
    "    debug(f\"Features \\n {data[:10]}\")\n",
    "    target = get_multilabels(labels_df, appliances)\n",
    "    target = np.array(target.values)\n",
    "    debug(f\"Target \\n {target[:10]}\")\n",
    "    window = get_window(window_len, sample_period)\n",
    "    rem = len(data) % window\n",
    "    if rem > 0:\n",
    "        data = data[:-rem]\n",
    "        target = target[:-rem]\n",
    "    target = bucketize_target(target, window)\n",
    "    data = bucketize_data(data, window)\n",
    "    # if representation_type == TransformerType.raw or representation_type == TransformerType.approximate:\n",
    "    #     pass\n",
    "    \n",
    "    start_time = time.time()\n",
    "    data = reduce_dimensions(data, window, sample_period, dimension, delay_in_seconds, should_fit)\n",
    "    reduce_dimensions_time = time.time() - start_time\n",
    "    timing(f\"reduce dimensions time {reduce_dimensions_time}\")\n",
    "\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8d74d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train(train_df, train_labels_df, sample_period, appliances: list, window_len : TimeSeriesLength,\n",
    "              dimension, delay_in_seconds):\n",
    "    \"\"\"\n",
    "    Train the algorithm for the specified appliances.\n",
    "    Args:\n",
    "        appliances (List): List of appliances to be recognized.\n",
    "        raw_data (bool): True if the experiment uses raw data without any time series representation.\n",
    "    Returns:\n",
    "        The preprocess and the fiting time.\n",
    "    \"\"\"\n",
    "    info(\"Prepossessing before training...\")\n",
    "    start_time = time.time()\n",
    "    data, target = _preprocess(train_df, train_labels_df, appliances, window_len, sample_period,\n",
    "                              dimension, delay_in_seconds)\n",
    "    preprocess_time = time.time() - start_time\n",
    "    timing(f\"preprocess time {preprocess_time}\")\n",
    "\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.reshape(data, (data.shape[0], data.shape[1] * data.shape[2]))\n",
    "    \n",
    "    return data, target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fba2a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_test(test_df, test_labels_df, sample_period, appliances: list, window_len : TimeSeriesLength,\n",
    "             dimension, delay_in_seconds):\n",
    "    \"\"\"\n",
    "    Runs a test using the specified appliances.\n",
    "    Args:\n",
    "        appliances (List): List of appliances to be recognized.\n",
    "        raw_data (bool): True if the experiment uses raw data without any time series representation.\n",
    "    Returns:\n",
    "        A tuple containing macro, micro, a report, preprocess and fiting time.\n",
    "    \"\"\"\n",
    "    \n",
    "    info(\"Prepossessing before testing...\")\n",
    "    start_time = time.time()\n",
    "    data, target = _preprocess(test_df, test_labels_df, appliances, window_len, sample_period,\n",
    "                              dimension, delay_in_seconds)\n",
    "    preprocess_time = time.time() - start_time\n",
    "    timing(f\"preprocess time {preprocess_time}\")\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.reshape(data, (data.shape[0], data.shape[1] * data.shape[2]))\n",
    "    \n",
    "    return data, target\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7052c0bf",
   "metadata": {},
   "source": [
    "### Comparison with existing multi-label NILM systems\n",
    "</br>\n",
    "According to the literature, the models proposed by <b>Tabatabaei et al. [1]</b> are often used as a strong baseline to evaluate state-of-the-art solutions. In time domain, the method that is used is time delay embeddings. It has two parameters: the time delay and the dimensions of the embeddings. I use the exact same time delay and dimension used in [1], <b>time delay of 32 seconds and dimension of 8</b>. The <b>sampling rate is 6s</b> for all houses in REDD, however, the window isn't specified in their paper.I run my experiment with <b>3 chosen windows: 1 hour, 2 hours, and 4 hours.</b> The authors didn't mention the number of appliances they have used in their experiments, so I use only the appliances mentioned in their paper. The appliances for <b>House 1 are oven, fridge, light, microwave, bath gfi, outlet, washer dryer</b>. The appliances for <b>House 3 are electronics, furnace, washer dryer, microwave, bath gfi, kitchen outlet</b>. \n",
    "\n",
    "\n",
    "\n",
    "Besides [1], <b>Nalmpantis et al. [2]</b> was proposed that they had a similar setup to [1] in their comparison. They found that the best time delay is determined to be <b>30 seconds and the best dimension equal to 6. The sampling rate is 6s for all houses in REDD, and the window is set to 5 minutes</b>. The appliances in <b>House 1 are oven, refrigerator, light, microwave, bath GFI and kitchen outlet. For House 3, the appliances are electronics, furnace, washer dryer, microwave, bath GFI and kitchen outlet</b>. I will run another experiment using the exact mentioned parameters and compare the result to [2].\n",
    "\n",
    "\n",
    "References: </br>\n",
    "[1] Tabatabaei, S. M., Dick, S., & Xu, W. (2016). Toward non-intrusive load monitoring via multi-label classification. IEEE Transactions on Smart Grid, 8(1), 26-40.\n",
    "\n",
    "[2] Nalmpantis, C., & Vrakas, D. (2020). On time series representations for multi-label NILM. Neural Computing and Applications, 32, 17275-17290."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328d2d0",
   "metadata": {},
   "source": [
    "### Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6a6b12ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts_len_5_min = TimeSeriesLength.WINDOW_5_MINS\n",
    "ts_len_1hr = TimeSeriesLength.WINDOW_1_HOUR\n",
    "ts_len_2hr = TimeSeriesLength.WINDOW_2_HOURS\n",
    "ts_len_4hr = TimeSeriesLength.WINDOW_4_HOURS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6c320",
   "metadata": {},
   "source": [
    "### Classifiers\n",
    "#### - MlkNN\n",
    "#### - Rakel\n",
    "\n",
    "<b>Note for MlkNN</b> </br>\n",
    "\n",
    "If you ran into error like I did : TypeError: __init__() takes 1 positional argument but 2 were given\n",
    ", you can try fix it this way\n",
    "* Uninstall the current sklearn version and install sklearn = 0.2.4\n",
    "* Locally by modifying L165 in _compute_cond from </br>\n",
    "self.knn_ = NearestNeighbors(self.k).fit(X)\n",
    "* to </br>\n",
    "self.knn_ = NearestNeighbors(n_neighbors=self.k).fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9eb0a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from skmultilearn.ensemble import RakelD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "classifier_MlkNN = MLkNN(ignore_first_neighbours=0, k=3, s=1.0)\n",
    "classifier_Rakel =RakelD(MLPClassifier(hidden_layer_sizes=(100, 100, 100), learning_rate='adaptive',\n",
    "                                 solver='adam'), labelset_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaba6f8",
   "metadata": {},
   "source": [
    "#### [1], house 1, 1 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b8189ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Prepossessing before training...\n",
      "TIMING: get features time 0.0\n",
      "\n",
      "DEBUG: Features \n",
      " [225.28334 222.60167 222.67667 222.35    222.58667 224.87833 223.71\n",
      " 224.68832 224.195   226.35   ]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['sockets', 'washer dryer', 'fridge', 'unknown', 'electric oven',\n",
      "       'light', 'microwave'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]]\n",
      "DEBUG: bucketize_data: Initial shape (411600, 7)\n",
      "DEBUG: bucketize_data: Shape in batches: (686, 600, 7)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (686, 600, 7)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (686, 7)\n",
      "DEBUG: bucketize_data: Initial shape (411600,)\n",
      "DEBUG: bucketize_data: Shape in batches: (686, 600)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 600\n",
      "DEBUG: Shape of squeezed seq: (686, 8, 560)\n",
      "TIMING: reduce dimensions time 0.030755043029785156\n",
      "\n",
      "TIMING: preprocess time 0.06188321113586426\n",
      "\n",
      "INFO: Prepossessing before testing...\n",
      "TIMING: get features time 0.0\n",
      "\n",
      "DEBUG: Features \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['sockets', 'washer dryer', 'fridge', 'unknown', 'electric oven',\n",
      "       'light', 'microwave'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "DEBUG: bucketize_data: Initial shape (95400, 7)\n",
      "DEBUG: bucketize_data: Shape in batches: (159, 600, 7)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (159, 600, 7)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (159, 7)\n",
      "DEBUG: bucketize_data: Initial shape (95400,)\n",
      "DEBUG: bucketize_data: Shape in batches: (159, 600)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 600\n",
      "DEBUG: Shape of squeezed seq: (159, 8, 560)\n",
      "TIMING: reduce dimensions time 0.015656232833862305\n",
      "\n",
      "TIMING: preprocess time 0.015656232833862305\n",
      "\n",
      "INFO: MlkNN report\n",
      "INFO: F1 macro 0.4230611392811247\n",
      "INFO: F1 micro 0.7583892617449665\n",
      "{'electric oven': {'precision': 1.0, 'recall': 0.06666666666666667, 'f1-score': 0.125, 'support': 15}, 'fridge': {'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1-score': 0.9806451612903225, 'support': 154}, 'light': {'precision': 0.6, 'recall': 0.08823529411764706, 'f1-score': 0.15384615384615385, 'support': 102}, 'microwave': {'precision': 0.7272727272727273, 'recall': 0.18181818181818182, 'f1-score': 0.2909090909090909, 'support': 44}, 'washer dryer': {'precision': 0.2, 'recall': 0.0625, 'f1-score': 0.09523809523809523, 'support': 16}, 'unknown': {'precision': 0.8181818181818182, 'recall': 0.1956521739130435, 'f1-score': 0.3157894736842105, 'support': 46}, 'sockets': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 159}, 'micro avg': {'precision': 0.946927374301676, 'recall': 0.6324626865671642, 'f1-score': 0.7583892617449665, 'support': 536}, 'macro avg': {'precision': 0.75997335997336, 'recall': 0.3688407576469323, 'f1-score': 0.4230611392811247, 'support': 536}, 'weighted avg': {'precision': 0.8546411300142642, 'recall': 0.6324626865671642, 'f1-score': 0.6649940071722025, 'support': 536}, 'samples avg': {'precision': 0.9623689727463314, 'recall': 0.688020365378856, 'f1-score': 0.7814696833564758, 'support': 536}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\skmultilearn\\cluster\\random.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(label_sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: RakelD report\n",
      "INFO: F1 macro 0.4435139046129949\n",
      "INFO: F1 micro 0.8201581027667985\n",
      "{'electric oven': {'precision': 0.3333333333333333, 'recall': 0.06666666666666667, 'f1-score': 0.1111111111111111, 'support': 15}, 'fridge': {'precision': 0.9683544303797469, 'recall': 0.9935064935064936, 'f1-score': 0.9807692307692308, 'support': 154}, 'light': {'precision': 0.6530612244897959, 'recall': 0.9411764705882353, 'f1-score': 0.7710843373493975, 'support': 102}, 'microwave': {'precision': 0.4, 'recall': 0.045454545454545456, 'f1-score': 0.0816326530612245, 'support': 44}, 'washer dryer': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 16}, 'unknown': {'precision': 1.0, 'recall': 0.08695652173913043, 'f1-score': 0.16, 'support': 46}, 'sockets': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 159}, 'micro avg': {'precision': 0.8718487394957983, 'recall': 0.7742537313432836, 'f1-score': 0.8201581027667985, 'support': 536}, 'macro avg': {'precision': 0.6221069983146965, 'recall': 0.4476800997078673, 'f1-score': 0.4435139046129949, 'support': 536}, 'weighted avg': {'precision': 0.8271246775679855, 'recall': 0.7742537313432836, 'f1-score': 0.7487081480400386, 'support': 536}, 'samples avg': {'precision': 0.8721174004192873, 'recall': 0.8426175501647201, 'f1-score': 0.8338424678047319, 'support': 536}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sample_period = 6\n",
    "dimension = 8\n",
    "delay_in_seconds = 32\n",
    "train_data, train_target = prep_train(train_df_taba1, train_labels_df_taba1, sample_period, \n",
    "                                      appliances_redd1_taba, ts_len_1hr, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_taba1, test_labels_df_taba1, sample_period, \n",
    "                                   appliances_redd1_taba, ts_len_1hr, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_1hr = classification_report(test_target, predictions_nn, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_mlknn_1hr)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_1hr = classification_report(test_target, predictions_rak, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_rakeld_1hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a3a6c6",
   "metadata": {},
   "source": [
    "#### [1], house 1, 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "02f56898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Prepossessing before training...\n",
      "TIMING: get features time 0.00024700164794921875\n",
      "\n",
      "DEBUG: Features \n",
      " [225.28334 222.60167 222.67667 222.35    222.58667 224.87833 223.71\n",
      " 224.68832 224.195   226.35   ]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['sockets', 'washer dryer', 'fridge', 'unknown', 'electric oven',\n",
      "       'light', 'microwave'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]]\n",
      "DEBUG: bucketize_data: Initial shape (411600, 7)\n",
      "DEBUG: bucketize_data: Shape in batches: (343, 1200, 7)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (343, 1200, 7)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (343, 7)\n",
      "DEBUG: bucketize_data: Initial shape (411600,)\n",
      "DEBUG: bucketize_data: Shape in batches: (343, 1200)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 1200\n",
      "DEBUG: Shape of squeezed seq: (343, 8, 1160)\n",
      "TIMING: reduce dimensions time 0.03093552589416504\n",
      "\n",
      "TIMING: preprocess time 0.050293922424316406\n",
      "\n",
      "INFO: Prepossessing before testing...\n",
      "TIMING: get features time 0.0\n",
      "\n",
      "DEBUG: Features \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['sockets', 'washer dryer', 'fridge', 'unknown', 'electric oven',\n",
      "       'light', 'microwave'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "DEBUG: bucketize_data: Initial shape (94800, 7)\n",
      "DEBUG: bucketize_data: Shape in batches: (79, 1200, 7)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (79, 1200, 7)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (79, 7)\n",
      "DEBUG: bucketize_data: Initial shape (94800,)\n",
      "DEBUG: bucketize_data: Shape in batches: (79, 1200)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 1200\n",
      "DEBUG: Shape of squeezed seq: (79, 8, 1160)\n",
      "TIMING: reduce dimensions time 0.015697717666625977\n",
      "\n",
      "TIMING: preprocess time 0.015697717666625977\n",
      "\n",
      "INFO: MlkNN report\n",
      "INFO: F1 macro 0.472108843537415\n",
      "INFO: F1 micro 0.8036363636363636\n",
      "{'electric oven': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}, 'fridge': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 79}, 'light': {'precision': 0.7702702702702703, 'recall': 0.9661016949152542, 'f1-score': 0.8571428571428571, 'support': 59}, 'microwave': {'precision': 0.6666666666666666, 'recall': 0.0625, 'f1-score': 0.11428571428571428, 'support': 32}, 'washer dryer': {'precision': 0.4, 'recall': 0.15384615384615385, 'f1-score': 0.2222222222222222, 'support': 13}, 'unknown': {'precision': 0.6666666666666666, 'recall': 0.06060606060606061, 'f1-score': 0.1111111111111111, 'support': 33}, 'sockets': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 79}, 'micro avg': {'precision': 0.9094650205761317, 'recall': 0.7198697068403909, 'f1-score': 0.8036363636363636, 'support': 307}, 'macro avg': {'precision': 0.6433719433719433, 'recall': 0.46329341562392407, 'f1-score': 0.472108843537415, 'support': 307}, 'weighted avg': {'precision': 0.8207794113331572, 'recall': 0.7198697068403909, 'f1-score': 0.7126518794271236, 'support': 307}, 'samples avg': {'precision': 0.9145569620253164, 'recall': 0.788456901748041, 'f1-score': 0.8259985443529747, 'support': 307}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\skmultilearn\\cluster\\random.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(label_sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: RakelD report\n",
      "INFO: F1 macro 0.4030126190527193\n",
      "INFO: F1 micro 0.7258064516129031\n",
      "{'electric oven': {'precision': 1.0, 'recall': 0.08333333333333333, 'f1-score': 0.15384615384615385, 'support': 12}, 'fridge': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 79}, 'light': {'precision': 0.7272727272727273, 'recall': 0.2711864406779661, 'f1-score': 0.39506172839506176, 'support': 59}, 'microwave': {'precision': 0.6666666666666666, 'recall': 0.0625, 'f1-score': 0.11428571428571428, 'support': 32}, 'washer dryer': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, 'unknown': {'precision': 0.6, 'recall': 0.09090909090909091, 'f1-score': 0.15789473684210525, 'support': 33}, 'sockets': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 79}, 'micro avg': {'precision': 0.9523809523809523, 'recall': 0.5863192182410424, 'f1-score': 0.7258064516129031, 'support': 307}, 'macro avg': {'precision': 0.7134199134199134, 'recall': 0.3582755521314843, 'f1-score': 0.4030126190527193, 'support': 307}, 'weighted avg': {'precision': 0.8274997532326523, 'recall': 0.5863192182410424, 'f1-score': 0.6254803420012861, 'support': 307}, 'samples avg': {'precision': 0.9662447257383967, 'recall': 0.6473176612417119, 'f1-score': 0.7441639232778473, 'support': 307}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sample_period = 6\n",
    "dimension = 8\n",
    "delay_in_seconds = 32\n",
    "train_data, train_target = prep_train(train_df_taba1, train_labels_df_taba1, sample_period, \n",
    "                                      appliances_redd1_taba, ts_len_2hr, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_taba1, test_labels_df_taba1, sample_period, \n",
    "                                   appliances_redd1_taba, ts_len_2hr, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_2hr = classification_report(test_target, predictions_nn, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_mlknn_2hr)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_2hr = classification_report(test_target, predictions_rak, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_rakeld_2hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb913dc",
   "metadata": {},
   "source": [
    "#### [1], house 1, 4 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1d4a4353",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Prepossessing before training...\n",
      "TIMING: get features time 0.0\n",
      "\n",
      "DEBUG: Features \n",
      " [225.28334 222.60167 222.67667 222.35    222.58667 224.87833 223.71\n",
      " 224.68832 224.195   226.35   ]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['sockets', 'washer dryer', 'fridge', 'unknown', 'electric oven',\n",
      "       'light', 'microwave'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]]\n",
      "DEBUG: bucketize_data: Initial shape (410400, 7)\n",
      "DEBUG: bucketize_data: Shape in batches: (171, 2400, 7)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (171, 2400, 7)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (171, 7)\n",
      "DEBUG: bucketize_data: Initial shape (410400,)\n",
      "DEBUG: bucketize_data: Shape in batches: (171, 2400)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 2400\n",
      "DEBUG: Shape of squeezed seq: (171, 8, 2360)\n",
      "TIMING: reduce dimensions time 0.019517183303833008\n",
      "\n",
      "TIMING: preprocess time 0.04106879234313965\n",
      "\n",
      "INFO: Prepossessing before testing...\n",
      "TIMING: get features time 0.0\n",
      "\n",
      "DEBUG: Features \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['sockets', 'washer dryer', 'fridge', 'unknown', 'electric oven',\n",
      "       'light', 'microwave'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "DEBUG: bucketize_data: Initial shape (93600, 7)\n",
      "DEBUG: bucketize_data: Shape in batches: (39, 2400, 7)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (39, 2400, 7)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (39, 7)\n",
      "DEBUG: bucketize_data: Initial shape (93600,)\n",
      "DEBUG: bucketize_data: Shape in batches: (39, 2400)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 2400\n",
      "DEBUG: Shape of squeezed seq: (39, 8, 2360)\n",
      "TIMING: reduce dimensions time 0.0\n",
      "\n",
      "TIMING: preprocess time 0.004495859146118164\n",
      "\n",
      "INFO: MlkNN report\n",
      "INFO: F1 macro 0.6324242348904855\n",
      "INFO: F1 micro 0.8539944903581267\n",
      "{'electric oven': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, 'fridge': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 39}, 'light': {'precision': 0.8717948717948718, 'recall': 1.0, 'f1-score': 0.9315068493150686, 'support': 34}, 'microwave': {'precision': 0.7, 'recall': 0.7777777777777778, 'f1-score': 0.7368421052631577, 'support': 27}, 'washer dryer': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 9}, 'unknown': {'precision': 0.7333333333333333, 'recall': 0.7857142857142857, 'f1-score': 0.7586206896551724, 'support': 28}, 'sockets': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 39}, 'micro avg': {'precision': 0.8757062146892656, 'recall': 0.8333333333333334, 'f1-score': 0.8539944903581267, 'support': 186}, 'macro avg': {'precision': 0.6150183150183149, 'recall': 0.6519274376417233, 'f1-score': 0.6324242348904855, 'support': 186}, 'weighted avg': {'precision': 0.7907223600771988, 'recall': 0.8333333333333334, 'f1-score': 0.8107921990815184, 'support': 186}, 'samples avg': {'precision': 0.8803418803418804, 'recall': 0.8637973137973137, 'f1-score': 0.8464516964516964, 'support': 186}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\skmultilearn\\cluster\\random.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(label_sets)\n",
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: RakelD report\n",
      "INFO: F1 macro 0.410242982823628\n",
      "INFO: F1 micro 0.6666666666666667\n",
      "{'electric oven': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, 'fridge': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 39}, 'light': {'precision': 0.8, 'recall': 0.23529411764705882, 'f1-score': 0.3636363636363636, 'support': 34}, 'microwave': {'precision': 1.0, 'recall': 0.14814814814814814, 'f1-score': 0.25806451612903225, 'support': 27}, 'washer dryer': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 9}, 'unknown': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 28}, 'sockets': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 39}, 'micro avg': {'precision': 0.9791666666666666, 'recall': 0.5053763440860215, 'f1-score': 0.6666666666666667, 'support': 186}, 'macro avg': {'precision': 0.6857142857142857, 'recall': 0.3608999155217643, 'f1-score': 0.410242982823628, 'support': 186}, 'weighted avg': {'precision': 0.8612903225806451, 'recall': 0.5053763440860215, 'f1-score': 0.5609213887049475, 'support': 186}, 'samples avg': {'precision': 0.9863247863247862, 'recall': 0.5409645909645909, 'f1-score': 0.6754948754948756, 'support': 186}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sample_period = 6\n",
    "dimension = 8\n",
    "delay_in_seconds = 32\n",
    "train_data, train_target = prep_train(train_df_taba1, train_labels_df_taba1, sample_period, \n",
    "                                      appliances_redd1_taba, ts_len_4hr, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_taba1, test_labels_df_taba1, sample_period, \n",
    "                                   appliances_redd1_taba, ts_len_4hr, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_4hr = classification_report(test_target, predictions_nn, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_mlknn_4hr)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_4hr = classification_report(test_target, predictions_rak, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_rakeld_4hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a43cf96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nilmtk-env)",
   "language": "python",
   "name": "nilmtk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
