{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "938b4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilmtk as nilmtk\n",
    "from nilmtk import DataSet, MeterGroup, Appliance\n",
    "from nilmtk.metergroup import MeterGroupID\n",
    "from nilmtk.elecmeter import ElecMeter, ElecMeterID \n",
    "from typing import List, Tuple, Dict\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "#REDD = os.path.join(dirname, r\"datasource\\dataset\\REDD\\redd.h5\")\n",
    "redd = DataSet('redd.h5')\n",
    "SITE_METER = 'Site meter'\n",
    "year = '2011'\n",
    "train_month_end = '5'\n",
    "train_month_start = '4'\n",
    "train_end_date = \"{}-17-{}\".format(train_month_end, year)\n",
    "train_start_date = \"{}-18-{}\".format(train_month_start, year)\n",
    "test_month_end = '5'\n",
    "test_month_start = '5'\n",
    "test_end_date = \"{}-25-{}\".format(test_month_end, year)\n",
    "test_start_date = \"{}-18-{}\".format(test_month_start, year)\n",
    "appliances_redd1 = ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
    "building = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c95ea785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(t: str):\n",
    "    print('TIMING: ' + t)\n",
    "    print()\n",
    "\n",
    "    \n",
    "def info(i: str):\n",
    "    print('INFO: ' + i)\n",
    "    \n",
    "def debug(d):\n",
    "    print('DEBUG: ' + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d99a2",
   "metadata": {},
   "source": [
    "## Read data using nilmtk\n",
    "* Read selected data\n",
    "* Label data\n",
    "* Bucketize data (delay embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ae4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_metergroup(dataset: DataSet, building: int, appliances: List,  start: str, end: str, \n",
    "                               sample_period = 3, include_mains=True):\n",
    "    \"\"\"\n",
    "    Get the MeterGroup of selected appliances\n",
    "    Return the MeterGroup\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_selected_metergroup() starts')\n",
    "    dataset.set_window(start=start, end=end)\n",
    "    elec = dataset.buildings[building].elec\n",
    "    appliances_with_one_meter = []\n",
    "    appliances_with_more_meters = []\n",
    "    for appliance in appliances:\n",
    "        metergroup = elec.select_using_appliances(type=appliances)\n",
    "        if len(metergroup.meters) > 1:\n",
    "            appliances_with_more_meters.append(appliance)\n",
    "        else:\n",
    "            appliances_with_one_meter.append(appliance)\n",
    "\n",
    "    special_metergroup = None\n",
    "    for appliance in appliances_with_more_meters:\n",
    "        inst = 1\n",
    "        if appliance == 'sockets' and building == 3:\n",
    "            inst = 4\n",
    "        if special_metergroup is None:\n",
    "            special_metergroup = elec.select_using_appliances(type=appliance, instance=inst)\n",
    "        else:\n",
    "            special_metergroup = special_metergroup.union(elec.select_using_appliances(type=appliance, instance=1))\n",
    "\n",
    "    selected_metergroup = elec.select_using_appliances(type=appliances_with_one_meter)\n",
    "    selected_metergroup = selected_metergroup.union(special_metergroup)\n",
    "    if include_mains:\n",
    "        mains_meter = dataset.buildings[building].elec.mains()\n",
    "        if isinstance(mains_meter, MeterGroup):\n",
    "            if len(mains_meter.meters) > 1:\n",
    "                mains_meter = mains_meter.meters[0]\n",
    "                mains_metergroup = MeterGroup(meters=[mains_meter])\n",
    "            else:\n",
    "                mains_metergroup = mains_meter\n",
    "        else:\n",
    "            mains_metergroup = MeterGroup(meters=[mains_meter])\n",
    "        selected_metergroup = selected_metergroup.union(mains_metergroup)\n",
    "    info('get_selected_metergroup() finished')\n",
    "    print(selected_metergroup)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "    return selected_metergroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3af49e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_selected_appliances(dataset: DataSet, building: int, appliances : List, start: str, end: str, include_mains,\n",
    "                               sample_period = 3):\n",
    "    \"\"\"\n",
    "    Read and fill in missing values of selected appliances in a given bulding\n",
    "    Return the DataFrame of selected appliances in which columns are ElecMeter IDs,\n",
    "    and values are the PC of the meter in given sample period\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('read_selected_appliances() starts')\n",
    "    selected_metergroup = get_selected_metergroup(dataset, building, appliances, start, end,sample_period,include_mains)\n",
    "    df = selected_metergroup.dataframe_of_meters(sample_period=sample_period)\n",
    "    df.fillna(0, inplace=True)\n",
    "    info('read_selected_appliances() finished')\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "    return df, selected_metergroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a08373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_meters(dataset: DataSet, building: int, start_date: str, end_date:str, sample_period = 3):\n",
    "    \"\"\"\n",
    "    Read all the meters in given building\n",
    "    \"\"\"\n",
    "    elec = dataset.buildings[building].elec\n",
    "    print(elec)\n",
    "    #redd_datasource = Datasource(redd, \"REDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86957733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_df(df: DataFrame, selected_metergroup: MeterGroup) -> [List, Dict]:\n",
    "    \"\"\"\n",
    "    Returns two lists, one is a list of labels which describes DataFrame columns\n",
    "    Other is a list of power threshold of each appliances\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_labels_df() starts')\n",
    "    lst = []\n",
    "    threshold = {}\n",
    "    for m in df.columns:\n",
    "        label = \"\"\n",
    "        if isinstance(m,MeterGroupID):\n",
    "            tup_elecmeterID = m[0]\n",
    "            lst_elecmeterID = list(tup_elecmeterID)\n",
    "            #get meter group using list of ElecMeterIDs\n",
    "            mg = selected_metergroup[lst_elecmeterID]\n",
    "            #get labels of meter group\n",
    "            labels = mg.get_labels(lst_elecmeterID)\n",
    "            label = labels[0]\n",
    "            threshold[label] =mg.on_power_threshold()\n",
    "        else:\n",
    "            #get ElecMeter using ElecMeterID\n",
    "            elec_meter = selected_metergroup[m]\n",
    "            #get labels of ElecMeter\n",
    "            label = elec_meter.label()\n",
    "            threshold[label] = elec_meter.on_power_threshold()\n",
    "        lst += [label]\n",
    "    info('get_labels_df() finished')\n",
    "    print(lst)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "        \n",
    "    return lst, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77703d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dic_real_power(df: DataFrame, labels: List) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns a Dictionary in which key is name of the appliance, and value is the power consumption the appliance\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_dic_real_power() starts')\n",
    "    Dict = {}\n",
    "    lst = []\n",
    "    for k, v in df.items():\n",
    "        lst += [v]\n",
    "        \n",
    "    for i in range(len(labels)):\n",
    "        Dict[labels[i]] = lst[i]\n",
    "    info('get_dic_real_power() finished')\n",
    "    print(Dict)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))    \n",
    "    return Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10510e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dic_labeled_power(RealPower: Dict, threshold: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns a Dictionary in which key is name of the appliance, and value is \n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_dic_labeled_power() starts')\n",
    "    LabeledPower = {}\n",
    "    for appliance, real_power in RealPower.items():\n",
    "        if appliance != 'Site meter':\n",
    "            arr = create_labels(real_power, threshold[appliance])\n",
    "            LabeledPower[appliance] = arr\n",
    "    info('get_dic_labeled_power() finished')\n",
    "    print(LabeledPower)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "    return LabeledPower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4b38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(array, threshold):\n",
    "    res = np.empty(array.shape)\n",
    "    for i in range(len(array)):\n",
    "        if array[i] >= threshold:\n",
    "            res[i] = 1\n",
    "        else:\n",
    "            res[i] = 0\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "217df2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def normalize_columns(df: DataFrame, meter_group: MeterGroup, appliance_names: List[str]) -> Tuple[DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    It normalizes the names of the columns for compatibility.\n",
    "    Args:\n",
    "        df (DataFrame):\n",
    "        meter_group (MeterGroup):\n",
    "        appliance_names (List[str]):\n",
    "    Returns:\n",
    "        A tuple with a DataFrame and a dictionary mapping labels to ids.\n",
    "    \"\"\"\n",
    "    labels = meter_group.get_labels(df.columns)\n",
    "    normalized_labels = []\n",
    "    info(f\"Df columns before normalization {df.columns}\")\n",
    "    info(f\"Labels before normalization {labels}\")\n",
    "\n",
    "    for label in labels:\n",
    "        if label == SITE_METER and SITE_METER not in appliance_names:\n",
    "            normalized_labels.append(SITE_METER)\n",
    "            continue\n",
    "        for name in appliance_names:\n",
    "            ratio = fuzz.ratio(label.lower().replace('electric', \"\").lstrip().rstrip().split()[0],\n",
    "                                   name.lower().replace('electric', \"\").lstrip().rstrip().split()[0])\n",
    "            if ratio > 90:\n",
    "                info(f\"{name} ~ {label} ({ratio}%)\")\n",
    "                normalized_labels.append(name)\n",
    "    if len(normalized_labels) != len(labels):\n",
    "        debug(f\"len(normalized_labels) {len(normalized_labels)} != len(labels) {len(labels)}\")\n",
    "        raise LabelNormalizationError()\n",
    "    label2id = {l: i for l, i in zip(normalized_labels, df.columns)}\n",
    "    df.columns = normalized_labels\n",
    "    info(f\"Normalized labels {normalized_labels}\")\n",
    "    return df, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e55534e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_site_meter_data(df: DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the data of the site meter from the given DataFrame.\n",
    "    Args:\n",
    "        df (DataFrame): A DataFrame containing energy data with columns corresponding to different meters.\n",
    "    Returns:\n",
    "        The site meter data as an array (ndarray).\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if SITE_METER in col:\n",
    "            return df[col].values\n",
    "    raise NoSiteMeterException(\"Couldn' t find site meter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "785ec9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multilabels(labels_df: DataFrame, appliances: List = None) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Get the labels of the specified appliances.\n",
    "    Args:\n",
    "        labels_df (DataFrame):\n",
    "        appliances (List):\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    debug(f\"get_multilabels  labels_df.columns {labels_df.columns}\")\n",
    "    debug(f\"get_multilabels  appliances {appliances}\")\n",
    "    if appliances is None:\n",
    "        return labels_df\n",
    "    else:\n",
    "        return labels_df[appliances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d32476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_one_building(dataset: DataSet, appliances, building, start, end, sample_period) -> (pd.DataFrame, MeterGroup, Dict, Dict):\n",
    "    all_df, metergroup = read_selected_appliances(dataset = dataset, building = building, \n",
    "                                                 appliances = appliances, start = start, end = end, include_mains = True, sample_period = sample_period )\n",
    "    debug(f\"Length of data of all loaded meters {len(all_df)}\")\n",
    "    all_df, label2id = normalize_columns(all_df, metergroup, appliances)\n",
    "    debug(f\"Length of data of all loaded meters {len(all_df)}\")\n",
    "    info('Meters that have been loaded (all_df.columns):\\n' + str(all_df.columns))\n",
    "    \n",
    "    \n",
    "    return all_df, metergroup, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceb40d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multilabels_from_meters(meters: DataFrame, meter_group: MeterGroup, labels2id: dict) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Creates multi labels from the given meter group using a dictionary as a lookup table.\n",
    "    Args:\n",
    "        meters (DataFrame):\n",
    "        meter_group (MeterGroup):\n",
    "        labels2id (dict):\n",
    "    Returns:\n",
    "        A DataFrame with the multi labels.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    labels = dict()\n",
    "    for col in meters.columns:\n",
    "        info(f\"Creating multilabels from meter {col}, \"\n",
    "             f\"\\nlabels2id[col] {labels2id[col]}\"\n",
    "             f\"\\nmetergroup[labels2id[col]] {meter_group[labels2id[col]]}\")\n",
    "        meter = meter_group[labels2id[col]]\n",
    "        threshold = meter.on_power_threshold()\n",
    "        vals = meters[col].values.astype(float)\n",
    "        if vals is None or col == SITE_METER:\n",
    "            debug(f\"Skipping {col} - {vals}\")\n",
    "            continue\n",
    "        debug(f\"meters[col].values.astype(float) {col} - {vals}\")\n",
    "        labels[col] = create_labels(vals, threshold)\n",
    "    timing('Create multilabels from meters {}'.format(round(time.time() - start_time, 2)))\n",
    "    return DataFrame(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15921bb4",
   "metadata": {},
   "source": [
    "#### Set up train data (REDD1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5daa2f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: read_selected_appliances() starts\n",
      "INFO: get_selected_metergroup() starts\n",
      "INFO: get_selected_metergroup() finished\n",
      "MeterGroup(meters=\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "    ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "    ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      "  ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "  ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "  ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "  ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      ")\n",
      "TIMING: 0.05\n",
      "\n",
      "Loading data for meter ElecMeterID(instance=20, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Loading data for meter ElecMeterID(instance=4, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "INFO: read_selected_appliances() finished\n",
      "TIMING: 5.86\n",
      "\n",
      "DEBUG: Length of data of all loaded meters 411979\n",
      "INFO: Df columns before normalization Index([(((10, 1, 'REDD'), (20, 1, 'REDD')),),\n",
      "                              (9, 1, 'REDD'),\n",
      "         (((3, 1, 'REDD'), (4, 1, 'REDD')),),\n",
      "                             (11, 1, 'REDD'),\n",
      "                             (12, 1, 'REDD'),\n",
      "                              (5, 1, 'REDD'),\n",
      "                              (7, 1, 'REDD'),\n",
      "                              (1, 1, 'REDD')],\n",
      "      dtype='object')\n",
      "INFO: Labels before normalization ['Washer dryer', 'Light', 'Electric oven', 'Microwave', 'Unknown', 'Fridge', 'Sockets', 'Site meter']\n",
      "INFO: washer dryer ~ Washer dryer (100%)\n",
      "INFO: light ~ Light (100%)\n",
      "INFO: electric oven ~ Electric oven (100%)\n",
      "INFO: microwave ~ Microwave (100%)\n",
      "INFO: unknown ~ Unknown (100%)\n",
      "INFO: fridge ~ Fridge (100%)\n",
      "INFO: sockets ~ Sockets (100%)\n",
      "INFO: Normalized labels ['washer dryer', 'light', 'electric oven', 'microwave', 'unknown', 'fridge', 'sockets', 'Site meter']\n",
      "DEBUG: Length of data of all loaded meters 411979\n",
      "INFO: Meters that have been loaded (all_df.columns):\n",
      "Index(['washer dryer', 'light', 'electric oven', 'microwave', 'unknown',\n",
      "       'fridge', 'sockets', 'Site meter'],\n",
      "      dtype='object')\n",
      "INFO: Creating multilabels from meter washer dryer, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=10, building=1, dataset='REDD'), ElecMeterID(instance=20, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) washer dryer - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter light, \n",
      "labels2id[col] ElecMeterID(instance=9, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) light - [ 0. 81. 81. ... 43. 43. 43.]\n",
      "INFO: Creating multilabels from meter electric oven, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=3, building=1, dataset='REDD'), ElecMeterID(instance=4, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) electric oven - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter microwave, \n",
      "labels2id[col] ElecMeterID(instance=11, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) microwave - [0. 5. 5. ... 4. 4. 4.]\n",
      "INFO: Creating multilabels from meter unknown, \n",
      "labels2id[col] ElecMeterID(instance=12, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) unknown - [0. 1. 1. ... 1. 1. 1.]\n",
      "INFO: Creating multilabels from meter fridge, \n",
      "labels2id[col] ElecMeterID(instance=5, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) fridge - [  0.    6.    6.  ... 199.  197.5 197.5]\n",
      "INFO: Creating multilabels from meter sockets, \n",
      "labels2id[col] ElecMeterID(instance=7, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) sockets - [ 0.  34.  34.5 ... 21.  21.5 21. ]\n",
      "INFO: Creating multilabels from meter Site meter, \n",
      "labels2id[col] ElecMeterID(instance=1, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "DEBUG: Skipping Site meter - [225.28334045 222.60166931 222.67666626 ...   0.           0.\n",
      "   0.        ]\n",
      "TIMING: Create multilabels from meters 1.17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df, train_metergroup, train_label2id = setup_one_building(redd, appliances_redd1, building, \n",
    "                                                                train_start_date, train_end_date, sample_period = 6)\n",
    "train_labels_df = create_multilabels_from_meters(train_df, train_metergroup, train_label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3f708",
   "metadata": {},
   "source": [
    "#### Set up test data (REDD1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7d0cd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: read_selected_appliances() starts\n",
      "INFO: get_selected_metergroup() starts\n",
      "INFO: get_selected_metergroup() finished\n",
      "MeterGroup(meters=\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "    ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "    ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      "  ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "  ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "  ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "  ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      ")\n",
      "TIMING: 0.04\n",
      "\n",
      "Loading data for meter ElecMeterID(instance=20, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Loading data for meter ElecMeterID(instance=4, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "INFO: read_selected_appliances() finished\n",
      "TIMING: 2.02\n",
      "\n",
      "DEBUG: Length of data of all loaded meters 95971\n",
      "INFO: Df columns before normalization Index([(((10, 1, 'REDD'), (20, 1, 'REDD')),),\n",
      "                              (9, 1, 'REDD'),\n",
      "         (((3, 1, 'REDD'), (4, 1, 'REDD')),),\n",
      "                             (11, 1, 'REDD'),\n",
      "                             (12, 1, 'REDD'),\n",
      "                              (5, 1, 'REDD'),\n",
      "                              (7, 1, 'REDD'),\n",
      "                              (1, 1, 'REDD')],\n",
      "      dtype='object')\n",
      "INFO: Labels before normalization ['Washer dryer', 'Light', 'Electric oven', 'Microwave', 'Unknown', 'Fridge', 'Sockets', 'Site meter']\n",
      "INFO: washer dryer ~ Washer dryer (100%)\n",
      "INFO: light ~ Light (100%)\n",
      "INFO: electric oven ~ Electric oven (100%)\n",
      "INFO: microwave ~ Microwave (100%)\n",
      "INFO: unknown ~ Unknown (100%)\n",
      "INFO: fridge ~ Fridge (100%)\n",
      "INFO: sockets ~ Sockets (100%)\n",
      "INFO: Normalized labels ['washer dryer', 'light', 'electric oven', 'microwave', 'unknown', 'fridge', 'sockets', 'Site meter']\n",
      "DEBUG: Length of data of all loaded meters 95971\n",
      "INFO: Meters that have been loaded (all_df.columns):\n",
      "Index(['washer dryer', 'light', 'electric oven', 'microwave', 'unknown',\n",
      "       'fridge', 'sockets', 'Site meter'],\n",
      "      dtype='object')\n",
      "INFO: Creating multilabels from meter washer dryer, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=10, building=1, dataset='REDD'), ElecMeterID(instance=20, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) washer dryer - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter light, \n",
      "labels2id[col] ElecMeterID(instance=9, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) light - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter electric oven, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=3, building=1, dataset='REDD'), ElecMeterID(instance=4, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) electric oven - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter microwave, \n",
      "labels2id[col] ElecMeterID(instance=11, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=11, building=1, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) microwave - [5. 5. 5. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter unknown, \n",
      "labels2id[col] ElecMeterID(instance=12, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) unknown - [1. 1. 1. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter fridge, \n",
      "labels2id[col] ElecMeterID(instance=5, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) fridge - [7. 7. 7. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter sockets, \n",
      "labels2id[col] ElecMeterID(instance=7, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) sockets - [22. 22. 22. ...  0.  0.  0.]\n",
      "INFO: Creating multilabels from meter Site meter, \n",
      "labels2id[col] ElecMeterID(instance=1, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "DEBUG: Skipping Site meter - [  0.           0.           0.         ... 235.17333984 235.08500671\n",
      " 235.25      ]\n",
      "TIMING: Create multilabels from meters 0.27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df, test_metergroup, test_label2id = setup_one_building(redd, appliances_redd1, building, \n",
    "                                                                test_start_date, test_end_date, sample_period = 6)\n",
    "test_labels_df = create_multilabels_from_meters(test_df, test_metergroup, test_label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f269b7",
   "metadata": {},
   "source": [
    "### Time series length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce3135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "63f58b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class TimeSeriesLength(Enum):\n",
    "    \"\"\"\n",
    "    The length of each segment of the time series, which will be used for inference.\n",
    "    \"\"\"\n",
    "    WINDOW_SAMPLE_PERIOD = 'same'\n",
    "    WINDOW_1_MIN = '1m'\n",
    "    WINDOW_5_MINS = '5m'\n",
    "    WINDOW_10_MINS = '10m'\n",
    "    WINDOW_30_MINS = '30m'\n",
    "    WINDOW_1_HOUR = '1h'\n",
    "    WINDOW_2_HOURS = '2h'\n",
    "    WINDOW_3_HOURS = '3h'\n",
    "    WINDOW_4_HOURS = '4h'\n",
    "    WINDOW_8_HOURS = '8h'\n",
    "    WINDOW_1_DAY = '1d'\n",
    "    WINDOW_1_WEEK = '1w'\n",
    "    \n",
    "def get_window(dt: TimeSeriesLength, sample_period) -> int:\n",
    "    choices = {TimeSeriesLength.WINDOW_SAMPLE_PERIOD: 1,\n",
    "               TimeSeriesLength.WINDOW_1_MIN        : get_no_of_samples_per_min(sample_period),\n",
    "               TimeSeriesLength.WINDOW_5_MINS       : get_no_of_samples_per_min(sample_period) * 5,\n",
    "               TimeSeriesLength.WINDOW_10_MINS      : get_no_of_samples_per_min(sample_period) * 10,\n",
    "               TimeSeriesLength.WINDOW_30_MINS      : get_no_of_samples_per_min(sample_period) * 30,\n",
    "               TimeSeriesLength.WINDOW_1_HOUR       : get_no_of_samples_per_hour(sample_period),\n",
    "               TimeSeriesLength.WINDOW_2_HOURS      : get_no_of_samples_per_hour(sample_period) * 2,\n",
    "               TimeSeriesLength.WINDOW_3_HOURS      : get_no_of_samples_per_hour(sample_period) * 3,\n",
    "               TimeSeriesLength.WINDOW_4_HOURS      : get_no_of_samples_per_hour(sample_period) * 4,\n",
    "               TimeSeriesLength.WINDOW_8_HOURS      : get_no_of_samples_per_hour(sample_period) * 8,\n",
    "               TimeSeriesLength.WINDOW_1_DAY        : get_no_of_samples_per_day(sample_period),\n",
    "               TimeSeriesLength.WINDOW_1_WEEK       : get_no_of_samples_per_day(sample_period) * 7\n",
    "              }\n",
    "    return int(choices.get(dt, 1))\n",
    "    \n",
    "def get_no_of_samples_per_min(sample_period):\n",
    "    \"\"\"\n",
    "    It returns the number of samples per minute. This depends also on the predefined sample period.\n",
    "    Returns:\n",
    "        An int representing the number of samples.\n",
    "    \"\"\"\n",
    "    return 60 / sample_period\n",
    "\n",
    "\n",
    "def get_no_of_samples_per_hour(sample_period):\n",
    "    \"\"\"\n",
    "    It returns the number of samples per hour. This depends also on the predefined sample period.\n",
    "    Returns:\n",
    "        An int representing the number of samples.\n",
    "    \"\"\"\n",
    "    return get_no_of_samples_per_min(sample_period) * 60\n",
    "\n",
    "\n",
    "def get_no_of_samples_per_day(sample_period):\n",
    "    \"\"\"\n",
    "    It returns the number of samples per day. This depends also on the predefined sample period.\n",
    "    Returns:\n",
    "        An int representing the number of samples.\n",
    "    \"\"\"\n",
    "    return get_no_of_samples_per_hour(sample_period) * 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c7e04",
   "metadata": {},
   "source": [
    "### Bucketize data / delay embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ffc8dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_data(data: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    It segments the time series grouping it into batches. Its segment is of size equal to the window.\n",
    "    Args:\n",
    "        data (ndarray): The given time series.\n",
    "        window (int): The size of the segments.\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    debug('bucketize_data: Initial shape {}'.format(data.shape))\n",
    "    n_dims = len(data.shape)\n",
    "\n",
    "    if n_dims == 1:\n",
    "        seq_in_batches = np.reshape(data, (int(len(data) / window), window))\n",
    "    elif n_dims == 2:\n",
    "        seq_in_batches = np.reshape(data, (int(len(data) / window), window, data.shape[1]))\n",
    "    else:\n",
    "        raise Exception('Invalid number of dimensions {}.'.format(n_dims))\n",
    "    debug('bucketize_data: Shape in batches: {}'.format(seq_in_batches.shape))\n",
    "    return seq_in_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c447f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_target(target: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Creates target data according to the lenght of the window of the segmented data.\n",
    "    Args:\n",
    "        target (ndarray): Target data with the original size.\n",
    "        window (int): The length of window that will be used to create the corresponding labels.\n",
    "    Returns:\n",
    "        The target data for the new bucketized time series.\n",
    "    \"\"\"\n",
    "    target_in_batches = bucketize_data(target, window)\n",
    "    any_multilabel = np.any(target_in_batches, axis=1)\n",
    "    debug('bucketize_target: Shape of array in windows: {}'.format(target_in_batches.shape))\n",
    "    debug('bucketize_target: Shape of array after merging windows: {}'.format(any_multilabel.shape))\n",
    "    return any_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0939b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def takens_embedding(series: np.ndarray, delay, dimension) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function returns the Takens embedding of data with delay into dimension,\n",
    "    delay*dimension must be < len(data)\n",
    "    \"\"\"\n",
    "    if delay * dimension > len(series):\n",
    "        info(f'Not enough data for the given delay ({delay}) and dimension ({dimension}).'\n",
    "             f'\\ndelay * dimension > len(data): {delay * dimension} > {len(series)}')\n",
    "        return series\n",
    "    delay_embedding = np.array([series[0:len(series) - delay * dimension]])\n",
    "    for i in range(1, dimension):\n",
    "        delay_embedding = np.append(delay_embedding,\n",
    "                                    [series[i * delay:len(series) - delay * (dimension - i)]], axis=0)\n",
    "    return delay_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51a21250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate(delay_in_seconds: int, dimension: int, sample_period: int, series_in_segments: np.ndarray, window: int = 1, should_fit: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    The time series is given as segments. For each segment we extract the delay embeddings.\n",
    "    \"\"\"\n",
    "    delay_items = int(delay_in_seconds / sample_period)\n",
    "    window_size = delay_items * dimension\n",
    "\n",
    "    if window_size > len(series_in_segments[0]):\n",
    "        raise Exception(\n",
    "            f'Not enough data for the given delay ({delay_in_seconds} seconds) and dimension ({dimension}).'\n",
    "            f'\\ndelay_items * dimension > len(data): {window_size} > {len(series_in_segments[0])}')\n",
    "\n",
    "    if window_size == len(series_in_segments[0]):\n",
    "        info(f\"TimeDelayEmbeddingAdapter is applied with delay embeddings equavalent to the length of each segment\"\n",
    "                f\" {window_size} == {len(series_in_segments[0])}\")\n",
    "\n",
    "    if window_size < len(series_in_segments[0]):\n",
    "        info(f\"TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each \"\n",
    "                f\"segment. {window_size} < {len(series_in_segments[0])}\")\n",
    "\n",
    "    delay_embeddings = []\n",
    "    for segment in series_in_segments:\n",
    "        embedding = takens_embedding(segment, delay_items, dimension)\n",
    "        delay_embeddings.append(embedding)\n",
    "    return np.asarray(delay_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaf910f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensions(data_in_batches: np.ndarray, window: int, sample_period: int, should_fit: bool = True):\n",
    "    \"\"\"\n",
    "    It uses the method approximate of the TimeSeriesTransformer in order to achieve dimensionality reduction.\n",
    "    Args:\n",
    "        data_in_batches (ndarray): The data of the time series separated in batches.\n",
    "        window (int): The size of the sub-segments of the given time series.\n",
    "            This is not supported by all algorithms.\n",
    "        target (ndarray): The labels that correspond to the given data in batches.\n",
    "        should_fit (bool): True if it is supported by the algorithm of the specified time series representation.\n",
    "    Returns:\n",
    "        The shortened time series as an array (ndarray).\n",
    "    \"\"\"\n",
    "    squeezed_seq = approximate(delay_in_seconds = 32, dimension = 8, sample_period = sample_period, \n",
    "                               series_in_segments = data_in_batches, window = window, should_fit = True)\n",
    "\n",
    "    debug('Shape of squeezed seq: {}'.format(squeezed_seq.shape))\n",
    "    return squeezed_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56cbfb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def _preprocess(data_df, labels_df, appliances, window_len, sample_period, should_fit: bool = True):\n",
    "    start_time = time.time()\n",
    "    data = get_site_meter_data(data_df)\n",
    "    get_features_time = time.time() - start_time\n",
    "    timing(f\"get features time {get_features_time}\")\n",
    "\n",
    "    debug(f\"Features \\n {data[:10]}\")\n",
    "    target = get_multilabels(labels_df, appliances)\n",
    "    target = np.array(target.values)\n",
    "    debug(f\"Target \\n {target[:10]}\")\n",
    "    window = get_window(window_len, sample_period)\n",
    "    rem = len(data) % window\n",
    "    if rem > 0:\n",
    "        data = data[:-rem]\n",
    "        target = target[:-rem]\n",
    "    target = bucketize_target(target, window)\n",
    "    data = bucketize_data(data, window)\n",
    "    # if representation_type == TransformerType.raw or representation_type == TransformerType.approximate:\n",
    "    #     pass\n",
    "    \n",
    "    start_time = time.time()\n",
    "    data = reduce_dimensions(data, window, sample_period,should_fit)\n",
    "    reduce_dimensions_time = time.time() - start_time\n",
    "    timing(f\"reduce dimensions time {reduce_dimensions_time}\")\n",
    "\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8d74d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train(train_df, train_labels_df, sample_period, appliances: list, window_len : TimeSeriesLength):\n",
    "    \"\"\"\n",
    "    Train the algorithm for the specified appliances.\n",
    "    Args:\n",
    "        appliances (List): List of appliances to be recognized.\n",
    "        raw_data (bool): True if the experiment uses raw data without any time series representation.\n",
    "    Returns:\n",
    "        The preprocess and the fiting time.\n",
    "    \"\"\"\n",
    "    info(\"Prepossessing before training...\")\n",
    "    start_time = time.time()\n",
    "    data, target = _preprocess(train_df, train_labels_df, appliances, window_len, sample_period)\n",
    "    preprocess_time = time.time() - start_time\n",
    "    timing(f\"preprocess time {preprocess_time}\")\n",
    "\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.reshape(data, (data.shape[0], data.shape[1] * data.shape[2]))\n",
    "    \n",
    "    return data, target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fba2a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_test(test_df, test_labels_df, sample_period, appliances: list, window_len : TimeSeriesLength):\n",
    "    \"\"\"\n",
    "    Runs a test using the specified appliances.\n",
    "    Args:\n",
    "        appliances (List): List of appliances to be recognized.\n",
    "        raw_data (bool): True if the experiment uses raw data without any time series representation.\n",
    "    Returns:\n",
    "        A tuple containing macro, micro, a report, preprocess and fiting time.\n",
    "    \"\"\"\n",
    "    \n",
    "    info(\"Prepossessing before testing...\")\n",
    "    start_time = time.time()\n",
    "    data, target = _preprocess(test_df, test_labels_df, appliances, window_len, sample_period)\n",
    "    preprocess_time = time.time() - start_time\n",
    "    timing(f\"preprocess time {preprocess_time}\")\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.reshape(data, (data.shape[0], data.shape[1] * data.shape[2]))\n",
    "    \n",
    "    return data, target\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb9efc",
   "metadata": {},
   "source": [
    "### Comparison with existing multi-label NILM systems\n",
    "</br>\n",
    "According to the literature, the models proposed by <b>Tabatabaei et al. [1]</b> are often used as a strong baseline to evaluate state-of-the-art solutions. In time domain, the method that is used is time delay embeddings. It has two parameters: the time delay and the dimensions of the embeddings. I use the exact same time delay and dimension used in [1], <b>time delay of 32 seconds and dimension of 8</b>. The <b>sampling rate is 6s</b> for all houses in REDD, however, the window isn't specified in their paper.I run my experiment with <b>3 chosen windows: 1 hour, 2 hours, and 4 hours.</b> The authors didn't mention the number of appliances they have used in their experiments, so I use only the appliances mentioned in their paper. The appliances for <b>House 1 are oven, fridge, light, microwave, bath gfi, outlet, washer dryer</b>. The appliances for <b>House 3 are electronics, furnace, washer dryer, microwave, bath gfi, kitchen outlet</b>. \n",
    "\n",
    "\n",
    "\n",
    "Besides [1], <b>Nalmpantis et al. [2]</b> was proposed that they had a similar setup to [1] in their comparison. They found that the best time delay is determined to be <b>30 seconds and the best dimension equal to 6. The sampling rate is 6s for all houses in REDD, and the window is set to 5 minutes</b>. The appliances in <b>House 1 are oven, refrigerator, light, microwave, bath GFI and kitchen outlet. For House 3, the appliances are electronics, furnace, washer dryer, microwave, bath GFI and kitchen outlet</b>. I will run another experiment using the exact mentioned parameters and compare the result to [2].\n",
    "\n",
    "\n",
    "References: </br>\n",
    "[1] Tabatabaei, S. M., Dick, S., & Xu, W. (2016). Toward non-intrusive load monitoring via multi-label classification. IEEE Transactions on Smart Grid, 8(1), 26-40.\n",
    "\n",
    "[2] Nalmpantis, C., & Vrakas, D. (2020). On time series representations for multi-label NILM. Neural Computing and Applications, 32, 17275-17290."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc148a",
   "metadata": {},
   "source": [
    "### Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6a6b12ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts_len_5_min = TimeSeriesLength.WINDOW_5_MINS\n",
    "ts_len_1hr = TimeSeriesLength.WINDOW_1_HOUR\n",
    "ts_len_2hr = TimeSeriesLength.WINDOW_2_HOURS\n",
    "ts_len_4hr = TimeSeriesLength.WINDOW_4_HOURS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ce3e4",
   "metadata": {},
   "source": [
    "### Classifiers\n",
    "#### - MlkNN\n",
    "#### - Rakel\n",
    "\n",
    "<b>Note for MlkNN</b> </br>\n",
    "\n",
    "If you ran into error like I did : TypeError: __init__() takes 1 positional argument but 2 were given\n",
    ", you can try fix it this way\n",
    "* Uninstall the current sklearn version and install sklearn = 0.2.4\n",
    "* Locally by modifying L165 in _compute_cond from </br>\n",
    "self.knn_ = NearestNeighbors(self.k).fit(X)\n",
    "* to </br>\n",
    "self.knn_ = NearestNeighbors(n_neighbors=self.k).fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3c75084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from skmultilearn.ensemble import RakelD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "classifier_MlkNN = MLkNN(ignore_first_neighbours=0, k=3, s=1.0)\n",
    "classifier_Rakel =RakelD(MLPClassifier(hidden_layer_sizes=(100, 100, 100), learning_rate='adaptive',\n",
    "                                 solver='adam'), labelset_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaba6f8",
   "metadata": {},
   "source": [
    "#### [1], house 1, 1 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0b8189ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Prepossessing before training...\n",
      "TIMING: get features time 0.0\n",
      "\n",
      "DEBUG: Features \n",
      " [225.28334 222.60167 222.67667 222.35    222.58667 224.87833 223.71\n",
      " 224.68832 224.195   226.35   ]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['washer dryer', 'light', 'electric oven', 'microwave', 'unknown',\n",
      "       'fridge', 'sockets'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]]\n",
      "DEBUG: bucketize_data: Initial shape (411600, 7)\n",
      "DEBUG: bucketize_data: Shape in batches: (686, 600, 7)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (686, 600, 7)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (686, 7)\n",
      "DEBUG: bucketize_data: Initial shape (411600,)\n",
      "DEBUG: bucketize_data: Shape in batches: (686, 600)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 600\n",
      "DEBUG: Shape of squeezed seq: (686, 8, 560)\n",
      "TIMING: reduce dimensions time 0.034938812255859375\n",
      "\n",
      "TIMING: preprocess time 0.055991172790527344\n",
      "\n",
      "INFO: Prepossessing before testing...\n",
      "TIMING: get features time 0.0009989738464355469\n",
      "\n",
      "DEBUG: Features \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['washer dryer', 'light', 'electric oven', 'microwave', 'unknown',\n",
      "       'fridge', 'sockets'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "DEBUG: bucketize_data: Initial shape (95400, 7)\n",
      "DEBUG: bucketize_data: Shape in batches: (159, 600, 7)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (159, 600, 7)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (159, 7)\n",
      "DEBUG: bucketize_data: Initial shape (95400,)\n",
      "DEBUG: bucketize_data: Shape in batches: (159, 600)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 600\n",
      "DEBUG: Shape of squeezed seq: (159, 8, 560)\n",
      "TIMING: reduce dimensions time 0.007979154586791992\n",
      "\n",
      "TIMING: preprocess time 0.01492929458618164\n",
      "\n",
      "INFO: MlkNN report\n",
      "INFO: F1 macro 0.4230611392811247\n",
      "INFO: F1 micro 0.7583892617449665\n",
      "{'electric oven': {'precision': 1.0, 'recall': 0.06666666666666667, 'f1-score': 0.125, 'support': 15}, 'fridge': {'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1-score': 0.9806451612903225, 'support': 154}, 'light': {'precision': 0.6, 'recall': 0.08823529411764706, 'f1-score': 0.15384615384615385, 'support': 102}, 'microwave': {'precision': 0.7272727272727273, 'recall': 0.18181818181818182, 'f1-score': 0.2909090909090909, 'support': 44}, 'washer dryer': {'precision': 0.2, 'recall': 0.0625, 'f1-score': 0.09523809523809523, 'support': 16}, 'unknown': {'precision': 0.8181818181818182, 'recall': 0.1956521739130435, 'f1-score': 0.3157894736842105, 'support': 46}, 'sockets': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 159}, 'micro avg': {'precision': 0.946927374301676, 'recall': 0.6324626865671642, 'f1-score': 0.7583892617449665, 'support': 536}, 'macro avg': {'precision': 0.75997335997336, 'recall': 0.3688407576469323, 'f1-score': 0.4230611392811247, 'support': 536}, 'weighted avg': {'precision': 0.8546411300142642, 'recall': 0.6324626865671642, 'f1-score': 0.6649940071722025, 'support': 536}, 'samples avg': {'precision': 0.9623689727463314, 'recall': 0.688020365378856, 'f1-score': 0.7814696833564758, 'support': 536}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\skmultilearn\\cluster\\random.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(label_sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: RakelD report\n",
      "INFO: F1 macro 0.4144731576841263\n",
      "INFO: F1 micro 0.8043478260869565\n",
      "{'electric oven': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, 'fridge': {'precision': 0.9685534591194969, 'recall': 1.0, 'f1-score': 0.9840255591054313, 'support': 154}, 'light': {'precision': 0.6642335766423357, 'recall': 0.8921568627450981, 'f1-score': 0.7615062761506275, 'support': 102}, 'microwave': {'precision': 0.5, 'recall': 0.045454545454545456, 'f1-score': 0.08333333333333334, 'support': 44}, 'washer dryer': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 16}, 'unknown': {'precision': 0.8333333333333334, 'recall': 0.10869565217391304, 'f1-score': 0.1923076923076923, 'support': 46}, 'sockets': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 159}, 'micro avg': {'precision': 0.874468085106383, 'recall': 0.7667910447761194, 'f1-score': 0.8170974155069582, 'support': 536}, 'macro avg': {'precision': 0.5665886241564523, 'recall': 0.4351867229105081, 'f1-score': 0.43159612298529776, 'support': 536}, 'weighted avg': {'precision': 0.8138850575657726, 'recall': 0.7667910447761194, 'f1-score': 0.7476238745940689, 'support': 536}, 'samples avg': {'precision': 0.8819706498951783, 'recall': 0.8356244384546271, 'f1-score': 0.834078884078884, 'support': 536}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sample_period = 6\n",
    "train_data, train_target = prep_train(train_df, train_labels_df, sample_period, appliances_redd1, ts_len_1hr)\n",
    "test_data, test_target = prep_test(test_df, test_labels_df, sample_period, appliances_redd1, ts_len_1hr)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_1hr = classification_report(test_target, predictions_nn, target_names=appliances_redd1, output_dict=True)\n",
    "print(report_mlknn_1hr)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(predictions_rak, predictions, average='micro')\n",
    "macro = f1_score(predictions_rak, predictions, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_1hr = classification_report(test_target, predictions_rak, target_names=appliances_redd1, output_dict=True)\n",
    "print(report_rakeld_1hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a3a6c6",
   "metadata": {},
   "source": [
    "#### [1], house 1, 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "02f56898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Prepossessing before training...\n",
      "TIMING: get features time 0.0\n",
      "\n",
      "DEBUG: Features \n",
      " [225.28334 222.60167 222.67667 222.35    222.58667 224.87833 223.71\n",
      " 224.68832 224.195   226.35   ]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['washer dryer', 'light', 'electric oven', 'microwave', 'unknown',\n",
      "       'fridge', 'sockets'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]]\n",
      "DEBUG: bucketize_data: Initial shape (411600, 7)\n",
      "DEBUG: bucketize_data: Shape in batches: (343, 1200, 7)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (343, 1200, 7)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (343, 7)\n",
      "DEBUG: bucketize_data: Initial shape (411600,)\n",
      "DEBUG: bucketize_data: Shape in batches: (343, 1200)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 1200\n",
      "DEBUG: Shape of squeezed seq: (343, 8, 1160)\n",
      "TIMING: reduce dimensions time 0.026961565017700195\n",
      "\n",
      "TIMING: preprocess time 0.06489109992980957\n",
      "\n",
      "INFO: Prepossessing before testing...\n",
      "TIMING: get features time 0.0\n",
      "\n",
      "DEBUG: Features \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['washer dryer', 'light', 'electric oven', 'microwave', 'unknown',\n",
      "       'fridge', 'sockets'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "DEBUG: bucketize_data: Initial shape (94800, 7)\n",
      "DEBUG: bucketize_data: Shape in batches: (79, 1200, 7)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (79, 1200, 7)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (79, 7)\n",
      "DEBUG: bucketize_data: Initial shape (94800,)\n",
      "DEBUG: bucketize_data: Shape in batches: (79, 1200)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 1200\n",
      "DEBUG: Shape of squeezed seq: (79, 8, 1160)\n",
      "TIMING: reduce dimensions time 0.005194187164306641\n",
      "\n",
      "TIMING: preprocess time 0.016165494918823242\n",
      "\n",
      "INFO: MlkNN report\n",
      "INFO: F1 macro 0.472108843537415\n",
      "INFO: F1 micro 0.8036363636363636\n",
      "{'electric oven': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}, 'fridge': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 79}, 'light': {'precision': 0.7702702702702703, 'recall': 0.9661016949152542, 'f1-score': 0.8571428571428571, 'support': 59}, 'microwave': {'precision': 0.6666666666666666, 'recall': 0.0625, 'f1-score': 0.11428571428571428, 'support': 32}, 'washer dryer': {'precision': 0.4, 'recall': 0.15384615384615385, 'f1-score': 0.2222222222222222, 'support': 13}, 'unknown': {'precision': 0.6666666666666666, 'recall': 0.06060606060606061, 'f1-score': 0.1111111111111111, 'support': 33}, 'sockets': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 79}, 'micro avg': {'precision': 0.9094650205761317, 'recall': 0.7198697068403909, 'f1-score': 0.8036363636363636, 'support': 307}, 'macro avg': {'precision': 0.6433719433719433, 'recall': 0.46329341562392407, 'f1-score': 0.472108843537415, 'support': 307}, 'weighted avg': {'precision': 0.8207794113331572, 'recall': 0.7198697068403909, 'f1-score': 0.7126518794271236, 'support': 307}, 'samples avg': {'precision': 0.9145569620253164, 'recall': 0.788456901748041, 'f1-score': 0.8259985443529747, 'support': 307}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\skmultilearn\\cluster\\random.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(label_sets)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [79, 159]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [129], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m classifier_Rakel\u001b[38;5;241m.\u001b[39mfit(train_data, train_target)\n\u001b[0;32m     17\u001b[0m predictions_rak \u001b[38;5;241m=\u001b[39m classifier_Rakel\u001b[38;5;241m.\u001b[39mpredict(test_data)\n\u001b[1;32m---> 18\u001b[0m micro \u001b[38;5;241m=\u001b[39m f1_score(predictions_rak, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m macro \u001b[38;5;241m=\u001b[39m f1_score(predictions_rak, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m info(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRakelD report\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1136\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(\n\u001b[0;32m   1002\u001b[0m     y_true,\n\u001b[0;32m   1003\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1010\u001b[0m ):\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \n\u001b[0;32m   1013\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1277\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfbeta_score\u001b[39m(\n\u001b[0;32m   1149\u001b[0m     y_true,\n\u001b[0;32m   1150\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1157\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1158\u001b[0m ):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \n\u001b[0;32m   1161\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;124;03m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1277\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mD:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1563\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1562\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1563\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mD:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1364\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1364\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1367\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mD:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [79, 159]"
     ]
    }
   ],
   "source": [
    "sample_period = 6\n",
    "train_data, train_target = prep_train(train_df, train_labels_df, sample_period, appliances_redd1, ts_len_2hr)\n",
    "test_data, test_target = prep_test(test_df, test_labels_df, sample_period, appliances_redd1, ts_len_2hr)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_2hr = classification_report(test_target, predictions_nn, target_names=appliances_redd1, output_dict=True)\n",
    "print(report_mlknn_2hr)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(predictions_rak, predictions, average='micro')\n",
    "macro = f1_score(predictions_rak, predictions, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_2hr = classification_report(test_target, predictions_rak, target_names=appliances_redd1, output_dict=True)\n",
    "print(report_rakeld_2hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25944cc6",
   "metadata": {},
   "source": [
    "#### [1], house 1, 4 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1e75ec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Prepossessing before training...\n",
      "TIMING: get features time 0.0\n",
      "\n",
      "DEBUG: Features \n",
      " [225.28334 222.60167 222.67667 222.35    222.58667 224.87833 223.71\n",
      " 224.68832 224.195   226.35   ]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['washer dryer', 'light', 'electric oven', 'microwave', 'unknown',\n",
      "       'fridge', 'sockets'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]]\n",
      "DEBUG: bucketize_data: Initial shape (411600, 7)\n",
      "DEBUG: bucketize_data: Shape in batches: (343, 1200, 7)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (343, 1200, 7)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (343, 7)\n",
      "DEBUG: bucketize_data: Initial shape (411600,)\n",
      "DEBUG: bucketize_data: Shape in batches: (343, 1200)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 1200\n",
      "DEBUG: Shape of squeezed seq: (343, 8, 1160)\n",
      "TIMING: reduce dimensions time 0.025729894638061523\n",
      "\n",
      "TIMING: preprocess time 0.045378684997558594\n",
      "\n",
      "INFO: Prepossessing before testing...\n",
      "TIMING: get features time 0.0\n",
      "\n",
      "DEBUG: Features \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['washer dryer', 'light', 'electric oven', 'microwave', 'unknown',\n",
      "       'fridge', 'sockets'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "DEBUG: bucketize_data: Initial shape (94800, 7)\n",
      "DEBUG: bucketize_data: Shape in batches: (79, 1200, 7)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (79, 1200, 7)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (79, 7)\n",
      "DEBUG: bucketize_data: Initial shape (94800,)\n",
      "DEBUG: bucketize_data: Shape in batches: (79, 1200)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 1200\n",
      "DEBUG: Shape of squeezed seq: (79, 8, 1160)\n",
      "TIMING: reduce dimensions time 0.0049877166748046875\n",
      "\n",
      "TIMING: preprocess time 0.010971307754516602\n",
      "\n",
      "INFO: MlkNN report\n",
      "INFO: F1 macro 0.472108843537415\n",
      "INFO: F1 micro 0.8036363636363636\n",
      "{'electric oven': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}, 'fridge': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 79}, 'light': {'precision': 0.7702702702702703, 'recall': 0.9661016949152542, 'f1-score': 0.8571428571428571, 'support': 59}, 'microwave': {'precision': 0.6666666666666666, 'recall': 0.0625, 'f1-score': 0.11428571428571428, 'support': 32}, 'washer dryer': {'precision': 0.4, 'recall': 0.15384615384615385, 'f1-score': 0.2222222222222222, 'support': 13}, 'unknown': {'precision': 0.6666666666666666, 'recall': 0.06060606060606061, 'f1-score': 0.1111111111111111, 'support': 33}, 'sockets': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 79}, 'micro avg': {'precision': 0.9094650205761317, 'recall': 0.7198697068403909, 'f1-score': 0.8036363636363636, 'support': 307}, 'macro avg': {'precision': 0.6433719433719433, 'recall': 0.46329341562392407, 'f1-score': 0.472108843537415, 'support': 307}, 'weighted avg': {'precision': 0.8207794113331572, 'recall': 0.7198697068403909, 'f1-score': 0.7126518794271236, 'support': 307}, 'samples avg': {'precision': 0.9145569620253164, 'recall': 0.788456901748041, 'f1-score': 0.8259985443529747, 'support': 307}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\skmultilearn\\cluster\\random.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(label_sets)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [79, 159]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [130], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m classifier_Rakel\u001b[38;5;241m.\u001b[39mfit(train_data, train_target)\n\u001b[0;32m     17\u001b[0m predictions_rak \u001b[38;5;241m=\u001b[39m classifier_Rakel\u001b[38;5;241m.\u001b[39mpredict(test_data)\n\u001b[1;32m---> 18\u001b[0m micro \u001b[38;5;241m=\u001b[39m f1_score(predictions_rak, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m macro \u001b[38;5;241m=\u001b[39m f1_score(predictions_rak, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m info(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRakelD report\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1136\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(\n\u001b[0;32m   1002\u001b[0m     y_true,\n\u001b[0;32m   1003\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1010\u001b[0m ):\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \n\u001b[0;32m   1013\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1277\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfbeta_score\u001b[39m(\n\u001b[0;32m   1149\u001b[0m     y_true,\n\u001b[0;32m   1150\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1157\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1158\u001b[0m ):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \n\u001b[0;32m   1161\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;124;03m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1277\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mD:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1563\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1562\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1563\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mD:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1364\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1364\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1367\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mD:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [79, 159]"
     ]
    }
   ],
   "source": [
    "sample_period = 6\n",
    "train_data, train_target = prep_train(train_df, train_labels_df, sample_period, appliances_redd1, ts_len_2hr)\n",
    "test_data, test_target = prep_test(test_df, test_labels_df, sample_period, appliances_redd1, ts_len_2hr)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_4hr = classification_report(test_target, predictions_nn, target_names=appliances_redd1, output_dict=True)\n",
    "print(report_mlknn_4hr)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(predictions_rak, predictions, average='micro')\n",
    "macro = f1_score(predictions_rak, predictions, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_4hr = classification_report(test_target, predictions_rak, target_names=appliances_redd1, output_dict=True)\n",
    "print(report_rakeld_4hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dd7f83",
   "metadata": {},
   "source": [
    "#### [1], house 1, 4 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "752edcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: F1 macro 0.42091492905800265\n",
      "INFO: F1 micro 0.746786433328171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classifier = MLkNN(ignore_first_neighbours=0, k=3, s=1.0)\n",
    "classifier.fit(train_data, train_target)\n",
    "start_time = time.time()\n",
    "predictions = classifier.predict(test_data)\n",
    "predictions_time = time.time() - start_time\n",
    "micro = f1_score(test_target, predictions, average='micro')\n",
    "macro = f1_score(test_target, predictions, average='macro')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_5min = classification_report(test_target, predictions, target_names=appliances_redd1, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5ee3389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'electric oven': {'precision': 0.25,\n",
       "  'recall': 0.028985507246376812,\n",
       "  'f1-score': 0.051948051948051945,\n",
       "  'support': 69},\n",
       " 'fridge': {'precision': 0.9170506912442397,\n",
       "  'recall': 0.2707482993197279,\n",
       "  'f1-score': 0.41806722689075626,\n",
       "  'support': 735},\n",
       " 'light': {'precision': 0.9402985074626866,\n",
       "  'recall': 0.25688073394495414,\n",
       "  'f1-score': 0.40352281825460373,\n",
       "  'support': 981},\n",
       " 'microwave': {'precision': 0.5945945945945946,\n",
       "  'recall': 0.2268041237113402,\n",
       "  'f1-score': 0.3283582089552239,\n",
       "  'support': 97},\n",
       " 'washer dryer': {'precision': 0.4666666666666667,\n",
       "  'recall': 0.19444444444444445,\n",
       "  'f1-score': 0.27450980392156865,\n",
       "  'support': 72},\n",
       " 'unknown': {'precision': 0.7804878048780488,\n",
       "  'recall': 0.34408602150537637,\n",
       "  'f1-score': 0.47761194029850756,\n",
       "  'support': 93},\n",
       " 'sockets': {'precision': 0.9848879624804586,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9923864531373064,\n",
       "  'support': 1890},\n",
       " 'micro avg': {'precision': 0.9567460317460318,\n",
       "  'recall': 0.6123952247904496,\n",
       "  'f1-score': 0.746786433328171,\n",
       "  'support': 3937},\n",
       " 'macro avg': {'precision': 0.7048551753323851,\n",
       "  'recall': 0.3317070185960314,\n",
       "  'f1-score': 0.42091492905800265,\n",
       "  'support': 3937},\n",
       " 'weighted avg': {'precision': 0.9243115022867189,\n",
       "  'recall': 0.6123952247904496,\n",
       "  'f1-score': 0.6803056822669971,\n",
       "  'support': 3937},\n",
       " 'samples avg': {'precision': 0.9711481674483237,\n",
       "  'recall': 0.6788952579468472,\n",
       "  'f1-score': 0.7633251295054317,\n",
       "  'support': 3937}}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_mlknn_5min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b1e536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nilmtk-env)",
   "language": "python",
   "name": "nilmtk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
