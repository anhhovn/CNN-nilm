{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938b4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilmtk as nilmtk\n",
    "from nilmtk import DataSet, MeterGroup, Appliance\n",
    "from nilmtk.metergroup import MeterGroupID\n",
    "from nilmtk.elecmeter import ElecMeter, ElecMeterID \n",
    "from typing import List, Tuple, Dict\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "#REDD = os.path.join(dirname, r\"datasource\\dataset\\REDD\\redd.h5\")\n",
    "redd = DataSet('redd.h5')\n",
    "SITE_METER = 'Site meter'\n",
    "year = '2011'\n",
    "train_month_end = '5'\n",
    "train_month_start = '4'\n",
    "train_end_date = \"{}-17-{}\".format(train_month_end, year)\n",
    "train_start_date = \"{}-18-{}\".format(train_month_start, year)\n",
    "test_month_end = '5'\n",
    "test_month_start = '5'\n",
    "test_end_date = \"{}-25-{}\".format(test_month_end, year)\n",
    "test_start_date = \"{}-18-{}\".format(test_month_start, year)\n",
    "appliances_redd1 = ['fridge','dish washer','sockets','light','unknown','electric space heater','electric stove','electric oven',\n",
    "                   'washer dryer']\n",
    "building = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c95ea785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(t: str):\n",
    "    print('TIMING: ' + t)\n",
    "    print()\n",
    "\n",
    "    \n",
    "def info(i: str):\n",
    "    print('INFO: ' + i)\n",
    "    \n",
    "def debug(d):\n",
    "    print('DEBUG: ' + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d99a2",
   "metadata": {},
   "source": [
    "## Read data using nilmtk\n",
    "* Read selected data\n",
    "* Label data\n",
    "* Bucketize data (delay embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ae4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_metergroup(dataset: DataSet, building: int, appliances: List,  start: str, end: str, \n",
    "                               sample_period = 3, include_mains=True):\n",
    "    \"\"\"\n",
    "    Get the MeterGroup of selected appliances\n",
    "    Return the MeterGroup\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_selected_metergroup() starts')\n",
    "    dataset.set_window(start=start, end=end)\n",
    "    elec = dataset.buildings[building].elec\n",
    "    appliances_with_one_meter = []\n",
    "    appliances_with_more_meters = []\n",
    "    for appliance in appliances:\n",
    "        metergroup = elec.select_using_appliances(type=appliances)\n",
    "        if len(metergroup.meters) > 1:\n",
    "            appliances_with_more_meters.append(appliance)\n",
    "        else:\n",
    "            appliances_with_one_meter.append(appliance)\n",
    "\n",
    "    special_metergroup = None\n",
    "    for appliance in appliances_with_more_meters:\n",
    "        inst = 1\n",
    "        if appliance == 'sockets' and building == 3:\n",
    "            inst = 4\n",
    "        if special_metergroup is None:\n",
    "            special_metergroup = elec.select_using_appliances(type=appliance, instance=inst)\n",
    "        else:\n",
    "            special_metergroup = special_metergroup.union(elec.select_using_appliances(type=appliance, instance=1))\n",
    "\n",
    "    selected_metergroup = elec.select_using_appliances(type=appliances_with_one_meter)\n",
    "    selected_metergroup = selected_metergroup.union(special_metergroup)\n",
    "    if include_mains:\n",
    "        mains_meter = dataset.buildings[building].elec.mains()\n",
    "        if isinstance(mains_meter, MeterGroup):\n",
    "            if len(mains_meter.meters) > 1:\n",
    "                mains_meter = mains_meter.meters[0]\n",
    "                mains_metergroup = MeterGroup(meters=[mains_meter])\n",
    "            else:\n",
    "                mains_metergroup = mains_meter\n",
    "        else:\n",
    "            mains_metergroup = MeterGroup(meters=[mains_meter])\n",
    "        selected_metergroup = selected_metergroup.union(mains_metergroup)\n",
    "    info('get_selected_metergroup() finished')\n",
    "    print(selected_metergroup)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "    return selected_metergroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3af49e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_selected_appliances(dataset: DataSet, building: int, appliances : List, start: str, end: str, include_mains,\n",
    "                               sample_period = 3):\n",
    "    \"\"\"\n",
    "    Read and fill in missing values of selected appliances in a given bulding\n",
    "    Return the DataFrame of selected appliances in which columns are ElecMeter IDs,\n",
    "    and values are the PC of the meter in given sample period\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('read_selected_appliances() starts')\n",
    "    selected_metergroup = get_selected_metergroup(dataset, building, appliances, start, end,sample_period,include_mains)\n",
    "    df = selected_metergroup.dataframe_of_meters(sample_period=sample_period)\n",
    "    df.fillna(0, inplace=True)\n",
    "    info('read_selected_appliances() finished')\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "    return df, selected_metergroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a08373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_meters(dataset: DataSet, building: int, start_date: str, end_date:str, sample_period = 3):\n",
    "    \"\"\"\n",
    "    Read all the meters in given building\n",
    "    \"\"\"\n",
    "    elec = dataset.buildings[building].elec\n",
    "    print(elec)\n",
    "    #redd_datasource = Datasource(redd, \"REDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86957733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_df(df: DataFrame, selected_metergroup: MeterGroup) -> [List, Dict]:\n",
    "    \"\"\"\n",
    "    Returns two lists, one is a list of labels which describes DataFrame columns\n",
    "    Other is a list of power threshold of each appliances\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_labels_df() starts')\n",
    "    lst = []\n",
    "    threshold = {}\n",
    "    for m in df.columns:\n",
    "        label = \"\"\n",
    "        if isinstance(m,MeterGroupID):\n",
    "            tup_elecmeterID = m[0]\n",
    "            lst_elecmeterID = list(tup_elecmeterID)\n",
    "            #get meter group using list of ElecMeterIDs\n",
    "            mg = selected_metergroup[lst_elecmeterID]\n",
    "            #get labels of meter group\n",
    "            labels = mg.get_labels(lst_elecmeterID)\n",
    "            label = labels[0]\n",
    "            threshold[label] =mg.on_power_threshold()\n",
    "        else:\n",
    "            #get ElecMeter using ElecMeterID\n",
    "            elec_meter = selected_metergroup[m]\n",
    "            #get labels of ElecMeter\n",
    "            label = elec_meter.label()\n",
    "            threshold[label] = elec_meter.on_power_threshold()\n",
    "        lst += [label]\n",
    "    info('get_labels_df() finished')\n",
    "    print(lst)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "        \n",
    "    return lst, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77703d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dic_real_power(df: DataFrame, labels: List) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns a Dictionary in which key is name of the appliance, and value is the power consumption the appliance\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_dic_real_power() starts')\n",
    "    Dict = {}\n",
    "    lst = []\n",
    "    for k, v in df.items():\n",
    "        lst += [v]\n",
    "        \n",
    "    for i in range(len(labels)):\n",
    "        Dict[labels[i]] = lst[i]\n",
    "    info('get_dic_real_power() finished')\n",
    "    print(Dict)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))    \n",
    "    return Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10510e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dic_labeled_power(RealPower: Dict, threshold: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns a Dictionary in which key is name of the appliance, and value is \n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_dic_labeled_power() starts')\n",
    "    LabeledPower = {}\n",
    "    for appliance, real_power in RealPower.items():\n",
    "        if appliance != 'Site meter':\n",
    "            arr = create_labels(real_power, threshold[appliance])\n",
    "            LabeledPower[appliance] = arr\n",
    "    info('get_dic_labeled_power() finished')\n",
    "    print(LabeledPower)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "    return LabeledPower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4b38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(array, threshold):\n",
    "    res = np.empty(array.shape)\n",
    "    for i in range(len(array)):\n",
    "        if array[i] >= threshold:\n",
    "            res[i] = 1\n",
    "        else:\n",
    "            res[i] = 0\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "217df2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def normalize_columns(df: DataFrame, meter_group: MeterGroup, appliance_names: List[str]) -> Tuple[DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    It normalizes the names of the columns for compatibility.\n",
    "    Args:\n",
    "        df (DataFrame):\n",
    "        meter_group (MeterGroup):\n",
    "        appliance_names (List[str]):\n",
    "    Returns:\n",
    "        A tuple with a DataFrame and a dictionary mapping labels to ids.\n",
    "    \"\"\"\n",
    "    labels = meter_group.get_labels(df.columns)\n",
    "    normalized_labels = []\n",
    "    info(f\"Df columns before normalization {df.columns}\")\n",
    "    info(f\"Labels before normalization {labels}\")\n",
    "\n",
    "    for label in labels:\n",
    "        if label == SITE_METER and SITE_METER not in appliance_names:\n",
    "            normalized_labels.append(SITE_METER)\n",
    "            continue\n",
    "        for name in appliance_names:\n",
    "            ratio = fuzz.ratio(label.lower().replace('electric', \"\").lstrip().rstrip().split()[0],\n",
    "                                   name.lower().replace('electric', \"\").lstrip().rstrip().split()[0])\n",
    "            if ratio > 90:\n",
    "                info(f\"{name} ~ {label} ({ratio}%)\")\n",
    "                normalized_labels.append(name)\n",
    "    if len(normalized_labels) != len(labels):\n",
    "        debug(f\"len(normalized_labels) {len(normalized_labels)} != len(labels) {len(labels)}\")\n",
    "        raise LabelNormalizationError()\n",
    "    label2id = {l: i for l, i in zip(normalized_labels, df.columns)}\n",
    "    df.columns = normalized_labels\n",
    "    info(f\"Normalized labels {normalized_labels}\")\n",
    "    return df, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e55534e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_site_meter_data(df: DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the data of the site meter from the given DataFrame.\n",
    "    Args:\n",
    "        df (DataFrame): A DataFrame containing energy data with columns corresponding to different meters.\n",
    "    Returns:\n",
    "        The site meter data as an array (ndarray).\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if SITE_METER in col:\n",
    "            return df[col].values\n",
    "    raise NoSiteMeterException(\"Couldn' t find site meter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "785ec9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multilabels(labels_df: DataFrame, appliances: List = None) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Get the labels of the specified appliances.\n",
    "    Args:\n",
    "        labels_df (DataFrame):\n",
    "        appliances (List):\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    debug(f\"get_multilabels  labels_df.columns {labels_df.columns}\")\n",
    "    debug(f\"get_multilabels  appliances {appliances}\")\n",
    "    if appliances is None:\n",
    "        return labels_df\n",
    "    else:\n",
    "        return labels_df[appliances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d32476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_one_building(dataset: DataSet, appliances, building, start, end, sample_period) -> (pd.DataFrame, MeterGroup, Dict, Dict):\n",
    "    all_df, metergroup = read_selected_appliances(dataset = dataset, building = building, \n",
    "                                                 appliances = appliances, start = start, end = end, include_mains = True, sample_period = sample_period )\n",
    "    debug(f\"Length of data of all loaded meters {len(all_df)}\")\n",
    "    all_df, label2id = normalize_columns(all_df, metergroup, appliances)\n",
    "    debug(f\"Length of data of all loaded meters {len(all_df)}\")\n",
    "    info('Meters that have been loaded (all_df.columns):\\n' + str(all_df.columns))\n",
    "    \n",
    "    \n",
    "    return all_df, metergroup, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceb40d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multilabels_from_meters(meters: DataFrame, meter_group: MeterGroup, labels2id: dict) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Creates multi labels from the given meter group using a dictionary as a lookup table.\n",
    "    Args:\n",
    "        meters (DataFrame):\n",
    "        meter_group (MeterGroup):\n",
    "        labels2id (dict):\n",
    "    Returns:\n",
    "        A DataFrame with the multi labels.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    labels = dict()\n",
    "    for col in meters.columns:\n",
    "        info(f\"Creating multilabels from meter {col}, \"\n",
    "             f\"\\nlabels2id[col] {labels2id[col]}\"\n",
    "             f\"\\nmetergroup[labels2id[col]] {meter_group[labels2id[col]]}\")\n",
    "        meter = meter_group[labels2id[col]]\n",
    "        threshold = meter.on_power_threshold()\n",
    "        vals = meters[col].values.astype(float)\n",
    "        if vals is None or col == SITE_METER:\n",
    "            debug(f\"Skipping {col} - {vals}\")\n",
    "            continue\n",
    "        debug(f\"meters[col].values.astype(float) {col} - {vals}\")\n",
    "        labels[col] = create_labels(vals, threshold)\n",
    "    timing('Create multilabels from meters {}'.format(round(time.time() - start_time, 2)))\n",
    "    return DataFrame(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15921bb4",
   "metadata": {},
   "source": [
    "#### Set up train data (REDD1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5daa2f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: read_selected_appliances() starts\n",
      "INFO: get_selected_metergroup() starts\n",
      "INFO: get_selected_metergroup() finished\n",
      "MeterGroup(meters=\n",
      "  ElecMeter(instance=13, building=1, dataset='REDD', appliances=[Appliance(type='electric space heater', instance=1)])\n",
      "  ElecMeter(instance=6, building=1, dataset='REDD', appliances=[Appliance(type='dish washer', instance=1)])\n",
      "  ElecMeter(instance=14, building=1, dataset='REDD', appliances=[Appliance(type='electric stove', instance=1)])\n",
      "  ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "  ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "    ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "    ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "  ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      ")\n",
      "TIMING: 0.06\n",
      "\n",
      "Loading data for meter ElecMeterID(instance=20, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Loading data for meter ElecMeterID(instance=4, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "INFO: read_selected_appliances() finished\n",
      "TIMING: 6.08\n",
      "\n",
      "DEBUG: Length of data of all loaded meters 411979\n",
      "INFO: Df columns before normalization Index([                      (13, 1, 'REDD'),\n",
      "                              (6, 1, 'REDD'),\n",
      "                             (14, 1, 'REDD'),\n",
      "                              (5, 1, 'REDD'),\n",
      "                              (1, 1, 'REDD'),\n",
      "       (((10, 1, 'REDD'), (20, 1, 'REDD')),),\n",
      "                              (9, 1, 'REDD'),\n",
      "         (((3, 1, 'REDD'), (4, 1, 'REDD')),),\n",
      "                             (12, 1, 'REDD'),\n",
      "                              (7, 1, 'REDD')],\n",
      "      dtype='object')\n",
      "INFO: Labels before normalization ['Electric space heater', 'Dish washer', 'Electric stove', 'Fridge', 'Site meter', 'Washer dryer', 'Light', 'Electric oven', 'Unknown', 'Sockets']\n",
      "INFO: electric space heater ~ Electric space heater (100%)\n",
      "INFO: dish washer ~ Dish washer (100%)\n",
      "INFO: electric stove ~ Electric stove (100%)\n",
      "INFO: fridge ~ Fridge (100%)\n",
      "INFO: washer dryer ~ Washer dryer (100%)\n",
      "INFO: light ~ Light (100%)\n",
      "INFO: electric oven ~ Electric oven (100%)\n",
      "INFO: unknown ~ Unknown (100%)\n",
      "INFO: sockets ~ Sockets (100%)\n",
      "INFO: Normalized labels ['electric space heater', 'dish washer', 'electric stove', 'fridge', 'Site meter', 'washer dryer', 'light', 'electric oven', 'unknown', 'sockets']\n",
      "DEBUG: Length of data of all loaded meters 411979\n",
      "INFO: Meters that have been loaded (all_df.columns):\n",
      "Index(['electric space heater', 'dish washer', 'electric stove', 'fridge',\n",
      "       'Site meter', 'washer dryer', 'light', 'electric oven', 'unknown',\n",
      "       'sockets'],\n",
      "      dtype='object')\n",
      "INFO: Creating multilabels from meter electric space heater, \n",
      "labels2id[col] ElecMeterID(instance=13, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=13, building=1, dataset='REDD', appliances=[Appliance(type='electric space heater', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) electric space heater - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter dish washer, \n",
      "labels2id[col] ElecMeterID(instance=6, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=6, building=1, dataset='REDD', appliances=[Appliance(type='dish washer', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) dish washer - [0.  0.  0.5 ... 0.5 0.  0. ]\n",
      "INFO: Creating multilabels from meter electric stove, \n",
      "labels2id[col] ElecMeterID(instance=14, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=14, building=1, dataset='REDD', appliances=[Appliance(type='electric stove', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) electric stove - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter fridge, \n",
      "labels2id[col] ElecMeterID(instance=5, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) fridge - [  0.    6.    6.  ... 199.  197.5 197.5]\n",
      "INFO: Creating multilabels from meter Site meter, \n",
      "labels2id[col] ElecMeterID(instance=1, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "DEBUG: Skipping Site meter - [225.28334045 222.60166931 222.67666626 ...   0.           0.\n",
      "   0.        ]\n",
      "INFO: Creating multilabels from meter washer dryer, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=10, building=1, dataset='REDD'), ElecMeterID(instance=20, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) washer dryer - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter light, \n",
      "labels2id[col] ElecMeterID(instance=9, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) light - [ 0. 81. 81. ... 43. 43. 43.]\n",
      "INFO: Creating multilabels from meter electric oven, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=3, building=1, dataset='REDD'), ElecMeterID(instance=4, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) electric oven - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter unknown, \n",
      "labels2id[col] ElecMeterID(instance=12, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) unknown - [0. 1. 1. ... 1. 1. 1.]\n",
      "INFO: Creating multilabels from meter sockets, \n",
      "labels2id[col] ElecMeterID(instance=7, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) sockets - [ 0.  34.  34.5 ... 21.  21.5 21. ]\n",
      "TIMING: Create multilabels from meters 1.51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df, train_metergroup, train_label2id = setup_one_building(redd, appliances_redd1, building, \n",
    "                                                                train_start_date, train_end_date, sample_period = 6)\n",
    "train_labels_df = create_multilabels_from_meters(train_df, train_metergroup, train_label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3f708",
   "metadata": {},
   "source": [
    "#### Set up test data (REDD1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7d0cd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: read_selected_appliances() starts\n",
      "INFO: get_selected_metergroup() starts\n",
      "INFO: get_selected_metergroup() finished\n",
      "MeterGroup(meters=\n",
      "  ElecMeter(instance=13, building=1, dataset='REDD', appliances=[Appliance(type='electric space heater', instance=1)])\n",
      "  ElecMeter(instance=6, building=1, dataset='REDD', appliances=[Appliance(type='dish washer', instance=1)])\n",
      "  ElecMeter(instance=14, building=1, dataset='REDD', appliances=[Appliance(type='electric stove', instance=1)])\n",
      "  ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "  ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "    ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "  MeterGroup(meters=\n",
      "    ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "    ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  )\n",
      "  ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "  ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      ")\n",
      "TIMING: 0.05\n",
      "\n",
      "Loading data for meter ElecMeterID(instance=20, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Loading data for meter ElecMeterID(instance=4, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "INFO: read_selected_appliances() finished\n",
      "TIMING: 1.94\n",
      "\n",
      "DEBUG: Length of data of all loaded meters 95971\n",
      "INFO: Df columns before normalization Index([                      (13, 1, 'REDD'),\n",
      "                              (6, 1, 'REDD'),\n",
      "                             (14, 1, 'REDD'),\n",
      "                              (5, 1, 'REDD'),\n",
      "                              (1, 1, 'REDD'),\n",
      "       (((10, 1, 'REDD'), (20, 1, 'REDD')),),\n",
      "                              (9, 1, 'REDD'),\n",
      "         (((3, 1, 'REDD'), (4, 1, 'REDD')),),\n",
      "                             (12, 1, 'REDD'),\n",
      "                              (7, 1, 'REDD')],\n",
      "      dtype='object')\n",
      "INFO: Labels before normalization ['Electric space heater', 'Dish washer', 'Electric stove', 'Fridge', 'Site meter', 'Washer dryer', 'Light', 'Electric oven', 'Unknown', 'Sockets']\n",
      "INFO: electric space heater ~ Electric space heater (100%)\n",
      "INFO: dish washer ~ Dish washer (100%)\n",
      "INFO: electric stove ~ Electric stove (100%)\n",
      "INFO: fridge ~ Fridge (100%)\n",
      "INFO: washer dryer ~ Washer dryer (100%)\n",
      "INFO: light ~ Light (100%)\n",
      "INFO: electric oven ~ Electric oven (100%)\n",
      "INFO: unknown ~ Unknown (100%)\n",
      "INFO: sockets ~ Sockets (100%)\n",
      "INFO: Normalized labels ['electric space heater', 'dish washer', 'electric stove', 'fridge', 'Site meter', 'washer dryer', 'light', 'electric oven', 'unknown', 'sockets']\n",
      "DEBUG: Length of data of all loaded meters 95971\n",
      "INFO: Meters that have been loaded (all_df.columns):\n",
      "Index(['electric space heater', 'dish washer', 'electric stove', 'fridge',\n",
      "       'Site meter', 'washer dryer', 'light', 'electric oven', 'unknown',\n",
      "       'sockets'],\n",
      "      dtype='object')\n",
      "INFO: Creating multilabels from meter electric space heater, \n",
      "labels2id[col] ElecMeterID(instance=13, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=13, building=1, dataset='REDD', appliances=[Appliance(type='electric space heater', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) electric space heater - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter dish washer, \n",
      "labels2id[col] ElecMeterID(instance=6, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=6, building=1, dataset='REDD', appliances=[Appliance(type='dish washer', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) dish washer - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter electric stove, \n",
      "labels2id[col] ElecMeterID(instance=14, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=14, building=1, dataset='REDD', appliances=[Appliance(type='electric stove', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) electric stove - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter fridge, \n",
      "labels2id[col] ElecMeterID(instance=5, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=5, building=1, dataset='REDD', appliances=[Appliance(type='fridge', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) fridge - [7. 7. 7. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter Site meter, \n",
      "labels2id[col] ElecMeterID(instance=1, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=1, building=1, dataset='REDD', site_meter, appliances=[])\n",
      "DEBUG: Skipping Site meter - [  0.           0.           0.         ... 235.17333984 235.08500671\n",
      " 235.25      ]\n",
      "INFO: Creating multilabels from meter washer dryer, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=10, building=1, dataset='REDD'), ElecMeterID(instance=20, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=10, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  ElecMeter(instance=20, building=1, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) washer dryer - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter light, \n",
      "labels2id[col] ElecMeterID(instance=9, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=9, building=1, dataset='REDD', appliances=[Appliance(type='light', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) light - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter electric oven, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=3, building=1, dataset='REDD'), ElecMeterID(instance=4, building=1, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=3, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      "  ElecMeter(instance=4, building=1, dataset='REDD', appliances=[Appliance(type='electric oven', instance=1)])\n",
      ")\n",
      "DEBUG: meters[col].values.astype(float) electric oven - [0. 0. 0. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter unknown, \n",
      "labels2id[col] ElecMeterID(instance=12, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=12, building=1, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) unknown - [1. 1. 1. ... 0. 0. 0.]\n",
      "INFO: Creating multilabels from meter sockets, \n",
      "labels2id[col] ElecMeterID(instance=7, building=1, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=7, building=1, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "DEBUG: meters[col].values.astype(float) sockets - [22. 22. 22. ...  0.  0.  0.]\n",
      "TIMING: Create multilabels from meters 0.38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df, test_metergroup, test_label2id = setup_one_building(redd, appliances_redd1, building, \n",
    "                                                                test_start_date, test_end_date, sample_period = 6)\n",
    "test_labels_df = create_multilabels_from_meters(test_df, test_metergroup, test_label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f269b7",
   "metadata": {},
   "source": [
    "### Time series length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce3135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63f58b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class TimeSeriesLength(Enum):\n",
    "    \"\"\"\n",
    "    The length of each segment of the time series, which will be used for inference.\n",
    "    \"\"\"\n",
    "    WINDOW_SAMPLE_PERIOD = 'same'\n",
    "    WINDOW_1_MIN = '1m'\n",
    "    WINDOW_5_MINS = '5m'\n",
    "    WINDOW_10_MINS = '10m'\n",
    "    WINDOW_30_MINS = '30m'\n",
    "    WINDOW_1_HOUR = '1h'\n",
    "    WINDOW_2_HOURS = '2h'\n",
    "    WINDOW_4_HOURS = '4h'\n",
    "    WINDOW_8_HOURS = '8h'\n",
    "    WINDOW_1_DAY = '1d'\n",
    "    WINDOW_1_WEEK = '1w'\n",
    "    \n",
    "def get_window(dt: TimeSeriesLength, sample_period) -> int:\n",
    "    choices = {TimeSeriesLength.WINDOW_SAMPLE_PERIOD: 1,\n",
    "               TimeSeriesLength.WINDOW_1_MIN        : get_no_of_samples_per_min(sample_period),\n",
    "               TimeSeriesLength.WINDOW_5_MINS       : get_no_of_samples_per_min(sample_period) * 5,\n",
    "               TimeSeriesLength.WINDOW_10_MINS      : get_no_of_samples_per_min(sample_period) * 10,\n",
    "               TimeSeriesLength.WINDOW_30_MINS      : get_no_of_samples_per_min(sample_period) * 30,\n",
    "               TimeSeriesLength.WINDOW_1_HOUR       : get_no_of_samples_per_hour(sample_period),\n",
    "               TimeSeriesLength.WINDOW_2_HOURS      : get_no_of_samples_per_hour(sample_period) * 2,\n",
    "               TimeSeriesLength.WINDOW_4_HOURS      : get_no_of_samples_per_hour(sample_period) * 4,\n",
    "               TimeSeriesLength.WINDOW_8_HOURS      : get_no_of_samples_per_hour(sample_period) * 8,\n",
    "               TimeSeriesLength.WINDOW_1_DAY        : get_no_of_samples_per_day(sample_period),\n",
    "               TimeSeriesLength.WINDOW_1_WEEK       : get_no_of_samples_per_day(sample_period) * 7\n",
    "              }\n",
    "    return int(choices.get(dt, 1))\n",
    "    \n",
    "def get_no_of_samples_per_min(sample_period):\n",
    "    \"\"\"\n",
    "    It returns the number of samples per minute. This depends also on the predefined sample period.\n",
    "    Returns:\n",
    "        An int representing the number of samples.\n",
    "    \"\"\"\n",
    "    return 60 / sample_period\n",
    "\n",
    "\n",
    "def get_no_of_samples_per_hour(sample_period):\n",
    "    \"\"\"\n",
    "    It returns the number of samples per hour. This depends also on the predefined sample period.\n",
    "    Returns:\n",
    "        An int representing the number of samples.\n",
    "    \"\"\"\n",
    "    return get_no_of_samples_per_min(sample_period) * 60\n",
    "\n",
    "\n",
    "def get_no_of_samples_per_day(sample_period):\n",
    "    \"\"\"\n",
    "    It returns the number of samples per day. This depends also on the predefined sample period.\n",
    "    Returns:\n",
    "        An int representing the number of samples.\n",
    "    \"\"\"\n",
    "    return get_no_of_samples_per_hour(sample_period) * 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c7e04",
   "metadata": {},
   "source": [
    "### Bucketize data / delay embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ffc8dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_data(data: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    It segments the time series grouping it into batches. Its segment is of size equal to the window.\n",
    "    Args:\n",
    "        data (ndarray): The given time series.\n",
    "        window (int): The size of the segments.\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    debug('bucketize_data: Initial shape {}'.format(data.shape))\n",
    "    n_dims = len(data.shape)\n",
    "\n",
    "    if n_dims == 1:\n",
    "        seq_in_batches = np.reshape(data, (int(len(data) / window), window))\n",
    "    elif n_dims == 2:\n",
    "        seq_in_batches = np.reshape(data, (int(len(data) / window), window, data.shape[1]))\n",
    "    else:\n",
    "        raise Exception('Invalid number of dimensions {}.'.format(n_dims))\n",
    "    debug('bucketize_data: Shape in batches: {}'.format(seq_in_batches.shape))\n",
    "    return seq_in_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c447f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_target(target: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Creates target data according to the lenght of the window of the segmented data.\n",
    "    Args:\n",
    "        target (ndarray): Target data with the original size.\n",
    "        window (int): The length of window that will be used to create the corresponding labels.\n",
    "    Returns:\n",
    "        The target data for the new bucketized time series.\n",
    "    \"\"\"\n",
    "    target_in_batches = bucketize_data(target, window)\n",
    "    any_multilabel = np.any(target_in_batches, axis=1)\n",
    "    debug('bucketize_target: Shape of array in windows: {}'.format(target_in_batches.shape))\n",
    "    debug('bucketize_target: Shape of array after merging windows: {}'.format(any_multilabel.shape))\n",
    "    return any_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0939b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def takens_embedding(series: np.ndarray, delay, dimension) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function returns the Takens embedding of data with delay into dimension,\n",
    "    delay*dimension must be < len(data)\n",
    "    \"\"\"\n",
    "    if delay * dimension > len(series):\n",
    "        info(f'Not enough data for the given delay ({delay}) and dimension ({dimension}).'\n",
    "             f'\\ndelay * dimension > len(data): {delay * dimension} > {len(series)}')\n",
    "        return series\n",
    "    delay_embedding = np.array([series[0:len(series) - delay * dimension]])\n",
    "    for i in range(1, dimension):\n",
    "        delay_embedding = np.append(delay_embedding,\n",
    "                                    [series[i * delay:len(series) - delay * (dimension - i)]], axis=0)\n",
    "    return delay_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51a21250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate(delay_in_seconds: int, dimension: int, sample_period: int, series_in_segments: np.ndarray, window: int = 1, should_fit: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    The time series is given as segments. For each segment we extract the delay embeddings.\n",
    "    \"\"\"\n",
    "    delay_items = int(delay_in_seconds / sample_period)\n",
    "    window_size = delay_items * dimension\n",
    "\n",
    "    if window_size > len(series_in_segments[0]):\n",
    "        raise Exception(\n",
    "            f'Not enough data for the given delay ({delay_in_seconds} seconds) and dimension ({dimension}).'\n",
    "            f'\\ndelay_items * dimension > len(data): {window_size} > {len(series_in_segments[0])}')\n",
    "\n",
    "    if window_size == len(series_in_segments[0]):\n",
    "        info(f\"TimeDelayEmbeddingAdapter is applied with delay embeddings equavalent to the length of each segment\"\n",
    "                f\" {window_size} == {len(series_in_segments[0])}\")\n",
    "\n",
    "    if window_size < len(series_in_segments[0]):\n",
    "        info(f\"TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each \"\n",
    "                f\"segment. {window_size} < {len(series_in_segments[0])}\")\n",
    "\n",
    "    delay_embeddings = []\n",
    "    for segment in series_in_segments:\n",
    "        embedding = takens_embedding(segment, delay_items, dimension)\n",
    "        delay_embeddings.append(embedding)\n",
    "    return np.asarray(delay_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaf910f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensions(data_in_batches: np.ndarray, window: int, sample_period: int, should_fit: bool = True):\n",
    "    \"\"\"\n",
    "    It uses the method approximate of the TimeSeriesTransformer in order to achieve dimensionality reduction.\n",
    "    Args:\n",
    "        data_in_batches (ndarray): The data of the time series separated in batches.\n",
    "        window (int): The size of the sub-segments of the given time series.\n",
    "            This is not supported by all algorithms.\n",
    "        target (ndarray): The labels that correspond to the given data in batches.\n",
    "        should_fit (bool): True if it is supported by the algorithm of the specified time series representation.\n",
    "    Returns:\n",
    "        The shortened time series as an array (ndarray).\n",
    "    \"\"\"\n",
    "    squeezed_seq = approximate(delay_in_seconds = 32, dimension = 8, sample_period = sample_period, \n",
    "                               series_in_segments = data_in_batches, window = window, should_fit = True)\n",
    "\n",
    "    debug('Shape of squeezed seq: {}'.format(squeezed_seq.shape))\n",
    "    return squeezed_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56cbfb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def _preprocess(data_df, labels_df, appliances, window_len, sample_period, should_fit: bool = True):\n",
    "    start_time = time.time()\n",
    "    data = get_site_meter_data(data_df)\n",
    "    get_features_time = time.time() - start_time\n",
    "    timing(f\"get features time {get_features_time}\")\n",
    "\n",
    "    debug(f\"Features \\n {data[:10]}\")\n",
    "    target = get_multilabels(labels_df, appliances)\n",
    "    target = np.array(target.values)\n",
    "    debug(f\"Target \\n {target[:10]}\")\n",
    "    window = get_window(window_len, sample_period)\n",
    "    rem = len(data) % window\n",
    "    if rem > 0:\n",
    "        data = data[:-rem]\n",
    "        target = target[:-rem]\n",
    "    target = bucketize_target(target, window)\n",
    "    data = bucketize_data(data, window)\n",
    "    # if representation_type == TransformerType.raw or representation_type == TransformerType.approximate:\n",
    "    #     pass\n",
    "    \n",
    "    start_time = time.time()\n",
    "    data = reduce_dimensions(data, window, sample_period,should_fit)\n",
    "    reduce_dimensions_time = time.time() - start_time\n",
    "    timing(f\"reduce dimensions time {reduce_dimensions_time}\")\n",
    "\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8d74d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train(train_df, train_labels_df, sample_period, appliances: list, window_len : TimeSeriesLength):\n",
    "    \"\"\"\n",
    "    Train the algorithm for the specified appliances.\n",
    "    Args:\n",
    "        appliances (List): List of appliances to be recognized.\n",
    "        raw_data (bool): True if the experiment uses raw data without any time series representation.\n",
    "    Returns:\n",
    "        The preprocess and the fiting time.\n",
    "    \"\"\"\n",
    "    info(\"Prepossessing before training...\")\n",
    "    start_time = time.time()\n",
    "    data, target = _preprocess(train_df, train_labels_df, appliances, window_len, sample_period)\n",
    "    preprocess_time = time.time() - start_time\n",
    "    timing(f\"preprocess time {preprocess_time}\")\n",
    "\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.reshape(data, (data.shape[0], data.shape[1] * data.shape[2]))\n",
    "    \n",
    "    return data, target\n",
    "    #info(\"Training...\")\n",
    "    #start_time = time.time()\n",
    "    #self.multilabel_clf.fit(data, target)\n",
    "    #fit_time = time.time() - start_time\n",
    "    #timing(f\"fit time {fit_time}\")\n",
    "    #return preprocess_time, fit_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fba2a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_test(test_df, test_labels_df, sample_period, appliances: list, window_len : TimeSeriesLength):\n",
    "    \"\"\"\n",
    "    Runs a test using the specified appliances.\n",
    "    Args:\n",
    "        appliances (List): List of appliances to be recognized.\n",
    "        raw_data (bool): True if the experiment uses raw data without any time series representation.\n",
    "    Returns:\n",
    "        A tuple containing macro, micro, a report, preprocess and fiting time.\n",
    "    \"\"\"\n",
    "    \n",
    "    info(\"Prepossessing before testing...\")\n",
    "    start_time = time.time()\n",
    "    data, target = _preprocess(test_df, test_labels_df, appliances, window_len, sample_period)\n",
    "    preprocess_time = time.time() - start_time\n",
    "    timing(f\"preprocess time {preprocess_time}\")\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.reshape(data, (data.shape[0], data.shape[1] * data.shape[2]))\n",
    "    \n",
    "    return data, target\n",
    "    #info(\"Testing...\")\n",
    "\n",
    "    #start_time = time.time()\n",
    "    \n",
    "    #predictions = multilabel_clf.predict(data)\n",
    "    #predictions_time = time.time() - start_time\n",
    "    #timing(f\"predictions time {predictions_time}\")\n",
    "\n",
    "    #micro = f1_score(target, predictions, average='micro')\n",
    "    #macro = f1_score(target, predictions, average='macro')\n",
    "    #info('F1 macro {}'.format(macro))\n",
    "    #info('F1 micro {}'.format(micro))\n",
    "    #report = classification_report(target, predictions, target_names=appliances, output_dict=True)\n",
    "    # confusion_matrix = multilabel_confusion_matrix(y_true=target, y_pred=predictions.toarray())\n",
    "    # confusion_matrix = None\n",
    "    #return macro, micro, report, preprocess_time, predictions_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e13a5",
   "metadata": {},
   "source": [
    "## Preprocess the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a6b12ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Prepossessing before training...\n",
      "TIMING: get features time 0.0\n",
      "\n",
      "DEBUG: Features \n",
      " [225.28334 222.60167 222.67667 222.35    222.58667 224.87833 223.71\n",
      " 224.68832 224.195   226.35   ]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['electric space heater', 'dish washer', 'electric stove', 'fridge',\n",
      "       'washer dryer', 'light', 'electric oven', 'unknown', 'sockets'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['fridge', 'dish washer', 'sockets', 'light', 'unknown', 'electric space heater', 'electric stove', 'electric oven', 'washer dryer']\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0.]]\n",
      "DEBUG: bucketize_data: Initial shape (411600, 9)\n",
      "DEBUG: bucketize_data: Shape in batches: (343, 1200, 9)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (343, 1200, 9)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (343, 9)\n",
      "DEBUG: bucketize_data: Initial shape (411600,)\n",
      "DEBUG: bucketize_data: Shape in batches: (343, 1200)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 1200\n",
      "DEBUG: Shape of squeezed seq: (343, 8, 1160)\n",
      "TIMING: reduce dimensions time 0.023937463760375977\n",
      "\n",
      "TIMING: preprocess time 0.045877933502197266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ts_len = TimeSeriesLength.WINDOW_2_HOURS\n",
    "sample_period = 6\n",
    "train_data, train_target = prep_train(train_df, train_labels_df, sample_period, appliances_redd1, ts_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaba6f8",
   "metadata": {},
   "source": [
    "## Preprocess the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b8189ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Prepossessing before testing...\n",
      "TIMING: get features time 0.0\n",
      "\n",
      "DEBUG: Features \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "DEBUG: get_multilabels  labels_df.columns Index(['electric space heater', 'dish washer', 'electric stove', 'fridge',\n",
      "       'washer dryer', 'light', 'electric oven', 'unknown', 'sockets'],\n",
      "      dtype='object')\n",
      "DEBUG: get_multilabels  appliances ['fridge', 'dish washer', 'sockets', 'light', 'unknown', 'electric space heater', 'electric stove', 'electric oven', 'washer dryer']\n",
      "DEBUG: Target \n",
      " [[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "DEBUG: bucketize_data: Initial shape (94800, 9)\n",
      "DEBUG: bucketize_data: Shape in batches: (79, 1200, 9)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (79, 1200, 9)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (79, 9)\n",
      "DEBUG: bucketize_data: Initial shape (94800,)\n",
      "DEBUG: bucketize_data: Shape in batches: (79, 1200)\n",
      "INFO: TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each segment. 40 < 1200\n",
      "DEBUG: Shape of squeezed seq: (79, 8, 1160)\n",
      "TIMING: reduce dimensions time 0.005984067916870117\n",
      "\n",
      "TIMING: preprocess time 0.01396322250366211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data, test_target = prep_test(test_df, test_labels_df, sample_period, appliances_redd1, ts_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a40a40",
   "metadata": {},
   "source": [
    "## Train and Classification\n",
    "* MlkNN\n",
    "* Rakel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9a24261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from skmultilearn.ensemble import RakelD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a3a6c6",
   "metadata": {},
   "source": [
    "### MlkNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb61ea",
   "metadata": {},
   "source": [
    "If you ran into error like I did : TypeError: __init__() takes 1 positional argument but 2 were given\n",
    ", you can try fix it this way\n",
    "* Uninstall the current sklearn version and install sklearn = 0.2.4\n",
    "* Locally by modifying L165 in _compute_cond from </br>\n",
    "self.knn_ = NearestNeighbors(self.k).fit(X)\n",
    "* to </br>\n",
    "self.knn_ = NearestNeighbors(n_neighbors=self.k).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5b84266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: F1 macro 0.42043142043142046\n",
      "INFO: F1 micro 0.8072727272727274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classifier = MLkNN(ignore_first_neighbours=0, k=3, s=1.0)\n",
    "classifier.fit(train_data, train_target)\n",
    "start_time = time.time()\n",
    "predictions = classifier.predict(test_data)\n",
    "predictions_time = time.time() - start_time\n",
    "micro = f1_score(test_target, predictions, average='micro')\n",
    "macro = f1_score(test_target, predictions, average='macro')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report = classification_report(test_target, predictions, target_names=appliances_redd1, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28afd1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fridge': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 79},\n",
       " 'dish washer': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 15},\n",
       " 'sockets': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 79},\n",
       " 'light': {'precision': 0.7702702702702703,\n",
       "  'recall': 0.9661016949152542,\n",
       "  'f1-score': 0.8571428571428571,\n",
       "  'support': 59},\n",
       " 'unknown': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.06060606060606061,\n",
       "  'f1-score': 0.1111111111111111,\n",
       "  'support': 33},\n",
       " 'electric space heater': {'precision': 1.0,\n",
       "  'recall': 0.18181818181818182,\n",
       "  'f1-score': 0.3076923076923077,\n",
       "  'support': 11},\n",
       " 'electric stove': {'precision': 0.5,\n",
       "  'recall': 0.2,\n",
       "  'f1-score': 0.28571428571428575,\n",
       "  'support': 5},\n",
       " 'electric oven': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 12},\n",
       " 'washer dryer': {'precision': 0.4,\n",
       "  'recall': 0.15384615384615385,\n",
       "  'f1-score': 0.2222222222222222,\n",
       "  'support': 13},\n",
       " 'micro avg': {'precision': 0.9098360655737705,\n",
       "  'recall': 0.7254901960784313,\n",
       "  'f1-score': 0.8072727272727274,\n",
       "  'support': 306},\n",
       " 'macro avg': {'precision': 0.5929929929929929,\n",
       "  'recall': 0.39581912124285007,\n",
       "  'f1-score': 0.42043142043142046,\n",
       "  'support': 306},\n",
       " 'weighted avg': {'precision': 0.7978625684508037,\n",
       "  'recall': 0.7254901960784313,\n",
       "  'f1-score': 0.7187587285626501,\n",
       "  'support': 306},\n",
       " 'samples avg': {'precision': 0.9145569620253164,\n",
       "  'recall': 0.7890194896524011,\n",
       "  'f1-score': 0.8273489871591136,\n",
       "  'support': 306}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f56898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c542a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nilmtk-env)",
   "language": "python",
   "name": "nilmtk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
