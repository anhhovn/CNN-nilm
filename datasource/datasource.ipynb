{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5246456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilmtk as nilmtk\n",
    "from nilmtk import DataSet, MeterGroup, Appliance\n",
    "from nilmtk.metergroup import MeterGroupID\n",
    "from nilmtk.elecmeter import ElecMeter, ElecMeterID \n",
    "from typing import List, Tuple, Dict\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "#REDD = os.path.join(dirname, r\"datasource\\dataset\\REDD\\redd.h5\")\n",
    "redd = DataSet('redd.h5')\n",
    "SITE_METER = 'Site meter'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd11a4a7",
   "metadata": {},
   "source": [
    "### House 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2011'\n",
    "train_month_end = '5'\n",
    "train_month_start = '4'\n",
    "train_end_date = \"{}-17-{}\".format(train_month_end, year)\n",
    "train_start_date = \"{}-18-{}\".format(train_month_start, year)\n",
    "test_month_end = '5'\n",
    "test_month_start = '5'\n",
    "test_end_date = \"{}-25-{}\".format(test_month_end, year)\n",
    "test_start_date = \"{}-18-{}\".format(test_month_start, year)\n",
    "#appliances for [1]\n",
    "appliances_redd1_taba = ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
    "##appliances for [2]\n",
    "appliances_redd1_nalm = ['electric oven', 'fridge', 'light', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
    "building = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ea785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(t: str):\n",
    "    print('TIMING: ' + t)\n",
    "    print()\n",
    "\n",
    "    \n",
    "def info(i: str):\n",
    "    print('INFO: ' + i)\n",
    "    \n",
    "def debug(d):\n",
    "    print('DEBUG: ' + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d99a2",
   "metadata": {},
   "source": [
    "## Read data using nilmtk\n",
    "* Read selected data\n",
    "* Label data\n",
    "* Bucketize data (delay embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_metergroup(dataset: DataSet, building: int, appliances: List,  start: str, end: str, \n",
    "                               sample_period = 3, include_mains=True):\n",
    "    \"\"\"\n",
    "    Get the MeterGroup of selected appliances\n",
    "    Return the MeterGroup\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_selected_metergroup() starts')\n",
    "    dataset.set_window(start=start, end=end)\n",
    "    elec = dataset.buildings[building].elec\n",
    "    appliances_with_one_meter = []\n",
    "    appliances_with_more_meters = []\n",
    "    for appliance in appliances:\n",
    "        metergroup = elec.select_using_appliances(type=appliances)\n",
    "        if len(metergroup.meters) > 1:\n",
    "            appliances_with_more_meters.append(appliance)\n",
    "        else:\n",
    "            appliances_with_one_meter.append(appliance)\n",
    "\n",
    "    special_metergroup = None\n",
    "    for appliance in appliances_with_more_meters:\n",
    "        inst = 1\n",
    "        if appliance == 'sockets' and building == 3:\n",
    "            inst = 4\n",
    "        if special_metergroup is None:\n",
    "            special_metergroup = elec.select_using_appliances(type=appliance, instance=inst)\n",
    "        else:\n",
    "            special_metergroup = special_metergroup.union(elec.select_using_appliances(type=appliance, instance=1))\n",
    "\n",
    "    selected_metergroup = elec.select_using_appliances(type=appliances_with_one_meter)\n",
    "    selected_metergroup = selected_metergroup.union(special_metergroup)\n",
    "    if include_mains:\n",
    "        mains_meter = dataset.buildings[building].elec.mains()\n",
    "        if isinstance(mains_meter, MeterGroup):\n",
    "            if len(mains_meter.meters) > 1:\n",
    "                mains_meter = mains_meter.meters[0]\n",
    "                mains_metergroup = MeterGroup(meters=[mains_meter])\n",
    "            else:\n",
    "                mains_metergroup = mains_meter\n",
    "        else:\n",
    "            mains_metergroup = MeterGroup(meters=[mains_meter])\n",
    "        selected_metergroup = selected_metergroup.union(mains_metergroup)\n",
    "    info('get_selected_metergroup() finished')\n",
    "    print(selected_metergroup)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "    return selected_metergroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af49e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_selected_appliances(dataset: DataSet, building: int, appliances : List, start: str, end: str, include_mains,\n",
    "                               sample_period = 3):\n",
    "    \"\"\"\n",
    "    Read and fill in missing values of selected appliances in a given bulding\n",
    "    Return the DataFrame of selected appliances in which columns are ElecMeter IDs,\n",
    "    and values are the PC of the meter in given sample period\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('read_selected_appliances() starts')\n",
    "    selected_metergroup = get_selected_metergroup(dataset, building, appliances, start, end,sample_period,include_mains)\n",
    "    df = selected_metergroup.dataframe_of_meters(sample_period=sample_period)\n",
    "    df.fillna(0, inplace=True)\n",
    "    info('read_selected_appliances() finished')\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "    return df, selected_metergroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a08373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_meters(dataset: DataSet, building: int, start_date: str, end_date:str, sample_period = 3):\n",
    "    \"\"\"\n",
    "    Read all the meters in given building\n",
    "    \"\"\"\n",
    "    elec = dataset.buildings[building].elec\n",
    "    print(elec)\n",
    "    #redd_datasource = Datasource(redd, \"REDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86957733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_df(df: DataFrame, selected_metergroup: MeterGroup) -> [List, Dict]:\n",
    "    \"\"\"\n",
    "    Returns two lists, one is a list of labels which describes DataFrame columns\n",
    "    Other is a list of power threshold of each appliances\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_labels_df() starts')\n",
    "    lst = []\n",
    "    threshold = {}\n",
    "    for m in df.columns:\n",
    "        label = \"\"\n",
    "        if isinstance(m,MeterGroupID):\n",
    "            tup_elecmeterID = m[0]\n",
    "            lst_elecmeterID = list(tup_elecmeterID)\n",
    "            #get meter group using list of ElecMeterIDs\n",
    "            mg = selected_metergroup[lst_elecmeterID]\n",
    "            #get labels of meter group\n",
    "            labels = mg.get_labels(lst_elecmeterID)\n",
    "            label = labels[0]\n",
    "            threshold[label] =mg.on_power_threshold()\n",
    "        else:\n",
    "            #get ElecMeter using ElecMeterID\n",
    "            elec_meter = selected_metergroup[m]\n",
    "            #get labels of ElecMeter\n",
    "            label = elec_meter.label()\n",
    "            threshold[label] = elec_meter.on_power_threshold()\n",
    "        lst += [label]\n",
    "    info('get_labels_df() finished')\n",
    "    print(lst)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "        \n",
    "    return lst, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77703d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dic_real_power(df: DataFrame, labels: List) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns a Dictionary in which key is name of the appliance, and value is the power consumption the appliance\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_dic_real_power() starts')\n",
    "    Dict = {}\n",
    "    lst = []\n",
    "    for k, v in df.items():\n",
    "        lst += [v]\n",
    "        \n",
    "    for i in range(len(labels)):\n",
    "        Dict[labels[i]] = lst[i]\n",
    "    info('get_dic_real_power() finished')\n",
    "    print(Dict)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))    \n",
    "    return Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10510e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dic_labeled_power(RealPower: Dict, threshold: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns a Dictionary in which key is name of the appliance, and value is \n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    info('get_dic_labeled_power() starts')\n",
    "    LabeledPower = {}\n",
    "    for appliance, real_power in RealPower.items():\n",
    "        if appliance != 'Site meter':\n",
    "            arr = create_labels(real_power, threshold[appliance])\n",
    "            LabeledPower[appliance] = arr\n",
    "    info('get_dic_labeled_power() finished')\n",
    "    print(LabeledPower)\n",
    "    timing('{}'.format(round(time.time() - start_time, 2)))\n",
    "    return LabeledPower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4b38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(array, threshold):\n",
    "    res = np.empty(array.shape)\n",
    "    for i in range(len(array)):\n",
    "        if array[i] >= threshold:\n",
    "            res[i] = 1\n",
    "        else:\n",
    "            res[i] = 0\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217df2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def normalize_columns(df: DataFrame, meter_group: MeterGroup, appliance_names: List[str]) -> Tuple[DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    It normalizes the names of the columns for compatibility.\n",
    "    Args:\n",
    "        df (DataFrame):\n",
    "        meter_group (MeterGroup):\n",
    "        appliance_names (List[str]):\n",
    "    Returns:\n",
    "        A tuple with a DataFrame and a dictionary mapping labels to ids.\n",
    "    \"\"\"\n",
    "    labels = meter_group.get_labels(df.columns)\n",
    "    normalized_labels = []\n",
    "    info(f\"Df columns before normalization {df.columns}\")\n",
    "    info(f\"Labels before normalization {labels}\")\n",
    "\n",
    "    for label in labels:\n",
    "        if label == SITE_METER and SITE_METER not in appliance_names:\n",
    "            normalized_labels.append(SITE_METER)\n",
    "            continue\n",
    "        for name in appliance_names:\n",
    "            ratio = fuzz.ratio(label.lower().replace('electric', \"\").lstrip().rstrip().split()[0],\n",
    "                                   name.lower().replace('electric', \"\").lstrip().rstrip().split()[0])\n",
    "            if ratio > 90:\n",
    "                info(f\"{name} ~ {label} ({ratio}%)\")\n",
    "                normalized_labels.append(name)\n",
    "    if len(normalized_labels) != len(labels):\n",
    "        debug(f\"len(normalized_labels) {len(normalized_labels)} != len(labels) {len(labels)}\")\n",
    "        raise LabelNormalizationError()\n",
    "    label2id = {l: i for l, i in zip(normalized_labels, df.columns)}\n",
    "    df.columns = normalized_labels\n",
    "    info(f\"Normalized labels {normalized_labels}\")\n",
    "    return df, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e55534e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_site_meter_data(df: DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the data of the site meter from the given DataFrame.\n",
    "    Args:\n",
    "        df (DataFrame): A DataFrame containing energy data with columns corresponding to different meters.\n",
    "    Returns:\n",
    "        The site meter data as an array (ndarray).\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if SITE_METER in col:\n",
    "            return df[col].values\n",
    "    raise NoSiteMeterException(\"Couldn' t find site meter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ec9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multilabels(labels_df: DataFrame, appliances: List = None) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Get the labels of the specified appliances.\n",
    "    Args:\n",
    "        labels_df (DataFrame):\n",
    "        appliances (List):\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    debug(f\"get_multilabels  labels_df.columns {labels_df.columns}\")\n",
    "    debug(f\"get_multilabels  appliances {appliances}\")\n",
    "    if appliances is None:\n",
    "        return labels_df\n",
    "    else:\n",
    "        return labels_df[appliances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d32476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_one_building(dataset: DataSet, appliances, building, start, end, sample_period) -> (pd.DataFrame, MeterGroup, Dict, Dict):\n",
    "    all_df, metergroup = read_selected_appliances(dataset = dataset, building = building, \n",
    "                                                 appliances = appliances, start = start, end = end, include_mains = True, sample_period = sample_period )\n",
    "    debug(f\"Length of data of all loaded meters {len(all_df)}\")\n",
    "    all_df, label2id = normalize_columns(all_df, metergroup, appliances)\n",
    "    debug(f\"Length of data of all loaded meters {len(all_df)}\")\n",
    "    info('Meters that have been loaded (all_df.columns):\\n' + str(all_df.columns))\n",
    "    \n",
    "    \n",
    "    return all_df, metergroup, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb40d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multilabels_from_meters(meters: DataFrame, meter_group: MeterGroup, labels2id: dict) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Creates multi labels from the given meter group using a dictionary as a lookup table.\n",
    "    Args:\n",
    "        meters (DataFrame):\n",
    "        meter_group (MeterGroup):\n",
    "        labels2id (dict):\n",
    "    Returns:\n",
    "        A DataFrame with the multi labels.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    labels = dict()\n",
    "    for col in meters.columns:\n",
    "        info(f\"Creating multilabels from meter {col}, \"\n",
    "             f\"\\nlabels2id[col] {labels2id[col]}\"\n",
    "             f\"\\nmetergroup[labels2id[col]] {meter_group[labels2id[col]]}\")\n",
    "        meter = meter_group[labels2id[col]]\n",
    "        threshold = meter.on_power_threshold()\n",
    "        vals = meters[col].values.astype(float)\n",
    "        if vals is None or col == SITE_METER:\n",
    "            debug(f\"Skipping {col} - {vals}\")\n",
    "            continue\n",
    "        debug(f\"meters[col].values.astype(float) {col} - {vals}\")\n",
    "        labels[col] = create_labels(vals, threshold)\n",
    "    timing('Create multilabels from meters {}'.format(round(time.time() - start_time, 2)))\n",
    "    return DataFrame(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15921bb4",
   "metadata": {},
   "source": [
    "#### Set up train and test data (house 1) for [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_taba1, train_metergroup_taba1, train_label2id_taba1 = setup_one_building(redd, appliances_redd1_taba, building, \n",
    "                                                                train_start_date, train_end_date, sample_period = 6)\n",
    "train_labels_df_taba1 = create_multilabels_from_meters(train_df_taba1, train_metergroup_taba1, train_label2id_taba1)\n",
    "\n",
    "test_df_taba1, test_metergroup_taba1, test_label2id_taba1 = setup_one_building(redd, appliances_redd1_taba, building, \n",
    "                                                                test_start_date, test_end_date, sample_period = 6)\n",
    "test_labels_df_taba1 = create_multilabels_from_meters(test_df_taba1, test_metergroup_taba1, test_label2id_taba1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3f708",
   "metadata": {},
   "source": [
    "#### Set up train and test data (house 1) for [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_nalm1, train_metergroup_nalm1, train_label2id_nalm1 = setup_one_building(redd, appliances_redd1_nalm, building, \n",
    "                                                                train_start_date, train_end_date, sample_period = 6)\n",
    "train_labels_df_nalm1 = create_multilabels_from_meters(train_df_nalm1, train_metergroup_nalm1, train_label2id_nalm1)\n",
    "\n",
    "test_df_nalm1, test_metergroup_nalm1, test_label2id_nalm1 = setup_one_building(redd, appliances_redd1_nalm, building, \n",
    "                                                                test_start_date, test_end_date, sample_period = 6)\n",
    "test_labels_df_nalm1 = create_multilabels_from_meters(test_df_nalm1, test_metergroup_nalm1, test_label2id_nalm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f269b7",
   "metadata": {},
   "source": [
    "### Time series length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f58b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class TimeSeriesLength(Enum):\n",
    "    \"\"\"\n",
    "    The length of each segment of the time series, which will be used for inference.\n",
    "    \"\"\"\n",
    "    WINDOW_SAMPLE_PERIOD = 'same'\n",
    "    WINDOW_1_MIN = '1m'\n",
    "    WINDOW_5_MINS = '5m'\n",
    "    WINDOW_10_MINS = '10m'\n",
    "    WINDOW_30_MINS = '30m'\n",
    "    WINDOW_1_HOUR = '1h'\n",
    "    WINDOW_2_HOURS = '2h'\n",
    "    WINDOW_3_HOURS = '3h'\n",
    "    WINDOW_4_HOURS = '4h'\n",
    "    WINDOW_8_HOURS = '8h'\n",
    "    WINDOW_1_DAY = '1d'\n",
    "    WINDOW_1_WEEK = '1w'\n",
    "    \n",
    "def get_window(dt: TimeSeriesLength, sample_period) -> int:\n",
    "    choices = {TimeSeriesLength.WINDOW_SAMPLE_PERIOD: 1,\n",
    "               TimeSeriesLength.WINDOW_1_MIN        : get_no_of_samples_per_min(sample_period),\n",
    "               TimeSeriesLength.WINDOW_5_MINS       : get_no_of_samples_per_min(sample_period) * 5,\n",
    "               TimeSeriesLength.WINDOW_10_MINS      : get_no_of_samples_per_min(sample_period) * 10,\n",
    "               TimeSeriesLength.WINDOW_30_MINS      : get_no_of_samples_per_min(sample_period) * 30,\n",
    "               TimeSeriesLength.WINDOW_1_HOUR       : get_no_of_samples_per_hour(sample_period),\n",
    "               TimeSeriesLength.WINDOW_2_HOURS      : get_no_of_samples_per_hour(sample_period) * 2,\n",
    "               TimeSeriesLength.WINDOW_3_HOURS      : get_no_of_samples_per_hour(sample_period) * 3,\n",
    "               TimeSeriesLength.WINDOW_4_HOURS      : get_no_of_samples_per_hour(sample_period) * 4,\n",
    "               TimeSeriesLength.WINDOW_8_HOURS      : get_no_of_samples_per_hour(sample_period) * 8,\n",
    "               TimeSeriesLength.WINDOW_1_DAY        : get_no_of_samples_per_day(sample_period),\n",
    "               TimeSeriesLength.WINDOW_1_WEEK       : get_no_of_samples_per_day(sample_period) * 7\n",
    "              }\n",
    "    return int(choices.get(dt, 1))\n",
    "    \n",
    "def get_no_of_samples_per_min(sample_period):\n",
    "    \"\"\"\n",
    "    It returns the number of samples per minute. This depends also on the predefined sample period.\n",
    "    Returns:\n",
    "        An int representing the number of samples.\n",
    "    \"\"\"\n",
    "    return 60 / sample_period\n",
    "\n",
    "\n",
    "def get_no_of_samples_per_hour(sample_period):\n",
    "    \"\"\"\n",
    "    It returns the number of samples per hour. This depends also on the predefined sample period.\n",
    "    Returns:\n",
    "        An int representing the number of samples.\n",
    "    \"\"\"\n",
    "    return get_no_of_samples_per_min(sample_period) * 60\n",
    "\n",
    "\n",
    "def get_no_of_samples_per_day(sample_period):\n",
    "    \"\"\"\n",
    "    It returns the number of samples per day. This depends also on the predefined sample period.\n",
    "    Returns:\n",
    "        An int representing the number of samples.\n",
    "    \"\"\"\n",
    "    return get_no_of_samples_per_hour(sample_period) * 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c7e04",
   "metadata": {},
   "source": [
    "### Bucketize data / delay embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc8dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_data(data: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    It segments the time series grouping it into batches. Its segment is of size equal to the window.\n",
    "    Args:\n",
    "        data (ndarray): The given time series.\n",
    "        window (int): The size of the segments.\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    debug('bucketize_data: Initial shape {}'.format(data.shape))\n",
    "    n_dims = len(data.shape)\n",
    "\n",
    "    if n_dims == 1:\n",
    "        seq_in_batches = np.reshape(data, (int(len(data) / window), window))\n",
    "    elif n_dims == 2:\n",
    "        seq_in_batches = np.reshape(data, (int(len(data) / window), window, data.shape[1]))\n",
    "    else:\n",
    "        raise Exception('Invalid number of dimensions {}.'.format(n_dims))\n",
    "    debug('bucketize_data: Shape in batches: {}'.format(seq_in_batches.shape))\n",
    "    return seq_in_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c447f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_target(target: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Creates target data according to the lenght of the window of the segmented data.\n",
    "    Args:\n",
    "        target (ndarray): Target data with the original size.\n",
    "        window (int): The length of window that will be used to create the corresponding labels.\n",
    "    Returns:\n",
    "        The target data for the new bucketized time series.\n",
    "    \"\"\"\n",
    "    target_in_batches = bucketize_data(target, window)\n",
    "    any_multilabel = np.any(target_in_batches, axis=1)\n",
    "    debug('bucketize_target: Shape of array in windows: {}'.format(target_in_batches.shape))\n",
    "    debug('bucketize_target: Shape of array after merging windows: {}'.format(any_multilabel.shape))\n",
    "    return any_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0939b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def takens_embedding(series: np.ndarray, delay, dimension) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function returns the Takens embedding of data with delay into dimension,\n",
    "    delay*dimension must be < len(data)\n",
    "    \"\"\"\n",
    "    if delay * dimension > len(series):\n",
    "        info(f'Not enough data for the given delay ({delay}) and dimension ({dimension}).'\n",
    "             f'\\ndelay * dimension > len(data): {delay * dimension} > {len(series)}')\n",
    "        return series\n",
    "    delay_embedding = np.array([series[0:len(series) - delay * dimension]])\n",
    "    for i in range(1, dimension):\n",
    "        delay_embedding = np.append(delay_embedding,\n",
    "                                    [series[i * delay:len(series) - delay * (dimension - i)]], axis=0)\n",
    "    return delay_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a21250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate(delay_in_seconds: int, dimension: int, sample_period: int, series_in_segments: np.ndarray, window: int = 1, should_fit: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    The time series is given as segments. For each segment we extract the delay embeddings.\n",
    "    \"\"\"\n",
    "    delay_items = int(delay_in_seconds / sample_period)\n",
    "    window_size = delay_items * dimension\n",
    "\n",
    "    if window_size > len(series_in_segments[0]):\n",
    "        raise Exception(\n",
    "            f'Not enough data for the given delay ({delay_in_seconds} seconds) and dimension ({dimension}).'\n",
    "            f'\\ndelay_items * dimension > len(data): {window_size} > {len(series_in_segments[0])}')\n",
    "\n",
    "    if window_size == len(series_in_segments[0]):\n",
    "        info(f\"TimeDelayEmbeddingAdapter is applied with delay embeddings equavalent to the length of each segment\"\n",
    "                f\" {window_size} == {len(series_in_segments[0])}\")\n",
    "\n",
    "    if window_size < len(series_in_segments[0]):\n",
    "        info(f\"TimeDelayEmbeddingAdapter is applied with delay embeddings covering less than the length of each \"\n",
    "                f\"segment. {window_size} < {len(series_in_segments[0])}\")\n",
    "\n",
    "    delay_embeddings = []\n",
    "    for segment in series_in_segments:\n",
    "        embedding = takens_embedding(segment, delay_items, dimension)\n",
    "        delay_embeddings.append(embedding)\n",
    "    return np.asarray(delay_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf910f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensions(data_in_batches: np.ndarray, window: int, sample_period: int,\n",
    "                      dimension: int, delay_in_seconds: int, should_fit: bool = True):\n",
    "    \"\"\"\n",
    "    It uses the method approximate of the TimeSeriesTransformer in order to achieve dimensionality reduction.\n",
    "    Args:\n",
    "        data_in_batches (ndarray): The data of the time series separated in batches.\n",
    "        window (int): The size of the sub-segments of the given time series.\n",
    "            This is not supported by all algorithms.\n",
    "        target (ndarray): The labels that correspond to the given data in batches.\n",
    "        should_fit (bool): True if it is supported by the algorithm of the specified time series representation.\n",
    "    Returns:\n",
    "        The shortened time series as an array (ndarray).\n",
    "    \"\"\"\n",
    "    squeezed_seq = approximate(delay_in_seconds, dimension, sample_period = sample_period, \n",
    "                               series_in_segments = data_in_batches, window = window, should_fit = True)\n",
    "\n",
    "    debug('Shape of squeezed seq: {}'.format(squeezed_seq.shape))\n",
    "    return squeezed_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cbfb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def _preprocess(data_df, labels_df, appliances, window_len, sample_period, \n",
    "                 dimension, delay_in_seconds, should_fit: bool = True):\n",
    "    start_time = time.time()\n",
    "    data = get_site_meter_data(data_df)\n",
    "    get_features_time = time.time() - start_time\n",
    "    timing(f\"get features time {get_features_time}\")\n",
    "\n",
    "    debug(f\"Features \\n {data[:10]}\")\n",
    "    target = get_multilabels(labels_df, appliances)\n",
    "    target = np.array(target.values)\n",
    "    debug(f\"Target \\n {target[:10]}\")\n",
    "    window = get_window(window_len, sample_period)\n",
    "    rem = len(data) % window\n",
    "    if rem > 0:\n",
    "        data = data[:-rem]\n",
    "        target = target[:-rem]\n",
    "    target = bucketize_target(target, window)\n",
    "    data = bucketize_data(data, window)\n",
    "    # if representation_type == TransformerType.raw or representation_type == TransformerType.approximate:\n",
    "    #     pass\n",
    "    \n",
    "    start_time = time.time()\n",
    "    data = reduce_dimensions(data, window, sample_period, dimension, delay_in_seconds, should_fit)\n",
    "    reduce_dimensions_time = time.time() - start_time\n",
    "    timing(f\"reduce dimensions time {reduce_dimensions_time}\")\n",
    "\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d74d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train(train_df, train_labels_df, sample_period, appliances: list, window_len : TimeSeriesLength,\n",
    "              dimension, delay_in_seconds):\n",
    "    \"\"\"\n",
    "    Train the algorithm for the specified appliances.\n",
    "    Args:\n",
    "        appliances (List): List of appliances to be recognized.\n",
    "        raw_data (bool): True if the experiment uses raw data without any time series representation.\n",
    "    Returns:\n",
    "        The preprocess and the fiting time.\n",
    "    \"\"\"\n",
    "    info(\"Prepossessing before training...\")\n",
    "    start_time = time.time()\n",
    "    data, target = _preprocess(train_df, train_labels_df, appliances, window_len, sample_period,\n",
    "                              dimension, delay_in_seconds)\n",
    "    preprocess_time = time.time() - start_time\n",
    "    timing(f\"preprocess time {preprocess_time}\")\n",
    "\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.reshape(data, (data.shape[0], data.shape[1] * data.shape[2]))\n",
    "    \n",
    "    return data, target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba2a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_test(test_df, test_labels_df, sample_period, appliances: list, window_len : TimeSeriesLength,\n",
    "             dimension, delay_in_seconds):\n",
    "    \"\"\"\n",
    "    Runs a test using the specified appliances.\n",
    "    Args:\n",
    "        appliances (List): List of appliances to be recognized.\n",
    "        raw_data (bool): True if the experiment uses raw data without any time series representation.\n",
    "    Returns:\n",
    "        A tuple containing macro, micro, a report, preprocess and fiting time.\n",
    "    \"\"\"\n",
    "    \n",
    "    info(\"Prepossessing before testing...\")\n",
    "    start_time = time.time()\n",
    "    data, target = _preprocess(test_df, test_labels_df, appliances, window_len, sample_period,\n",
    "                              dimension, delay_in_seconds)\n",
    "    preprocess_time = time.time() - start_time\n",
    "    timing(f\"preprocess time {preprocess_time}\")\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.reshape(data, (data.shape[0], data.shape[1] * data.shape[2]))\n",
    "    \n",
    "    return data, target\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7052c0bf",
   "metadata": {},
   "source": [
    "### Comparison with existing multi-label NILM systems\n",
    "</br>\n",
    "According to the literature, the models proposed by <b>Tabatabaei et al. [1]</b> are often used as a strong baseline to evaluate state-of-the-art solutions. In time domain, the method that is used is time delay embeddings. It has two parameters: the time delay and the dimensions of the embeddings. I use the exact same time delay and dimension used in [1], <b>time delay of 32 seconds and dimension of 8  for House 1, a time delay of 95 seconds and dimension of 18 for House 3 </b>. The <b>sampling rate is 6s</b> for all houses in REDD, however, the window isn't specified in their paper.I run my experiment with <b>3 chosen windows: 1 hour, 2 hours, and 4 hours.</b> The authors didn't mention the number of appliances they have used in their experiments, so I use only the appliances mentioned in their paper. The appliances for <b>House 1 are oven, fridge, light, microwave, bath gfi, outlet, washer dryer</b>. The appliances for <b>House 3 are electronics, furnace, washer dryer, microwave, bath gfi, kitchen outlet</b>. \n",
    "\n",
    "\n",
    "\n",
    "Besides [1], <b>Nalmpantis et al. [2]</b> was proposed that they had a similar setup to [1] in their comparison. They found that the best time delay is determined to be <b>30 seconds and the best dimension equal to 6. The sampling rate is 6s for all houses in REDD, and the window is set to 5 minutes</b>. The appliances in <b>House 1 are oven, refrigerator, light, microwave, bath GFI, washer dryer, and kitchen outlet. For House 3, the appliances are electronics, furnace, washer dryer, microwave, bath GFI and kitchen outlet</b>. I will run another experiment using the exact mentioned parameters and compare the result to [2]. <b> One thing is </b> the dimensionality and time delay are the same on both House 1 and House 3 in [2].\n",
    "\n",
    "\n",
    "References: </br>\n",
    "[1] Tabatabaei, S. M., Dick, S., & Xu, W. (2016). Toward non-intrusive load monitoring via multi-label classification. IEEE Transactions on Smart Grid, 8(1), 26-40.\n",
    "\n",
    "[2] Nalmpantis, C., & Vrakas, D. (2020). On time series representations for multi-label NILM. Neural Computing and Applications, 32, 17275-17290."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328d2d0",
   "metadata": {},
   "source": [
    "### Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b12ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts_len_5_min = TimeSeriesLength.WINDOW_5_MINS\n",
    "ts_len_10_min = TimeSeriesLength.WINDOW_10_MINS\n",
    "ts_len_30_min = TimeSeriesLength.WINDOW_30_MINS\n",
    "ts_len_1hr = TimeSeriesLength.WINDOW_1_HOUR\n",
    "ts_len_2hr = TimeSeriesLength.WINDOW_2_HOURS\n",
    "ts_len_4hr = TimeSeriesLength.WINDOW_4_HOURS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6c320",
   "metadata": {},
   "source": [
    "### Classifiers\n",
    "#### - MlkNN (k = 3, s = 1)\n",
    "#### - Rakel\n",
    "<b>Note for Rakel</b> </br>\n",
    "Classifier used in [1] is SVC, classifier used in [2] is  multi-layer perceptron\n",
    "\n",
    "<b>Note for MlkNN</b> </br>\n",
    "\n",
    "If you ran into error like I did : TypeError: __init__() takes 1 positional argument but 2 were given\n",
    ", you can try fix it this way\n",
    "* Uninstall the current sklearn version and install sklearn = 0.2.4\n",
    "* Locally by modifying L165 in _compute_cond from </br>\n",
    "self.knn_ = NearestNeighbors(self.k).fit(X)\n",
    "* to </br>\n",
    "self.knn_ = NearestNeighbors(n_neighbors=self.k).fit(X)\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb0a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from skmultilearn.ensemble import RakelD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "classifier_MlkNN = MLkNN(ignore_first_neighbours=0, k=3, s=1.0)\n",
    "classifier_Rakel =RakelD(SVC(gamma='auto'), labelset_size=4)\n",
    "classifier_Rakel_MLPC = RakelD(MLPClassifier(hidden_layer_sizes=(100, 100, 100), learning_rate='adaptive',\n",
    "                                             solver='adam'), labelset_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aca2e6",
   "metadata": {},
   "source": [
    "#### [1], house 1, 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1979350",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_period = 6\n",
    "dimension = 8\n",
    "delay_in_seconds = 32\n",
    "train_data, train_target = prep_train(train_df_taba1, train_labels_df_taba1, sample_period, \n",
    "                                      appliances_redd1_taba, ts_len_5_min, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_taba1, test_labels_df_taba1, sample_period, \n",
    "                                   appliances_redd1_taba, ts_len_5_min, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_5min = classification_report(test_target, predictions_nn, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_mlknn_5min)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_5min = classification_report(test_target, predictions_rak, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_rakeld_5min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e01c288",
   "metadata": {},
   "source": [
    "#### [1], house 1, 10 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b96ffb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_period = 6\n",
    "dimension = 8\n",
    "delay_in_seconds = 32\n",
    "train_data, train_target = prep_train(train_df_taba1, train_labels_df_taba1, sample_period, \n",
    "                                      appliances_redd1_taba, ts_len_10_min, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_taba1, test_labels_df_taba1, sample_period, \n",
    "                                   appliances_redd1_taba, ts_len_10_min, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_10min = classification_report(test_target, predictions_nn, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_mlknn_10min)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_10min = classification_report(test_target, predictions_rak, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_rakeld_10min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05afedd8",
   "metadata": {},
   "source": [
    "#### [1], house 1, 30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d23db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_period = 6\n",
    "dimension = 8\n",
    "delay_in_seconds = 32\n",
    "train_data, train_target = prep_train(train_df_taba1, train_labels_df_taba1, sample_period, \n",
    "                                      appliances_redd1_taba, ts_len_30_min, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_taba1, test_labels_df_taba1, sample_period, \n",
    "                                   appliances_redd1_taba, ts_len_30_min, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_30min = classification_report(test_target, predictions_nn, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_mlknn_30min)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_30min = classification_report(test_target, predictions_rak, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_rakeld_30min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaba6f8",
   "metadata": {},
   "source": [
    "#### [1], house 1, 1 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8189ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_period = 6\n",
    "dimension = 8\n",
    "delay_in_seconds = 32\n",
    "train_data, train_target = prep_train(train_df_taba1, train_labels_df_taba1, sample_period, \n",
    "                                      appliances_redd1_taba, ts_len_1hr, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_taba1, test_labels_df_taba1, sample_period, \n",
    "                                   appliances_redd1_taba, ts_len_1hr, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_1hr = classification_report(test_target, predictions_nn, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_mlknn_1hr)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_1hr = classification_report(test_target, predictions_rak, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_rakeld_1hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a3a6c6",
   "metadata": {},
   "source": [
    "#### [1], house 1, 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f56898",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_period = 6\n",
    "dimension = 8\n",
    "delay_in_seconds = 32\n",
    "train_data, train_target = prep_train(train_df_taba1, train_labels_df_taba1, sample_period, \n",
    "                                      appliances_redd1_taba, ts_len_2hr, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_taba1, test_labels_df_taba1, sample_period, \n",
    "                                   appliances_redd1_taba, ts_len_2hr, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_2hr = classification_report(test_target, predictions_nn, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_mlknn_2hr)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_2hr = classification_report(test_target, predictions_rak, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_rakeld_2hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb913dc",
   "metadata": {},
   "source": [
    "#### [1], house 1, 4 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a4353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_period = 6\n",
    "dimension = 8\n",
    "delay_in_seconds = 32\n",
    "train_data, train_target = prep_train(train_df_taba1, train_labels_df_taba1, sample_period, \n",
    "                                      appliances_redd1_taba, ts_len_4hr, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_taba1, test_labels_df_taba1, sample_period, \n",
    "                                   appliances_redd1_taba, ts_len_4hr, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_4hr = classification_report(test_target, predictions_nn, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_mlknn_4hr)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_4hr = classification_report(test_target, predictions_rak, target_names=appliances_redd1_taba, output_dict=True)\n",
    "print(report_rakeld_4hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a894165",
   "metadata": {},
   "source": [
    "#### [2], house 1, 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f34c57c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_period = 6\n",
    "dimension = 6\n",
    "delay_in_seconds = 30\n",
    "train_data, train_target = prep_train(train_df_nalm1, train_labels_df_nalm1, sample_period, \n",
    "                                      appliances_redd1_nalm, ts_len_5_min, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_nalm1, test_labels_df_nalm1, sample_period, \n",
    "                                   appliances_redd1_nalm, ts_len_5_min, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_5min_nalm = classification_report(test_target, predictions_nn, target_names=appliances_redd1_nalm, output_dict=True)\n",
    "print(report_mlknn_5min_nalm)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel_MLPC.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel_MLPC.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_5min_nalm = classification_report(test_target, predictions_rak, target_names=appliances_redd1_nalm, output_dict=True)\n",
    "print(report_rakeld_5min_nalm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d9f2ce",
   "metadata": {},
   "source": [
    "### House 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f160c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_3 = '2011'\n",
    "train_month_end_3 = '4'\n",
    "train_month_start_3 = '4'\n",
    "train_end_date_3 = \"{}-30-{}\".format(train_month_end_3, year_3)\n",
    "train_start_date_3 = \"{}-16-{}\".format(train_month_start_3, year_3)\n",
    "test_month_end_3 = '5'\n",
    "test_month_start_3 = '5'\n",
    "test_end_date_3 = \"{}-30-{}\".format(test_month_end_3, year_3)\n",
    "test_start_date_3 = \"{}-17-{}\".format(test_month_start_3, year_3)\n",
    "#appliances for [1]\n",
    "appliances_redd3_taba = ['electric furnace', 'CE appliance', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
    "##appliances for [2]\n",
    "appliances_redd3_nalm = ['electric furnace', 'CE appliance', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
    "building_3 = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68700f72",
   "metadata": {},
   "source": [
    "#### Set up train and test data (house 3) for [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd4064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df_taba3, train_metergroup_taba3, train_label2id_taba3 = setup_one_building(redd, appliances_redd3_taba, building_3, \n",
    "                                                                train_start_date_3, train_end_date_3, sample_period = 6)\n",
    "train_labels_df_taba3 = create_multilabels_from_meters(train_df_taba3, train_metergroup_taba3, train_label2id_taba3)\n",
    "\n",
    "test_df_taba3, test_metergroup_taba3, test_label2id_taba3 = setup_one_building(redd, appliances_redd3_taba, building_3, \n",
    "                                                                test_start_date_3, test_end_date_3, sample_period = 6)\n",
    "test_labels_df_taba3 = create_multilabels_from_meters(test_df_taba3, test_metergroup_taba3, test_label2id_taba3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31c4da9",
   "metadata": {},
   "source": [
    "#### [1], house 3, 30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a6b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_period = 6\n",
    "dimension = 18\n",
    "delay_in_seconds = 95\n",
    "train_data, train_target = prep_train(train_df_taba3, train_labels_df_taba3, sample_period, \n",
    "                                      appliances_redd3_taba, ts_len_30_min, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_taba3, test_labels_df_taba3, sample_period, \n",
    "                                   appliances_redd3_taba, ts_len_30_min, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report3_mlknn_30min = classification_report(test_target, predictions_nn, target_names=appliances_redd3_taba, output_dict=True)\n",
    "print(report3_mlknn_30min)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report3_rakeld_30min = classification_report(test_target, predictions_rak, target_names=appliances_redd3_taba, output_dict=True)\n",
    "print(report3_rakeld_30min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b533f",
   "metadata": {},
   "source": [
    "#### [1], house 3, 1 Hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6254d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_period = 6\n",
    "dimension = 18\n",
    "delay_in_seconds = 95\n",
    "train_data, train_target = prep_train(train_df_taba3, train_labels_df_taba3, sample_period, \n",
    "                                      appliances_redd3_taba, ts_len_1hr, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_taba3, test_labels_df_taba3, sample_period, \n",
    "                                   appliances_redd3_taba, ts_len_1hr, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report3_mlknn_1hr = classification_report(test_target, predictions_nn, target_names=appliances_redd3_taba, output_dict=True)\n",
    "print(report3_mlknn_1hr)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report3_rakeld_1hr = classification_report(test_target, predictions_rak, target_names=appliances_redd3_taba, output_dict=True)\n",
    "print(report3_rakeld_1hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89010e",
   "metadata": {},
   "source": [
    "#### [1], house 3, 2 Hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f37d42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_period = 6\n",
    "dimension = 18\n",
    "delay_in_seconds = 95\n",
    "train_data, train_target = prep_train(train_df_taba3, train_labels_df_taba3, sample_period, \n",
    "                                      appliances_redd3_taba, ts_len_2hr, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_taba3, test_labels_df_taba3, sample_period, \n",
    "                                   appliances_redd3_taba, ts_len_2hr, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report3_mlknn_2hr = classification_report(test_target, predictions_nn, target_names=appliances_redd3_taba, output_dict=True)\n",
    "print(report3_mlknn_2hr)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report3_rakeld_2hr = classification_report(test_target, predictions_rak, target_names=appliances_redd3_taba, output_dict=True)\n",
    "print(report3_rakeld_2hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600e9c1",
   "metadata": {},
   "source": [
    "#### [1], house 3, 4 Hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540fc4d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_period = 6\n",
    "dimension = 18\n",
    "delay_in_seconds = 95\n",
    "train_data, train_target = prep_train(train_df_taba3, train_labels_df_taba3, sample_period, \n",
    "                                      appliances_redd3_taba, ts_len_4hr, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_taba3, test_labels_df_taba3, sample_period, \n",
    "                                   appliances_redd3_taba, ts_len_4hr, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report3_mlknn_4hr = classification_report(test_target, predictions_nn, target_names=appliances_redd3_taba, output_dict=True)\n",
    "print(report3_mlknn_4hr)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report3_rakeld_4hr = classification_report(test_target, predictions_rak, target_names=appliances_redd3_taba, output_dict=True)\n",
    "print(report3_rakeld_4hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8cbc95",
   "metadata": {},
   "source": [
    "#### Set up train and test data (house 3) for [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_nalm3, train_metergroup_nalm3, train_label2id_nalm3 = setup_one_building(redd, appliances_redd3_nalm, building_3, \n",
    "                                                                train_start_date_3, train_end_date_3, sample_period = 6)\n",
    "train_labels_df_nalm3 = create_multilabels_from_meters(train_df_nalm3, train_metergroup_nalm3, train_label2id_nalm3)\n",
    "\n",
    "test_df_nalm3, test_metergroup_nalm3, test_label2id_nalm3 = setup_one_building(redd, appliances_redd3_nalm, building_3, \n",
    "                                                                test_start_date_3, test_end_date_3, sample_period = 6)\n",
    "test_labels_df_nalm3 = create_multilabels_from_meters(test_df_nalm3, test_metergroup_nalm3, test_label2id_nalm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae2958",
   "metadata": {},
   "source": [
    "#### [2], house 3, 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f65e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_period = 6\n",
    "dimension = 6\n",
    "delay_in_seconds = 30\n",
    "train_data, train_target = prep_train(train_df_nalm3, train_labels_df_nalm3, sample_period, \n",
    "                                      appliances_redd3_nalm, ts_len_5_min, dimension, delay_in_seconds)\n",
    "test_data, test_target = prep_test(test_df_nalm3, test_labels_df_nalm3, sample_period, \n",
    "                                   appliances_redd3_nalm, ts_len_5_min, dimension, delay_in_seconds)\n",
    "# MlkNN\n",
    "classifier_MlkNN.fit(train_data, train_target)\n",
    "predictions_nn = classifier_MlkNN.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_nn, average='micro')\n",
    "macro = f1_score(test_target, predictions_nn, average='macro')\n",
    "info('MlkNN report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_mlknn_5min_nalm = classification_report(test_target, predictions_nn, target_names=appliances_redd3_nalm, output_dict=True)\n",
    "print(report_mlknn_5min_nalm)\n",
    "\n",
    "#RakelD\n",
    "classifier_Rakel_MLPC.fit(train_data, train_target)\n",
    "predictions_rak = classifier_Rakel_MLPC.predict(test_data)\n",
    "micro = f1_score(test_target, predictions_rak, average='micro')\n",
    "macro = f1_score(test_target, predictions_rak, average='macro')\n",
    "info('RakelD report')\n",
    "info('F1 macro {}'.format(macro))\n",
    "info('F1 micro {}'.format(micro))\n",
    "report_rakeld_5min_nalm = classification_report(test_target, predictions_rak, target_names=appliances_redd3_nalm, output_dict=True)\n",
    "print(report_rakeld_5min_nalm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e07954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nilmtk-env)",
   "language": "python",
   "name": "nilmtk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
